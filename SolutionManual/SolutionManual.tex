\documentclass[oneside]{book}

\usepackage{wrapfig}
\usepackage{ifpdf}
 \ifpdf
  \usepackage{hyperref}
\fi


\RequirePackage{amsmath}
\RequirePackage{amssymb}
\RequirePackage{amsthm}

\usepackage{graphicx}
\usepackage{color}
\usepackage{makeidx}

\def\halmos{\mbox{\raggedright\rule{0.1in}{0.1in}}}
\newcommand{\xqedhere}[2]{%
  \rlap{\hbox to#1{\hfil\llap{\ensuremath{#2}}}}}

\newcommand{\xqed}[1]{%
  \leavevmode\unskip\penalty9999 \hbox{}\nobreak\hfill
  \quad\hbox{\ensuremath{#1}}}

\def\IndexTheorem#1{\index{Theorems!Theorem~\ref{#1}}}
\def\IndexDefinition#1{\index{Definitions!Definition~\ref{#1}}}
\def\IndexCorollary#1{\index{Corollaries!Corollary~\ref{#1}}}
\def\IndexLemma#1{\index{Lemmas!Lemma~\ref{#1}}}


\def\abs#1{\left|#1\right|}
\def\divides#1#2{#1\kern.1em\left|#2\right.{}}
\def\notdivide#1#2{#1\kern-.2em\not|\,#2}

\newenvironment{ProofOutline}{\noindent{}{\bf Sketch of Proof:}}{\hfill{}QED?\\}
\newenvironment{hint}{\noindent{}\hfill\\{\rm\bf Hint: }}{}
\newenvironment{scrapwork}{\noindent{}\hfill\\{\bf{} SCRAPWORK}:
}{\bf\hfill\\ END OF SCRAPWORK} 
%\renewenvironment{proof}{\noindent{}{\bf Proof:\,}}{\hfill \halmos{}\\[2mm]}
\renewenvironment{proof}{\leftline{{\bf Proof:\,}}}{\hfill \halmos{}\\[2mm]}

%% Set up margin notes
\setlength{\marginparwidth}{1.2in}
\let\oldmarginpar\marginpar
\renewcommand\marginpar[1]{\-\oldmarginpar[\raggedleft\footnotesize #1]%
{\raggedright\footnotesize #1}}
%



\newenvironment{solution}[1]{{\color{red}{}\ \\\noindent{}\sc
    \underline{Solution:}\\}#1}{\hfill{}\\\color{red}{\sc \underline{End of Solution}}}%$\clubsuit$}
   


%% Odds and Ends
\def\imp{\ \Rightarrow\ }
\def\d#1{\thinspace{\rm d}#1}
\def\dfdx#1#2{\frac{\text{d}{#1}}{\text{d}{#2}}} 
\def\abs#1{\left|#1\right|}
\def\limit#1#2#3{{\displaystyle\lim_{#1\rightarrow #2}#3}}

\def\LabelProblem#1#2{\label{#1}\addcontentsline{toc}{subsection}{\hskip1cm Problem~\ref{#1}}}

\newcommand{\eps}{\varepsilon}
\newcommand{\unif}{\stackrel{unif}{\longrightarrow}}
\newcommand{\ptwise}{\stackrel{ptwise}{\longrightarrow}}

\newcommand{\CC}{\mathbb {C}}
\newcommand{\DD}{\mathbb {D}}
\newcommand{\RR}{\mathbb {R}}
\newcommand{\QQ}{\mathbb {Q}}
\newcommand{\NN}{\mathbb {N}}
\newcommand{\ZZ}{\mathbb {Z}}


\newtheorem{problem}{Problem}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{example}{Example}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}{Lemma}


\pagestyle{headings}{}
 \makeindex{}
\begin{document}
\title{{\sc How We Got From There To Here:\\} A Story of Real
  Analysis\\ Solution Manual }
\author{Robert Rogers \\State University of New York \\at
  Fredonia\\[5mm]Eugene Boman \\The Pennsylvania State University \\Harrisburg campus}
\date{}
\maketitle
\newpage{}
\tableofcontents{}
%\nocite{*}

\part{In Which We Raise a Number of Questions}
\chapter*{Prologue: Three Lessons Before We Begin}
\label{sec:two-lessons-before}
\addcontentsline{toc}{chapter}{Prologue: Three Lessons Before We Begin}

\markboth{{\sc Prologue: Three Lessons}}{{\sc Prologue: Three Lessons}}

\pagestyle{myheadings}

\begin{problem}
\LabelProblem{prob:Quadratic Formula-Tartaglia's Method}{Quadratic
  Formula!First Alternate Method}
  As you saw when you filled in the details of our development of the
  Quadratic Formula\footnote{If you didn't fill in those details
    you're being stupid (or at least unduly stubborn). There is a good reason for putting these three
    lessons first. Stop wasting your time and intellect! Go do it
    now.} the substitution $x=y-\frac{b}{2a}$ was crucial because it
  turned 
$$
x^2+\frac{b}{a}x +\frac{c}{a}=0
$$
into
$$
y^2=k
$$
where $k$ depends only on $a,$ $b,$ and $c.$ In the sixteenth century
a similar technique was used by Ludovico Ferrari (1522-1565) to reduce
the general cubic equation
\begin{equation}
ax^3+bx^2+cx+d=0\label{eq:GenCubic}
\end{equation}
into the so-called ``depressed cubic''
$$
y^3 +py+q=0
$$
where $p,$ and $q$ depend only on $a,$ $b,$ $c,$ and $d.$ 

The general depressed cubic\footnote{It is not entirely clear why
  eliminating the quadratic term should be depressing, but there it
  is.} had previously been solved by Tartaglia (the Stutterer,
1500-1557) so converting the general cubic into a depressed cubic
provided a path for Ferrari to compute the ``Cubic Formula'' -- like the
Quadratic Formula but better. 

Ferrari also knew how to compute the general solution of the
``depressed quartic'' so when he and his teacher Girolomo Cardano
(1501-1576) figured out how to depress a general quartic they had a
complete solution of the general quartic as well. Alas, their methods
broke down entirely when they tried to solve the general quintic
equation. Unfortunately the rest of this story belongs in a course on
Abstract Algebra, not Real Analysis.  But the lesson in this story
applies to all of mathematics: Every problem solved is a new theorem
which then becomes a tool for later use. Depressing a cubic would have
been utterly useless had not Tartaglia had a solution of the depressed
cubic in hand. The technique they used, with slight modifications,
then allowed for a solution of the general quartic as well.

Keep this in mind as you proceed through this course and your
mathematical education. Every problem you solve is really a theorem, a
potential tool that you can use later. We have chosen the problems in
this text deliberately with this in mind. Don't just solve the
problems and move on. Just because you have solved a problem does not
mean you should stop thinking about it. Keep thinking about the
problems you've solved. Internalize them. Make the ideas your own so
that when you need them later you will have them at hand to use.


\begin{description}
\item[(a)] Find $M$ so that the substitution $x=y-M$ depresses
  equation~\ref{eq:GenCubic}, the general
  cubic equation. Then find $p$ and $q$ in terms of $a,$ $b,$ $c,$ and $d.$
\begin{solution}{}
Let $x=y-M.$  Then
\begin{align*}
  a(y^3&-3y^2M+3yM^2-M^3) +b(y^2-2yM+M^2) +cy-cM\\
  &= y^3 + \left(\frac{-3M}{a}+b\right)y^2 +
  \left(\frac{3M^2}{a}-\frac{2M}{b}+c\right)y - \frac{M^3}{a} +
  \frac{M^2}{b}-cM.\\
\end{align*}
Setting the coefficient of $y^2$ equal to zero and solving
  gives $M=\frac{ab}{3}.$

Since $p$ and $q$ are the coefficients of $y$ and the constant term
respectively we have 
\begin{align*}
  p&=\frac{3M^2}{a}-\frac{2M}{b}+c\\
   &=\frac{3\left(\frac{ab}{3}\right)^2}{a}-\frac{2\left(\frac{ab}{3}\right)}{b}+c\\
   &=\frac{ab^2}{3}-\frac{2a}{3}+c\\
   &=\frac13(ab^2-2a+3c),
\end{align*}
and
\begin{align*}
  q&=- \frac{M^3}{a} + \frac{M^2}{b}-cM\\
   &=- \frac{\left(\frac{ab}{3}\right)^3}{a} +
   \frac{\left(\frac{ab}{3}\right)^2}{b}-c\left(\frac{ab}{3}\right)\\
   &= \frac19(-ab^3-a^2b-3abc)
\end{align*}
\begin{align*}
%   ax^3+bx^2+cx+d&=0\\
%   a\left[x^3+\frac{b}{a}x^2+\frac{c}{a}x +\frac{d}{a}\right]&=0\\
%   a\left[(y-M)^3+\frac{b}{a}(y-M)^2+\frac{c}{a}(y-M)+\frac{d}{a}\right]&=0\\
%   a\left[(y^3-3y^2M+3yM^2-M^3)+\frac{b}{a}(y^2-2yM+M^2)+\frac{c}{a}(y-M)+\frac{d}{a}\right]&=0.\\  
% \intertext{The coefficient of $y^2$ in the above is $-3aM+b$ so we set $-3aM+b=0$
% and solve, giving $M-\frac{b}{2a}.$ Thus}
%   a\left[\left(y^3+(3M^2-\frac{2bM}{a}y+\frac{c}{a}\right) + \left(-M^3+\frac{b}{a}M^2-\frac{cM}{a}+\frac{d}{a}&=0\\
% y^3+\underbrace{\left(\frac{3b^2}{9a^2}-\frac{2b^2}{3a^2}+\frac{c}{a}\right)}_{=p}y
%   +\underbrace{\left(\frac{-b^3}{27a^3}+\frac{b^3}{9a^3}-\frac{cb}{3a^2}+\frac{d}{a}\right)}_{=q}
%                 &=0\\
% \intertext{and so}
%                   y^3+py+q&=0.
\end{align*}
\end{solution}
\item[(b)] Find $K$ so that the substitution $x=y-K$ depresses the
  general quartic equation. Make sure you demonstrate how you obtained that value or why it works (if you guessed it).
\begin{solution}{}
  In this case set $x=y-\frac{b}{4a}.$ 
\end{solution}
\item[(c)] Find $N$ so that the substitution $x=y-N$ depresses a
  polynomial of degree $n.$  Ditto on showing that this value works or showing how you obtained it.
\begin{solution}{}
 In general set $x=y-\frac{b}{na.}$ 
\end{solution}

\end{description}\xqed{\lozenge}{}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:Quadratic Formula-Lagrange's Method}{Quadratic Formula!Second Alternate Method}
Here is yet another way to solve a quadratic equation. Read the
development below with pencil and paper handy. Confirm all of the
computations that are not completely transparent to you. Then use your
notes to present the solution with \underline{all} steps filled
in.\footnote{Be sure you are clear on the purpose of this problem
  before you begin. This is not about solving the Quadratic
  Equation. You already know how to do that. Our purpose here is to
  give you practice filling in the skipped details of mathematical
  exposition. We've chosen this particular problem because it should
  be a comfortable setting for you, but this particular solution is
  probably outside of your previous experience.}

Suppose that $r_1$ and $r_2$ are solutions of $ax^2+bx+c=0.$ Suppose
further that $r_1\ge r_2.$ Then
\begin{align*}
  ax^2+bx+c &= a(x-r_1)(x-r_2)\\
  &= a\left[x^2-(r_1+r_2)x+(r_1+r_2)^2-(r_1-r_2)^2-3r_1r_2\right].\\
\end{align*}
Therefore
\begin{align}
  \label{eq:LagrangeQuadratic1}
  r_1+r_2&= -\frac{b}{a}\\
\intertext{and}
  \label{eq:LagrangeQuadratic2}  r_1-r_2 &= \sqrt{\left(\frac{b}{a}\right)^2-\frac{4c}{a}}.
\end{align}

Equations~\ref{eq:LagrangeQuadratic1} and~\ref{eq:LagrangeQuadratic2}
can be solved simultaneously to yield
\begin{align*}
  r_1&=\frac{-b+\sqrt{b^2-4ac}}{2a}\\
  r_2&=\frac{-b-\sqrt{b^2-4ac}}{2a}.
\end{align*}
\xqed{\lozenge}{}
\begin{solution}{}
Suppose that $r_1$ and $r_2$ are solutions of $ax^2+bx+c=0.$ Suppose
further that $r_1\ge r_2.$ Then since $r_1$ and $r_2$ are solutions,
\begin{align*}
  ax^2+bx+c &= a(x-r_1)(x-r_2) \\
  a\left(x^2+\frac{b}{a}x+\frac{c}{a}\right) &= a(x^2-(r_1+r_2)x + r_1r_2)\\
\end{align*}
Therefore
\begin{equation}
r_1+r_2= -\frac{b}{a}\label{eq:LagrangeQuadratic3}
\end{equation}
and $r_1r_2=\frac{c}{a}.$
Proceeding we have
$$
a\left(x^2+\frac{b}{a}x+\frac{c}{a}\right)  = a\left[x^2-(r_1+r_2)x+\underbrace{(r_1+r_2)^2-(r_1-r_2)^2-3r_1r_2}_{=r_1r_2}\right]
% &= a\left(x^2-(r_1+r_2)x+(r_1^2+2r_1r_2+r_2^2)-(r_1^2-2r_1r_2+r_2^2)-3r_1r_2\right)\\
% &= a\left(x^2-(r_1+r_2)x+(r_1+r_2)^2-(r_1-r_2)^2-3r_1r_2\right).\\
% \intertext{So}
% x^2+\frac{b}{a}x+\frac{c}{a} &= x^2-(r_1+r_2)x+\left[(r_1+r_2)^2-(r_1-r_2)^2-3r_1r_2\right]
$$
Therefore
\begin{align}
%  \label{eq:LagrangeQuadratic3}
\frac{c}{a} &= (r_1+r_2)^2-(r_1-r_2)^2-3r_1r_2\nonumber\\
  &= \frac{b^2}{a^2}-(r_1-r_2)^2-3r_1r_2.\nonumber\\
\intertext{Solving for $(r_1-r_2)^2,$  gives}
(r_1-r_2)^2 &= \frac{b^2}{a^2}-\frac{c}{a}-3\frac{c}{a}\nonumber\\
          &= \frac{b^2}{a^2}-4\frac{c}{a}\nonumber \\
(r_1-r_2)^2 &= \frac{b^2-4ac}{a^2}.\nonumber
\end{align}
Since  $r_1\ge r_2,$ we get
\begin{equation}
\label{eq:LagrangeQuadratic4}
  r_1-r_2 =
  \sqrt{\left(\frac{b}{a}\right)^2-\frac{4c}{a}}.
\end{equation}

Equations~\ref{eq:LagrangeQuadratic3} and~\ref{eq:LagrangeQuadratic4}
can be solved simultaneously to yield
\begin{align*}
  r_1&=\frac{-b+\sqrt{b^2-4ac}}{2a}\\
  r_2&=\frac{-b-\sqrt{b^2-4ac}}{2a}.
\end{align*}
\xqed{\lozenge}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:PrimeDivideTwoProduct}{}
Let $p$ be a prime number and $a, b$ positive integers such that $p\, |
(a\cdot b).$ Show that $p\,|a$ or $p\,|b.$ [Hint: If $p\,|a$ then we are
done.  If not then notice that $p$ is a prime factor of $a\cdot b$.
What does the Fundamental Theorem of Arithmetic say about the prime
factors of $a\cdot b$ compared to the prime factors of $a$ and $b?$]

\begin{solution}
  Suppose that $p$ is prime, that $a,b\in\NN$ and that $p\, |
  (a\cdot b).$

  \noindent{}{\bf{}To Show:} Either $\divides{p}{a}$ or
  $\divides{p}{b}$.
  
  \begin{description}
  \item[Case 1, $\divides{p}{a}$:] If $\divides{p}{a}$ then we are
    done.
  \item[Case 2, $\notdivide{p}{a}$:]  Suppose that
    $\notdivide{p}{a}.$\\
    \noindent{}{\bf To show:} $\notdivide{p}{a}\imp\divides{p}{b}.$\\
    \proof{
      Let
      \begin{align*}
        a&=p_1p_2\ldots p_n \text{ and}\\
        b&=q_1q_2\ldots q_m \text{ so that}\\
        ab&=(p_1p_2\ldots p_n)(q_1q_2\ldots q_m).
      \end{align*}
     }
    \end{description}
    Since $\divides{p}{ab}$ either $p=p_i$ for some $i,$ $1\le i\le
    n$ or $p=q_j$ for some $j,$ $1\le j\le m.$
    
    Since $\notdivide{p}{a}$ $p\neq p_i\  \forall\,
    i=1,\ldots,n.$
    
    Therefore $p=q_j$ for some $j, 1\le j\le m.$
    
    Therefore $\divides{a}{b}.$ 
\end{solution}

\newpage{}
\end{problem}


\begin{problem}
\LabelProblem{prob:PrimeDivideMultiProduct}{}
Let $p$ be a prime number and let $a_1, a_2, \ldots, a_n$ be positive
integers such that $p\,|\left(a_1\cdot a_2\cdot a_3\cdot\ldots\cdot
  a_n\right).$ Show that $p\,|a_k$ for some $k\in\{1, 2, 3, \ldots, n\}.$
[Hint: Use induction on $n$ and the result of the previous problem.]

\begin{solution}
  \underline{Proof by Induction:}
  
\underline{Base Case:} Supose $a=a_1.$ Then
$\divides{p}{a}\imp\divides{p}{a_1}.$  

\underline{Induction Hypothesis:} If
$\divides{p}{(a_1a_2\ldots a_{n-1})}$ then $\divides{p}{a_k}$ for some
$k\in\left\{1, 2, \ldots, n-1\right\}$

Supose $\divides{p}{[(a_1a_2\ldots a_{n-1})a_n]}.$ Then by
Problem~\ref{prob:PrimeDivideTwoProduct} 
$\divides{p}{(a_1a_2\ldots a_{n-1})}$ or  $\divides{p}{a_n}.$

Therefore $\divides{p}{a_k},$ $k\in\left\{1, 2, \ldots, n-1\right\}$
by our Induction Hypothesis, or $\divides{p}{a_n}.$ 

Therefore $\divides{p}{a_k},$ $k\in\left\{1, 2, \ldots, n\right\}$
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:NeedsALabel}{} 
Let $p$ be a prime number and let $k$ be an integer with $1\le k\le p-1.$
Prove that $p\left|{p \choose{}k}\right.$, where ${p \choose{}k}$ is the
binomial coefficient $\frac{p!}{k!(p-k)!}.$ [Hint: We know $p\,|p\,!,$
so $p\,|{p \choose{}k}k!(p-k)!.$ How does the previous result apply?]

\begin{solution}
  Since ${p\choose k} = \frac{p!}{k!(p-k)!}$ we have $p!={p\choose
  k}k!(p-k)!.$ Clearly $\divides{p}{p!}.$ Therefore 
\(
\divides{p}{{p\choose k} k! (p-k)!}.
\)

Thus by problem~\ref{prob:PrimeDivideMultiProduct}, either
\begin{align*}
  &\divides{p}{{p \choose k}} \\
\intertext{or}
  &\divides{p}{k!} \\
\intertext{or}
  &\divides{p}{(p-k)!}.
\end{align*}
Observe that every factor of $k!$ is less than $p.$ Thus since $p$ is prime
$\notdivide{p}{k!}.$ \hfill{}

Similarly $\notdivide{p}{(p-k)!}.$

Therefore $\divides{p}{{p\choose k}}.$
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
 \LabelProblem{prob:FermatsLittleTheorem}{} 
 Prove Fermat's Little Theorem.  [Hint: Use induction on $n.$ To get
 from $n$ to $n+1,$ use the binomial theorem on $(n+1)^p.$]

   \begin{solution}
     \underline{\bf{}Proof by Induction:}

\noindent{}     \underline{\bf{}Base Case:} If $n=1$ then
     $n^p-n=1-1=0$ so $\divides{p}{n^p-n}$ when $n=1.$

\noindent{}     \underline{\bf{}Induction Hypothesis:} Suppose
       $\divides{p}{n^p-n}.$

       Observe that 
       \[
       (n+1)^p = n^p + \underbrace{{p \choose p-1}n^{p-1} + \ldots + {p\choose
         2}n^2+{p\choose1}n}_{=  \sum_{k=1}^{p-1}{p\choose k}n^k} +1.
       \]
       Therefore 
       \begin{align*}
       (n+1)^p-(n+1) &= n^p + \sum_{k=1}^{p-1}{p\choose k}n^k +1
       -(n+1).\\
       (n+1)^p-(n+1) &= (n^p-n) + \sum_{k=1}^{p-1}{p\choose k}n^k.
       \end{align*}
     By our Induction Hypothesis, $$\divides{p}{n^p-n}$$ and 
       by problem~\ref{prob:NeedsALabel} $p$ divides each term of 
       $$
       \sum_{k=1}^{p-1}{p\choose k}n^k.
       $$
Therefore $\divides{p}{(n+1)^p-(n+1)}$. 
   \end{solution}
\newpage{}
\end{problem}

\chapter{Numbers, Real ($\RR$) and Rational ($\QQ$)}
\label{cha:numb-real-rati}
\markboth{{\sc Numbers, Real And Rational}}{{\sc Numbers, Real And Rational}}



\begin{problem}
\LabelProblem{prob:rationals between rationals}{Rationals Between Rationals}
  Let $a, b, c, d\in\NN$ and find a rational number between $a/b$ and
  $c/d.$  

   \begin{solution}{}
     There are two cases:
     \begin{description}
     \item[Case 1 $\left(\frac{a}{b} < \frac{c}{d}\right):$] 
       In this case $\frac{c}{d} - \frac{a}{b} > 0$ so
\[
         \frac{a}{b} < \frac{a}{b} + \frac12\left(\frac{c}{d} -
           \frac{a}{b}\right) \text{ and }
         \frac{c}{d} > \frac{c}{d} - \frac12\left(\frac{c}{d} - \frac{a}{b}\right).
\]
       Moreover
       \[  \frac{a}{b} + \frac12\left(\frac{c}{d} -  \frac{a}{b}\right) =
       \frac12\left(\frac{c}{d}+\frac{a}{b}\right) =\frac{c}{d} -
       \frac12\left(\frac{c}{d} - \frac{a}{b}\right). \]
       Therefore
       \[\frac{a}{b} < \frac12\left(\frac{c}{d}+\frac{a}{b}\right) <
       \frac{c}{d}.\]
       Finally, \(\frac12\left(\frac{c}{d}+\frac{a}{b}\right)\) is rational
       since 
       \[\frac12\left(\frac{c}{d}+\frac{a}{b}\right) =
       \frac{bc-ad}{2bd}\]
       and \(bc-ad\) and \(2bd\) are integers.
     \item[Case 2 $\left(\frac{c}{d} < \frac{a}{b}\right):$] 
       The proof of this case is similar. Just reverse the roles of
       \(\frac{a}{b}\) and \(\frac{c}{d}.\)
     \end{description}
   \end{solution}

\xqed{\lozenge}{}
 \newpage{}
\end{problem}

\begin{theorem}
\label{thm:CommonDenominatorsExist}
\IndexTheorem{thm:CommonDenominatorsExist}{}
  Let $a, b, c,$ and $ d$ be integers. There is a number
  $\alpha\in\QQ$ such that $M\alpha=a/b$ and $N\alpha=c/d$ where $M$
  and $N$ are also integers.\xqed{\blacktriangle}{}
\end{theorem}
\begin{proof}
  To prove this theorem we will display $\alpha,$ $M$ and $N.$ It is
  your responsibility to confirm that these actually work. Here they
  are: $\alpha=1/bd,$ $M=ad,$ and $N=cb.$
\end{proof}
\hrule{}
\begin{problem}
\LabelProblem{prob:common denominators}{Common Denominators}
  Confirm that $\alpha, M, \text{ and } N$ as given in the proof of
  theorem~\ref{thm:CommonDenominatorsExist} satisfy the requirements
  of the theorem.

   \begin{solution}{}
     \begin{align*}
       M\alpha &= ad\left(\frac{1}{bd}\right) = \frac{a}{b}\\
       N\alpha &= cb\left(\frac{1}{bd}\right) = \frac{c}{d}.
     \end{align*}
   \end{solution}
 
\xqed{\lozenge}{}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:irrational numbers}{irrational numbers}
  Show that each of the following numbers is irrational:
  \begin{solution}{}
    \begin{description}
    \item[(a)] $\sqrt{3}$

      \begin{proof}[by Contradiction]

        Suppose that \(\sqrt{3}=\frac{a}{b}, a,b\in\NN,\)
        where \(\frac{a}{b}\)
        is in lowest terms. Then \[ 3b^2=a^2,\]
        which implies that \(\divides{3}{a^2},\)
        which implies that \(\divides{3}{a}\) (why?).

        Therefore \(a=3k\) for some integer, $k.$ Therefore
        \begin{align*}
          3b^2 &= 9k^2\\
          b^2 &= 3k^2,
        \end{align*}
        which implies that \(\divides{3}{b^2},\)
        which implies that \(\divides{3}{b}\) (why?).

        Therefore, since \(\divides{3}{a}\)
        and \(\divides{3}{b}\)
        \(\frac{a}{b}\)
        is not in lowest terms, which is a contradiction.

        Therefore \(\sqrt{3}\) is irrational.
      \end{proof}
    \item[(b)] $\sqrt{5}$

      \begin{proof}[by Contradiction]

        Suppose that \(\sqrt{5}=\frac{a}{b}, a,b\in\NN,\)
        where \(\frac{a}{b}\)
        is in lowest terms. Then \[ 5b^2=a^2,\]
        which implies that \(\divides{5}{a^2},\)
        which implies that \(\divides{5}{a}\) (why?).

        Therefore \(a=5k\) for some integer, $k.$ Therefore
        \begin{align*}
          5b^2 &= 25k^2\\
          b^2 &= 5k^2,
        \end{align*}
        which implies that \(\divides{5}{b^2},\)
        which implies that \(\divides{5}{b}\) (why?).

        Therefore, since \(\divides{5}{a}\)
        and \(\divides{5}{b}\)
        \(\frac{a}{b}\)
        is not in lowest terms, which is a contradiction.

        Therefore \(\sqrt{5}\) is irrational.
      \end{proof}
    \item[(c)] $\sqrt[3]{2}$

      \begin{proof}[by Contradiction]

        Suppose that \(\sqrt[3]{2}=\frac{a}{b}, a,b\in\NN,\)
        where \(\frac{a}{b}\)
        is in lowest terms. Then \[ 2b^3=a^3,\]
        which implies that \(\divides{2}{a^3},\)
        which implies that \(\divides{2}{a}\) (why?).

        Therefore \(a=2k\) for some integer, $k.$ Therefore
        \begin{align*}
          2b^3 &= 8k^3\\
          b^3 &= 4k^3,
        \end{align*}
        which implies that \(\divides{2}{b^3},\)
        which implies that \(\divides{2}{b}\) (why?).

        Therefore, since \(\divides{2}{a}\)
        and \(\divides{2}{b}\)
        \(\frac{a}{b}\)
        is not in lowest terms, which is a contradiction.

        Therefore \(\sqrt[3]{2}\) is irrational.
      \end{proof}
    \item[(d)] $i (=\sqrt{-1})$

      \begin{proof}[by Contradiction]

        Suppose that \(i=\frac{a}{b},\ a,b\in\NN.\)
        Then \(i^2=\frac{a^2}{b^2}\)
        which is impossible since \(\frac{a^2}{b^2}\)
        is positive, but \(i^2\) is negative.

        Therefore \(i\) is irrational.
      \end{proof}
    \item[(e)] The square root of every positive integer which is not
      the square of an integer.

    \begin{proof}
      This problem can be restated as: If $n\in\NN$ then $\sqrt{n}$ is
      either an integer or it is irrational.

      We will prove the contrapositive: If $\sqrt{n}=\frac{a}{b},$
      where $ a,b\in\NN,$ $b\neq 1,$ then $n\not\in\NN.$

      We assume that $\frac{a}{b}$ is in lowest terms so that $a$ and
      $b$ have no prime factors in common. Therefore $a^2$ and $b^2$
      also have no prime factors in common, so that
      $n=\frac{a^2}{b^2}$ is also in lowest terms. Since $b^2\neq1,$
      $n\not\in\NN.$
    \end{proof}
  \end{description}
\end{solution}
\xqed{\lozenge}{}

\newpage{}
\end{problem}

\begin{theorem}\ 
\label{thm:IrrationalBetweenIrrationals}
\IndexTheorem{thm:IrrationalBetweenIrrationals}{}
  \begin{description}
  \item[(a)] Between any two real numbers there is a rational number.
  \item[(b)] Between any two real numbers there is an irrational number.\xqed{\blacktriangle}{}
  \end{description}
\end{theorem}
\hrule{}
\begin{problem}\ 
\LabelProblem{prob:ProductRationalIrrational}{product of a rational
  and an irrational}
\begin{description}
\item[(a)] Prove that the product of a nonzero rational number and an
  irrational number is irrational.
  \begin{solution}{}
    \begin{proof}
      The proof is by  contradiction, so
      suppose $\alpha$ is rational, $\beta$ is irrational and
      \(\alpha\beta\)
      is rational. Since $\alpha$ is rational we have \(\alpha=a/b\)
      for some \( a,b\in\NN.\)
      Similarly, since \(\alpha\beta\)
      is rational we have \(\alpha\beta = c/d\)
      for some \( c,d\in\NN.\)

      Therefore
      \begin{align*}
        \alpha\beta &= c/d\\
        (a/b) \beta &= c/d\\
        \beta &= (bc)/(ad).
      \end{align*}
      Therefore $\beta$ is rational. This is a contradiction since we
      assumed that $\beta$ was irrational.

    \end{proof}
  \end{solution}
\item[(b)] Turn the above ideas into a proof of
  Theorem~\ref{thm:IrrationalBetweenIrrationals}.\xqed{\lozenge}

  \begin{solution}{}
    \begin{description}
    \item[(a)] Between any two real numbers there is a rational
      number.\\
      \begin{proof}
        Let $\alpha$ and $\beta$ be real numbers with \(\alpha <
        \beta.\)

        \noindent{\bf Case 1:} \(\beta-\alpha>1.\)\\
        In this case there is an integer $k,$ such that
        \(\alpha<k<\beta.\) Since all integers are rational we are
        done.

        \noindent{\bf Case 2:} \(\beta-\alpha\le1.\)\\
        In this case, by the Archimedean Property there is an integer,
        \(n\) such that \(n(\beta-\alpha)>1.\) By Case 1 there is an
        integer, \(k,\) such that
        \begin{align*}
          n\alpha&<k<n\beta\\
\intertext{so that}
          \alpha&<k/n<\beta.
        \end{align*}
        Since \(k/n\) is rational, we are done.
      \end{proof}
    \end{description}
  \item [(b)] Between any two real numbers there is an irrational
      number.\\
      \begin{proof}
        Let $\alpha$ and $\beta$ be as before and suppose that \(p>0\)
        is irrational. By part (a) of Theorem~3 there is a rational
        number, say \(q,\) such that
        \begin{align*}
          p\alpha&<q<p\beta\\
          \intertext{and so}          
         \alpha&<q/p<\beta.
        \end{align*}
        By part (a) of this problem $q/p$ is irrational so we have
        found an irrational number between $\alpha$ and $\beta.$

        % (Strictly speaking we need to first show that the reciprocal
        % of an irrational number is also irrational, but this is
        % trivial.)
      \end{proof}
  \end{solution}
\end{description}
\newpage{}
\end{problem} 

\begin{problem}
\LabelProblem{prob:sums and products of rational and irrational
  numbers}{sums and products of rational and irrational
  numbers}
Determine if each of the following is always rational or always irrational. Justify your answers.
  \begin{description}
  \item[(a)] The sum of two rational numbers.

    \begin{solution}{}
      The sum of two rational numbers is also rational.\\
      \begin{proof}
        Let \(a, b, c, d\in\NN\) and form the rational numbers,
        \(a/b\) and \(c/d.\) Then
        \[\frac{a}{b}+\frac{c}{d} = \frac{ad+bc}{bd}\in\QQ.\]
      \end{proof}
    \end{solution}
  \item[(b)] The sum of two irrational numbers.

    \begin{solution}{}
      The sum of two irrational numbers, may be rational or irrational
      since \(\sqrt{2}+\sqrt{2} = 2\sqrt{2}\) is irrational, whereas
      \(\sqrt{2}+(-\sqrt{2}) = 0\) is rational.
    \end{solution}
  \item[(c)] The sum of a rational and an irrational number.
    \begin{solution}{}
      The sum of a rational and an irrational number will always be
      irrational. \\
      \begin{proof}
        Suppose \(q\in\QQ\) and $\alpha$ is irrational, and suppose
        that \(q+\alpha=p\in\QQ.\) Then \(\alpha=p-q\in\QQ\) which
        contradicts our assumption that $\alpha$ is irrational. 

        Therefore the sum of a rational and an irrational number will
        always be irrational.
      \end{proof}
    \end{solution}

\xqed{\lozenge}{}
  \end{description}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:creating irrationals from rationals}{creating irrationals from rationals}
  Is it possible to have two rational numbers, $a$ and $b,$ such that
  $a^b$ is irrational. If so, display an example of such $a$ and $b.$
  If not, prove that it is not possible.

    \begin{solution}{}
      Yes. Let \(a=2\) and \(b=1/2.\)
    \end{solution}

\xqed{\lozenge}{}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:creating rationals from irrationals}{creating rationals from irrationals}
  Decide if it is possible to have two irrational numbers, $a$ and $b,$ such that
  $a^b$ is rational. Prove it in either case.

   \begin{solution}{}
     Let $a=b=\sqrt{2}$ and observe that $\sqrt{2}$ is
     irrational. There are two cases:
     \begin{description}
       \item[Case 1:] $\left(\sqrt{2}\right)^{\sqrt{2}}$ is rational. \\
         Since
         $\sqrt{2}$ is known to be irrational we are done.
       \item[Case 2:] $\left(\sqrt{2}\right)^{\sqrt{2}}$ is irrational. \\
         In this case we have 
         \[\left(\left(\sqrt{2}\right)^{\sqrt{2}}\right)^{\sqrt{2}} =
         2.\] Since both $\left(\sqrt{2}\right)^{\sqrt{2}}$ and
         $\sqrt{2}$ are known to be irrational we are done. 
     \end{description}
   \end{solution}
 
\xqed{\lozenge}{}
\newpage{}
\end{problem}

\chapter{Calculus in the 17th and 18th Centuries}
\label{chpt:17thCentury}
\label{sec:leibn-calc-rules}
\markboth{{\sc Calculus In The 17th And 18th Centuries}}{{\sc Calculus In The 17th And 18th Centuries}}

\begin{problem}\ 
\LabelProblem{prob:Leibniz product rule}{}
  \begin{description}
  \item[(a)] Use Leibniz's product rule
$\d \left(xv\right)=x\d v+v\d x$ to show that if $n$ is a positive integer
then $\d \left(x^n\right)=nx^{n-1}\d x$
\begin{solution}{}
  \begin{proof} 
    Our proof is by induction.
    \begin{description}
    \item[\underline{Base Case:}] Supose
      \begin{align*}
        y&=x^2.\\
        \intertext{Then}
        y&=x\cdot x\\
        \intertext{so that by the Product Rule,}
        \d y &= x\d x + x\d x\\
             &= 2x\d x.
      \end{align*}
    \item[\underline{Induction Hypothesis:}] Next assume that if $y=x^{n-1}$ then
      $\d y = (n-1)x^{n-2}.$ 
      So if
      \begin{align*}
        y&= x^n = x^{n-1}\cdot x\\
        \intertext{we have by the Product Rule,}
        \d y&= x^{n-1}\d x + x\d\left(x^{n-1}\right)\\
            &= x^{n-1}\d x + x(n-1)x^{n-2}\d x\\
            &= nx^{n-1}.
      \end{align*}
Therefore if $n$ is a positive integer
then $\d \left(x^n\right)=nx^{n-1}\d x$
  \end{description}

  \end{proof}

\end{solution}
\item[(b)] Use Leibniz's product rule to derive the quotient rule
$$\d \left(\frac{v}{y}\right)=\frac{y\,\d v-v\,\d y}{yy}.$$
\begin{solution}{}
  First we compute $\d \left(\frac{1}{y}\right).$ Observe that
  \begin{align*}
    0&=\d\left(\frac{y}{y}\right)\\
     &=\d\left(y\cdot\frac{1}{y}\right).\\
\intertext{By the Product Rule we have}
    &= y\d\left(\frac{1}{y}\right)+\frac{1}{y}\d y\\
\intertext{so that }    
    -y\d\left(\frac{1}{y}\right) &= \frac{1}{y}\d y\\
\intertext{and}
    \d\left(\frac{1}{y}\right) &= \frac{-1}{y^2}\d y.
  \end{align*}
Next observe that
\begin{align*}
  \d\left(\frac{v}{y}\right) &= \d\left(v\cdot\frac{1}{y}\right)\\
\intertext{so that, by the Product Rule,}
  \d\left(\frac{v}{y}\right) &= v\d\left(\frac{1}{y}\right) +
                               \frac{1}{y}\d v\\
                             &= v\left( \frac{-1}{y^2}\d y \right) +
                               \frac{1}{y}\d v\\
                             &= \d \left(\frac{v}{y}\right)=\frac{y\,\d v-v\,\d y}{yy}.
\end{align*}
\end{solution}
\item[(c)]  Use the quotient rule to show that if $n\,$is a positive integer,
then 
$$\d \left(x^{-n}\right)=-nx^{-n-1}\d x.\xqedhere{1.48in}{\lozenge}{}$$
\begin{solution}
  \begin{align*}
    \d \left(x^{-n}\right)&=\d \left(\frac{1}{x^n}\right)\\
    &= \frac{x^n\d(1) - 1\d(x^n)}{x^{2n}}\\
    &= \frac{-nx^{n-1}\d x}{x^{2n}}\\
    &= -nx^{n-1-2n}\d x\\
    &= -nx^{-n-1}\d x.
  \end{align*}
\end{solution}
\end{description}

\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:power rule with fractional exponents}{}
 Let $p$ and $q$ be integers with $q\neq 0$.  Show 
$\d \left(x^{\frac{p}{q}}\right)=\frac{p}{q}x^{\frac{p}{q}-1}\d x$\xqed{\lozenge}{}
\begin{solution}{}
Let
\begin{align*}
  y&=x^{p/q}
\intertext{and suppose we wish to find $\d y.$  In that case we have}
  y^q&=x^p.\\
\intertext{Taking the differential of both sides gives, since $p$ and
  $q$ are integers:}
qy^{q-1}\d y &= px^{p-1}\d x.\\
\intertext{As before the expression $\d y$ appears in our formula and
  is easy to solve for. So we solve:}
\d y &= \frac{px^{p-1}\d x}{qy^{q-1}}\\
&=\frac{p}{q}\left(\frac{x^{p-1}}{y^{q-1}}\right)\d x.\\
\intertext{Since $y=x^{\frac{p}{q}}$ we see that $
  y^{q-1}=x^{\frac{p(q-1)}{q}} $ so that $\frac{x^{p-1}}{y^{q-1}} =
  \frac{x^{p-1}}{x^{\frac{p(q-1)}{q}}} = x^{\left[(p-1)-\left(\frac{p(q-1)}{q}\right)\right]}
  = x^{\left[\frac{q(p-1)}{q}-\frac{p(q-1)}{q}\right]}=
  x^{\frac{-q+p}{q}} = x^{\frac{p}{q}-1}.$ Substituting this into the
  equation above gives:}
\d y &=\frac{p}{q}x^{\frac{p}{q}-1} \d x\\
\end{align*}  
\end{solution}
\newpage{}
\end{problem}

\begin{align}
\label{eq:Brachistochrone}
%   \frac{\sin\alpha}{v} &= c\notag\\
% \intertext{and since $\sin\alpha = \frac{d x}{d s}$   we see that}
% \frac{\frac{d x}{d s}}{\sqrt{2gy}} &= c\notag\\
% \frac{d x}{\sqrt{2gy(ds)^2}} &= c\notag\\
% \frac{d x}{\sqrt{2gy\left[(d x)^2+(d y)^2\right]}} &= c.
\end{align}

\begin{problem}
\LabelProblem{prob:Brachistrochrone solution}{}
  Show that the equations $x=\frac{t-\sin t}{4gc^2},\,y=\frac{1-\cos
    t}{4gc^2}$ satisfy equation~\ref{eq:Brachistochrone}. Bernoulli
  recognized this solution to be an inverted cycloid, the curve traced
  by a fixed point on a circle as the circle rolls along a horizontal
  surface.

    \begin{solution}{}
      \begin{align*}
        \frac{\d x}{\sqrt{2gy\left[{\d x}^2+{\d y}^2\right]}} 
         &= 
          \frac{\d t-\cos t\d t}
                {4gc^2
                  \sqrt{
                    2g\frac{1-\cos t+1}{4gc^2}
                     \left[\frac{{\d t}^2(1-2\cos
                         t+1)}{(4gc^2)^2}\right]}}\\
         &=
          \frac{\d t(1-\cos t}{\frac{\d t}{c}\sqrt{\frac{1-\cos
                t}{2}(2-2\cos t)}}\\
         &=\frac{\d t(1-\cos t)}{\frac{\d t}{c}\sqrt{(1-\cos t)^2}}\\
         &=c.
      \end{align*}
    \end{solution}
\xqed{\lozenge}{}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:ExpProp3}{}
  Prove Property 3: If \(m\in\NN\) and \(x\in\RR\) then \(E(mx) =
  \left(E(x)\right)^m.\)
  \begin{solution}{}
    \noindent{}\begin{proof}
      Proof by Induction:\\
      \noindent{\bf Base Case:} By Property~2 \(E(x+x) = E(x)E(x) =
      (E(x))^2.\)\\
      \noindent{\bf Induction Hypothesis:} If \(m\in\NN\) and
      \(x\in\RR\) then \(E((m-1)x) = \left(E(x)\right)^{m-1}.\)
      
      \begin{align*}
        E(mx) &= E((m-1)x + x)\\
        &= E((m-1)x)E(x) \text{ by Property 2}\\
    &= E(x)^{m-1}E(x) \text{ by our Induction Hypothesis.}\\
    \intertext{Therefore} E(mx) &= \left(E(x)\right)^m.
  \end{align*}
  
\end{proof}
\end{solution}
\xqed{\lozenge}{}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:ExpProp4}{}
 Prove Property 4: \(E(-x) = \frac{1}{E(x)}.\)\xqed{\lozenge}{}
 \begin{solution}{}
   \begin{proof}
     Observe that
     \begin{align*}
       1&=E(0)\\
       &=E(x+(-x)) \\
       &=E(x)E(-x) \text{ by Property 2.}\\
       \intertext{Therefore} E(-x) &= \frac{1}{E(x)}.
     \end{align*}
   \end{proof}
 \end{solution}
\newpage{}
\end{problem}

  \begin{problem}
    \LabelProblem{prob:ExpProp5}{}
    Prove Property 5: If \(n\) is an integer with \(n\neq 0\) then
    \[E\left(\frac{1}{n}\right) = \left(E(1)\right)^\frac1n\]

\begin{solution}{}
  \begin{proof}
    Observe that
    \begin{align*}
      E(1) &= E\left(\frac{n}{n}\right)\\
      &= E\left(n\cdot\frac{1}{n}\right)\\
      &= E\left(\frac{1}{n}\right)^{n} \text{ by Property 3.}
      \intertext{Therefore} E\left(\frac{1}{n}\right) &=
      \left(E(1)\right)^\frac1n.
    \end{align*}
    
  \end{proof}
  \xqed{\lozenge}{}
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:ExpProp6}{}
  Prove Property 6: If \(m\) and \(n\) are integers with \(n\neq 0,\)
  then
\[
E\left(\frac{m}{n}\right) = \left(E(1)\right)^{\frac{m}{n}}.
\]

\begin{solution}{}
  \begin{proof}
    Observe that
    \begin{align*}
      E\left(\frac{m}{n}\right) &= E\left(m\cdot\frac{1}{n}\right) \\
      &= E\left(\frac{1}{n}\right)^m \text{ by Property 3}\\
      &= \left(E(1)^\frac{1}{n}\right)^m \text{ by Property 5}\\
      &= \left(E(1)\right)^{\frac{m}{n}}.
    \end{align*}
  \end{proof}
  \xqed{\lozenge}{} 
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:trig functions as solutions of IVP}{}
\begin{description}
\item[(a)] 
Show that if $y=\sum_{n=0}^\infty a_nx^n$ satisfies the
differential equation  $\frac{\d^2y}{\d x^2}=-y$, then 
$$
a_{n+2}=\frac{-1}{\left(n+2\right)\left(n+1\right)}\,a_n
$$
and conclude that 
$$
y=a_0+a_1x-\frac{1}{2!}\,a_0x^2-\frac{1}{3!}\,a_1x^3+\frac{1}{4!}\,a_0x^4+%
\frac{1}{5!}\,a_1x^5-\frac{1}{6!}\,a_0x^6-\frac{1}{7!}\,a_1x^7+\cdots.
$$
\begin{solution}{}
If   $\displaystyle y=\sum_{n=0}^\infty a_nx^n$ then $\displaystyle\frac{\d^2y}{\d
  x^2}=\sum_{n=2}^\infty n(n-1) a_nx^{n-2}$ so that
\begin{align*}
  \frac{\d^2y}{\d x^2}&=-y\\
  \sum_{n=2}^\infty n(n-1) a_nx^{n-2} &= \sum_{n=0}^\infty a_nx^n\\
  \sum_{n=2}^\infty n(n-1) a_nx^{n-2} - \sum_{n=0}^\infty a_nx^n &=0\\
  \sum_{n=0}^\infty (n+2)(n+1)a_{n+2}x^n - \sum_{n=0}^\infty a_nx^n &=0\\
  \sum_{n=0}^\infty \left[(n+2)(n+1)a_{n+2} -  a_n\right]x^n &=0.\\
\end{align*}
Therefore
$$
(n+2)(n+1)a_{n+2} -  a_n =2
$$
or
$$
a_{n+2}=\frac{-1}{\left(n+2\right)\left(n+1\right)}\,a_n
$$
as required.
\end{solution}

\item[(b)] Since $y=\sin x$ satisfies  $\frac{\d^2y}{\d  x^2}=-y$,
  we see that
$$
\sin x=a_0+a_1x-\frac{1}{2!}\,a_0x^2-\frac{1}{3!}\,a_1x^3+\frac{1}{4!}\,a_0x^4+%
\frac{1}{5!}\,a_1x^5-\frac{1}{6!}\,a_0x^6-\frac{1}{7!}\,a_1x^7+\cdots
$$
for some constants $a_0$ and $a_1$.  Show that in this case $a_0=0$ and
$a_1=1$ and obtain 
$$
\sin x=x-\frac{1}{3!}\,x^3+\frac{1}{5!}x^5-\frac{1}{7!}x^7+\cdots=\sum_{n=0}^%
\infty\frac{\left(-1\right)^n}{\left(2n+1\right)!}x^{2n+1}.\xqedhere{.5in}{\lozenge}
$$
\end{description}
\begin{solution}{}
Evaluating 
$$
  \displaystyle\sin x = a_0+a_1x-\frac{1}{2!}a_0x^2-\frac{1}{3!}\,a_1x^3+\frac{1}{4!}\,a_0x^4+%
  \frac{1}{5!}\,a_1x^5-\frac{1}{6!}\,a_0x^6-\frac{1}{7!}\,a_1x^7+\cdots,
$$
at $x=0$ gives
\begin{align*}
  \displaystyle\sin(0) &=
  a_0+a_1(0)-\frac{1}{2!}a_0(0)^2-\frac{1}{3!}a_1(0)^3+\frac{1}{4!}a_0(0)^4+%
  \frac{1}{5!}a_1(0)^5-\frac{1}{6!}a_0(0)^6-\frac{1}{7!}a_1(0)^7+\cdots\\
\intertext{or}
  0&=a_0
\end{align*}
Differentiating both sides and evaluating at $x=0$ will give $a_1=1.$ Thus
$$
  \sin x=x-\frac{1}{3!}\,x^3+\frac{1}{5!}x^5-\frac{1}{7!}x^7+\cdots=\sum_{n=0}^%
\infty\frac{\left(-1\right)^n}{\left(2n+1\right)!}x^{2n+1}.
$$
\end{solution}
\newpage{}
\end{problem}

\begin{problem}\ 
\LabelProblem{prob:NaiveTaylorSeries}{}
  \begin{description}
  \item[(a)] 
  Use the series 
$$
\sin x=x-\frac{1}{3!}\,x^3+\frac{1}{5!}x^5-\frac{1}{7!}x^7+\cdots=\sum_{n=0}^%
\infty\frac{\left(-1\right)^n}{\left(2n+1\right)!}x^{2n+1}
$$
to obtain the series
$$
\cos x=1-\frac{1}{2!}\,x^2+\frac{1}{4!}x^4-\frac{1}{6!}x^6+\cdots=\sum_{n=0}^%
\infty\frac{\left(-1\right)^n}{\left(2n\right)!}x^{2n}.
$$
\begin{solution}{}
  Differentiating both sides of 
$$
\sin x=x-\frac{1}{3!}\,x^3+\frac{1}{5!}x^5-\frac{1}{7!}x^7+\cdots=\sum_{n=0}^%
\infty\frac{\left(-1\right)^n}{\left(2n+1\right)!}x^{2n+1}
$$
gives 
$$
\cos x=1-\frac{1}{2!}x^2+\frac{1}{4!}x^4-\frac{1}{6!}x^6+\cdots=\sum_{n=0}^%
\infty\frac{\left(-1\right)^n}{\left(2n\right)!}x^{2n}.
$$

\end{solution}
\item[(b)] Let
$s(x,N)=\sum_{n=0}^N\frac{\left(-1\right)^n}{\left(2n+1\right)!}x^{2n+1}$ and
$c(x,N)=\sum_{n=0}^N\frac{\left(-1\right)^n}{\left(2n\right)!}x^{2n}$
and use a computer algebra system to plot these for $-4\pi\leq x\leq
4\pi,N=1,2,5,10,15$.
Describe what is happening to the series as  $N$  becomes
larger.\xqedhere{.75in}{\lozenge}
\begin{solution}{}
\vfill{}
{\underline{\Large $s(x,1):$}}\\
\centerline{\includegraphics*[height=2in,width=4in]{22b-1sin}  }
\vfill{}
{\underline{\Large $s(x,2):$}}\\
\centerline{\includegraphics*[height=2in,width=4in]{22b-2sin}  }
\vfill{}
{\underline{\Large $s(x,5):$}}\\
\centerline{\includegraphics*[height=2in,width=4in]{22b-5sin}  }
\vfill{}
{\underline{\Large $s(x,10):$}}\\
\centerline{\includegraphics*[height=2in,width=4in]{22b-10sin}  }
\vfill{}
{\underline{\Large $s(x,15):$}}\\
\centerline{\includegraphics*[height=2in,width=4in]{22b-15sin}  }
\vfill{}
\underline{\Large $c(x,1):$}\\
\centerline{\includegraphics*[height=2in,width=4in]{22b-1cos}  }
\vfill{}
\underline{\Large $c(x,2):$}\\
\centerline{\includegraphics*[height=2in,width=4in]{22b-2cos}  }
\vfill{}
\underline{\Large $c(x,5):$}\\
\centerline{\includegraphics*[height=2in,width=4in]{22b-5cos}  }
\vfill{}
\underline{\Large $c(x,10):$}\\
\centerline{\includegraphics*[height=2in,width=4in]{22b-10cos}  }
\vfill{}
\underline{\Large $c(x,15):$}\\
\centerline{\includegraphics*[height=2in,width=4in]{22b-15cos}  }
\vfill{}
\end{solution}
\end{description}

\newpage{}
\end{problem}

\begin{problem}
  \LabelProblem{prob:AtanViaGeoSeriesProb}{Geometric series!used to
    derive arctangent series}
Use the geometric series,
$\frac{1}{1-x}=1+x+x^2+x^3+\cdots=\sum_{n=0}^\infty x^n,$ to obtain a series for
$\frac{1}{1+x^2}$ and use this to obtain the series
$$
\arctan
x=x-\frac{1}{3}x^3+\frac{1}{5}x^5-\cdots=\sum_{n=0}^\infty(-1)^n
\frac{1}{2n+1}x^{2n+1}.
$$
Use the series above to obtain the series 
$\frac{\pi}{4}=\sum_{n=0}^\infty(-1)^n\frac{1}{2n+1}$.

\noindent{}\begin{solution}{}
Since
  \begin{align*}
    \frac{1}{1+x}                 &=\frac{1}{1-(-x)}\\
                                  &=\sum_{n=0}^\infty x^n\\
    \intertext{we see that }
    \frac{1}{(1+x)}               &=\sum_{n=0}^\infty (-x)^n\\
                                  &=\sum_{n=0}^\infty (-1)^nx^n\\
    \intertext{and therefore }
        \frac{1}{(1+x^2)}         &=\sum_{n=0}^\infty (-1)^n(x^2)^n\\
                                  &=\sum_{n=0}^\infty (-1)^nx^{2n}.\\
\intertext{Integrating gives:}
        \int \frac{1}{(1+x^2)}\d x&=\int\sum_{n=0}^\infty(-1)^nx^{2n}\d x\\
        \arctan x                 &= \sum_{n=0}^\infty\int(-1)^nx^{2n}\d x\\
                                  &= \sum_{n=0}^\infty\frac{(-1)^nx^{2n+1}}{2n+1}.\\
\intertext{Taking \(x=1\) gives}
        \arctan(1)                &= \sum_{n=0}^\infty\frac{(-1)^n(1)^{2n+1}}{2n+1}\\
        \pi/4                     &= \sum_{n=0}^\infty\frac{(-1)^n}{2n+1}\\
\intertext{or}
        \pi/4                     &= 1-1/3+1/5-1/7+1/9-\ldots.\\
  \end{align*}
 \end{solution}

\xqed{\lozenge}{}

\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:squaring the binomial series}{}

Consider the series representation 
\begin{align*}
\left(1+x\right)^{\frac{1}{2}}&=1+\sum_{n=1}^\infty\frac{\prod_{j=0}^{n-1}%
\left(\frac{1}{2}-j\right)}{n!}x^n\\
& =\sum_{n=0}^\infty\frac{\prod_{j=0}^{n-1}\left(\frac{1}{2}-j\right)}{n!}x^n.
\end{align*}

Multiply this series by itself and
compute the coefficients for $x^0,x^1,x^2,x^3,x^4$ in the resulting
series.

\noindent{}\begin{solution}{}
The first four terms of 
\begin{multline*}
  (1+x)^{\frac{1}{2}}]^2=\left[1+\frac12x+\frac{1/2(1/2-1)}{2!}x^2\right.\\
+\frac{1/2(1/2-1)(1/2-2)}{3!}x^3\\
\left.+\frac{1/2(1/2-1)(1/2-2)(1/2-3}{4!}x^4+\ldots\right]^2
\end{multline*}
Simplifying gives
\begin{align*}
(1+x)^{\frac{1}{2}}]^2=1+\frac12&x&-\frac{1}{2^2\cdot2!}&x^2&+\frac{3}{2^3\cdot3!}&x^3&-\frac{5\cdot3}{2^4\cdot4!}&x^4& \ldots\\
+\frac12&x&+\frac{1}{2^2}&x^2&-\frac{1}{2^3\cdot2!}&x^3&+\frac{3}{2^4\cdot3!}&x^4&\ldots\\
&&-\frac{1}{2^2\cdot2!}&x^2&-\frac{1}{2^3\cdot2!}&x^3& + \frac{1}{2^4\cdot2!\cdot2!}&x^4&\ldots\\
&&&&+\frac{3}{2^3\cdot3!}&x^3&+\frac{3}{2^4\cdot3!}&x^4&\ldots\\
&&&&&&-\frac{5\cdot3}{2^4\cdot4!}&x^4&+\ldots\\
&&&&\vdots&&
\end{align*}
and so
\begin{multline*}
  (1+x)^{\frac{1}{2}}]^2 = 1+\underbrace{\left(\frac12+\frac12\right)}_{=1}x\\
  +\underbrace{\left(\frac{-1}{2^2\cdot2}+\frac{1}{2^2}-\frac{1}{2^2\cdot2}\right)}_{=0}x^2\\
  +\underbrace{\left(\frac{3}{2^3\cdot3!}-\frac{1}{2^3\cdot2!}-\frac{1}{2^3\cdot2!}+\frac{3}{2^3\cdot3!}\right)}_{=0}x^3\\
  +\underbrace{\left(\frac{-5\cdot3}{2^4\cdot4!}+\frac{3}{2^4\cdot3!}+\frac{1}{2^4\cdot2!\cdot2!}+\frac{3}{2^4\cdot3!}-\frac{5\cdot3}{2^4\cdot4!}\right)}_{=0}x^4
  + \ldots.\\
\end{multline*}
So finally
\[  [(1+x)^{\frac{1}{2}}]^2 = 1+x\]
as expected.
  
\end{solution}

\xqed{\lozenge}{}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:SqrtSeriesProb}{}
Let
$$S(x,M)=\sum_{n=0}^M\frac{\prod_{j=0}^{n-1}\left(\frac{1}{2}-j%
  \right)}{n!}x^n.$$ Use a computer algebra system to plot $S(x,M)$
for $M=5, 10, 15, 95, 100$ and compare these to the graph for
$\sqrt{1+x}$. What seems to be happening?  For what values of $x$ does
the series appear to converge to $\sqrt{1+x}?$\xqed{\lozenge}{}
\begin{solution}{}
\underline{\Large $S(x,5):$}\\
\centerline{ \includegraphics*[height=2in,width=4in]{p25-5}}\\
\vfill{}
\underline{\Large $S(x,10):$}\\
\centerline{ \includegraphics*[height=2in,width=4in]{p25-10}}\\
\vfill{}
\underline{\Large $S(x,15):$}\\
\centerline{\includegraphics*[height=2in,width=4in]{p25-15}}\\
\vfill{}
\underline{\Large $S(x,95):$}\\
\centerline{ \includegraphics*[height=2in,width=4in]{p25-95}}\\
\vfill{}
\underline{\Large $S(x,100):$}\\
\centerline{ \includegraphics*[height=2in,width=4in]{p25-100}}
\vfill{}
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:first series expansion of pi}{}
Use the series
$\displaystyle \left(1+x\right)^{\frac{1}{2}}=\sum_{n=0}^\infty\frac{\prod_{j=0}^{n-1}%
\left(\frac{1}{2}-j\right)}{n!}x^n$ to obtain the series
\begin{align*}
  \frac{\pi}{4}&=\int_{x=0}^1\sqrt{1-x^2} \d x\\
&=\sum_{n=0}^\infty\left(\frac{%
\prod_{j=0}^{n-1}\left(\frac{1}{2}-j\right)}{n!}\text{
}\right)\left(\frac{\left(-1\right)^n}{2n+1}\right)\\
&=1-\frac{1}{6}-%
\frac{1}{40}-\frac{1}{112}-\frac{5}{1152}-\cdots.
\end{align*}

Use a computer algebra system to sum the first 100 terms of this
series and compare the answer to $\frac{\pi}{4}$.\xqed{\lozenge}{}
\begin{solution}{}
  Observe that $(1-x^2)^{1/2} = \left(1-(-x^2)\right)^{1/2}.$ Thus
  \begin{align*}
   \frac{\pi}{4} &= \int_{x=0}^1\sqrt{1-x^2} \d x \\
     &=\int_{n=0}^1\sum_{n=0}^\infty\frac{\prod_{j=0}^{n-1}(1/2-j)}{n!}(-x^2)^n\d x\\
     &=\int_{n=0}^1\sum_{n=0}^\infty\frac{\prod_{j=0}^{n-1}(1/2-j)}{n!}(-1)^nx^{2n}\d x\\
     &=\sum_{n=0}^\infty\frac{\prod_{j=0}^{n-1}(1/2-j)}{n!}(-1)^n\int_{x=0}^1x^{2n}\d x\\
     &=\sum_{n=0}^\infty\frac{\prod_{j=0}^{n-1}(1/2-j)}{n!}(-1)^n\left.\frac{x^{2n+1}}{2n+1}\right|_{x=0}^1\\
     &=\sum_{n=0}^\infty\frac{\prod_{j=0}^{n-1}(1/2-j)}{n!}\frac{(-1)^n}{2n+1}\\
     &=1-\frac{1}{6}-\frac{1}{40}-\frac{1}{112}-\frac{5}{1152}-\cdots.
  \end{align*}

Summing the first $100$ terms gives 
\begin{align*}
  \frac{\pi}{4}&\approx 0.785491,\\
  \intertext{whereas the first $6$ digits of $\frac{\pi}{4}$ is given
    by} 
  \frac{\pi}{4}&\approx 0.785398.
\end{align*}
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:second series expansion of pi}{}
  \begin{description}
  \item[(a)] 
Show that
$$
\int_{x=0}^{1/2}\sqrt{x-x^2}\d x=\sum_{n=0}^\infty\frac{(-1)^n\,\,%
\prod_{j=0}^{n-1}\left(\frac{1}{2}-j\right)}{\sqrt{2\,}n!\left(2n+3%
\right)2^n}
$$ 
and use this to show that 

$$
\pi=16\left(\sum_{n=0}^\infty\frac{(-1)^n\,\,\prod_{j=0}^{n-1}\left(%
\frac{1}{2}-j\right)}{\sqrt{2\,}n!\left(2n+3\right)2^n}\right).
$$

\item[(b)] We now have two series for calculating $\pi:$  the one from
part (a) and the one derived earlier, namely 
$$\pi=4\left(\sum_{n=0}^\infty\frac{(-1)^n\,\,}{2n+1}\right).$$  We will
explore which one converges to $\pi$ faster.  With this in mind,
define
$S1(N)=16\left(\sum_{n=0}^N\frac{(-1)^n\,\,\prod_{j=0}^{n-1}\left(
      \frac{1}{2}-j\right)}{\sqrt{2\,}n!\left(2n+3\right)2^n}\right)$
and $S2(N)=4\left(\sum_{n=0}^N\frac{(-1)^n\,\,}{2n+1}\right)$.  Use a
computer algebra system to compute $S1(N)\,$and $S2(N)$ for
$N=5,10,15,20$.  Which one appears to converge to $\pi$
faster?\xqedhere{1.1in}{\lozenge}{}
  \end{description}
  \begin{solution}{}
$$
    \begin{array}{c|c|c}
      $M$& $S1(N)$& $S2(N)$\\\hline
      5  & 3.14196750207      &2.97604617605\\
      10  & 3.14159565022      &3.23231580941\\
      15  & 3.14159269292      &3.0791533942\\
      20  & 3.14159265424      &3.18918478228\\
    \end{array}
$$
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:general binomial series}{}
Let $k$ be a positive integer. Find the power series, centered at
zero, for
$f(x) = \left(1-x\right)^{-k}$ by
  \begin{description}
  \item[(a)] Differentiating the\index{geometric series!differentiating} 
    geometric series $\left(k-1\right)$  times.
    \begin{solution}{}
      Let $f(x) = \frac{1}{1-x} = (1-x)^{-1} = \sum_{n=0}^\infty x^n$ so that
      \begin{align*}
        f^{(1)}(x) = (1-x)^{-2} &= \sum_{n=0}^\infty (n+1)x^n\\
        f^{(2)}(x) = 2!(1-x)^{-3} &= \sum_{n=0}^\infty (n+2)(n+1)x^n\\
        f^{(3)}(x) = 3!(1-x)^{-4} &= \sum_{n=0}^\infty \left(\prod_{i=1}^{3}
                                  (n+i)\right) x^n\\
\intertext{and in general,}
        f^{(k)}(x) = k!(1-x)^{-k} &= \sum_{n=0}^\infty \left(\prod_{i=1}^{k}
                                  (n+i)\right) x^n\\
\intertext{so that}
       (1-x)^{-k} &= \sum_{n=0}^\infty \left(\frac{\prod_{i=1}^{k-1}(n+i)}{k!}\right) x^n\\
      \end{align*}
    \end{solution}
  \item[(b)]  Applying the binomial series.
    \begin{solution}{}
      The Binomial Series is given by:
      \begin{align*}
        (1+x)^\alpha &= \sum_{n=0}^\infty\frac{\prod_{j=0}^{n-1}(\alpha-j)}{n!}x^n.\\ 
        \intertext{For this problem we have}
        \frac{1}{(1-x)^k} = (1+(-x))^{-k} &= \sum_{n=0}^\infty\frac{\prod_{j=0}^{n-1}(-k-j)}{n!}(-x)^n \\
        &= \sum_{n=0}^\infty\frac{\prod_{j=0}^{n-1}(-k-j)}{n!}(-1)^nx^n \\
        &= \sum_{n=0}^\infty\frac{\prod_{j=0}^{n-1}(k+j)}{n!}x^n
      \end{align*}
    \end{solution}
  \item[(c)]  Compare these two results.\xqedhere{2.9in}{\lozenge}{}
    \begin{solution}{}
      Since $\frac{\prod_{i=1}^{k-1}(n+i)}{k!} =
      \frac{\prod_{j=0}^{n-1}(k+j)}{n!}$ (They are both ${n+k-1}\choose {k}$)
      we see that the two series in (a) and (b) are the same.
    \end{solution}

  \end{description}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:Basel problem}{}
  \begin{description}
  \item[(a)]
Show that the power series for $\frac{\sin x}{x}$
is given by $1-\frac{1}{3!}x^2+\frac{1}{5!}x^4-\cdots.$
  \begin{solution}{}
    \begin{align*}
    \frac{\sin x}{x} &=
                       \frac{\sum_{n=0}^\infty\frac{(-1)^nx^{2n+1}}{(2n+1)!}}{x}\\
      &=               \sum_{n=0}^\infty\frac{(-1)^nx^{2n}}{(2n+1)!}\\
      &= 1-\frac{1}{3!}x^2+\frac{1}{5!}x^4-\cdots.
    \end{align*}

  \end{solution}
\item[(b)] Use (a) to infer that the roots of
  $1-\frac{1}{3!}x^2+\frac{1}{5!}x^4-\cdots$ are given by
$$
x=\pm\pi,\,\pm 2\pi,\,\pm 3\pi,\,\ldots
$$

  \begin{solution}{}
    The roots of $1-\frac{1}{3!}x^2+\frac{1}{5!}x^4-\cdots$ will be
    the same as the roots of $\sin x,$ which are as given.
  \end{solution}
\item[(c)] Suppose $p(x)=a_0+a_1x+\cdots+a_nx^n\,$is a polynomial with roots
$r_1,\,r_2,\,\ldots,r_n$.  Show that if $a_0\neq$ $0$, then all the roots
are non-zero and
$$
p(x)=a_0\left(1-\frac{x}{r_1}\right)\left(1-\frac{x}{r_2}\right)\cdots%
\left(1-\frac{x}{r_n}\right).
$$
  \begin{solution}{}
    Let $$p(x)=a_0+a_1x+\cdots+a_nx^n$$ and
    $$q(x)=a_0\left(1-\frac{x}{r_1}\right)\left(1-\frac{x}{r_2}\right)\cdots\left(1-\frac{x}{r_n}\right).$$

Clearly $p(x)$ and $q(x)$ have the same roots, so one must be a
constant multiple of the other. Since $p(0) = a_0 = q(0)$ they are
equal.
  \end{solution}

\item[(d)]  Assuming that the result in c holds for an infinite polynomial
power series, deduce that
$$
  1-\frac{1}{3!}x^2+\frac{1}{5!}x^4-\cdots=\left(1-\left(\frac{x}{\pi}\right)^2\right)\left(1-\left(\frac{x}{2\pi}
\right)^2\right)\left(1-\left(\frac{x}{3\pi}\right)^2\right)\cdots
$$
  \begin{solution}{}
    This conclusion is immediate with the given assumption and part
    (c).
  \end{solution}

\item[(e)] Expand this product to deduce
$$
\sum_{n=1}^\infty\frac{1}{n^2}=\frac{\pi^2}{6}.\xqedhere{1.9in}{\lozenge}{}
$$
  \begin{solution}{}
    Expanding the right side of the formula in part (d) and comparing
    the coefficients of the $x^2$ term we have
    \begin{align*}
      -\frac{1}{3!}x^2 &=  -\left(\frac{x}{\pi}\right)^2
                    - \left(\frac{x}{2\pi}\right)^2 -
                    \left(\frac{x}{3\pi}\right)^2 - 
                    \left(\frac{x}{4\pi}\right)^2
                    - \cdots\\
                  &=   \left[-\left(\frac{1}{\pi}\right)^2
                    - \left(\frac{1}{2\pi}\right)^2 -
                    \left(\frac{1}{3\pi}\right)^2 - 
                    \left(\frac{1}{4\pi}\right)^2
                    - \cdots\right]x^2\\
    \end{align*}
Therefore
$$
\frac{1}{3!} = \frac{1}{\pi^2}\sum_{n=1}^\infty\frac{1}{n^2}
$$
or 
$$
\frac{\pi^2}{6} = \sum_{n=1}^\infty\frac{1}{n^2}.
$$
  \end{solution}
  \end{description}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:alternating harmonic series}{alternating harmonic series}
Use the geometric series to obtain the series
\begin{align*}
\ln \left(1+x\right)&=x-\frac{1}{2}x^2+\frac{1}{3}x^3-\cdots\\
&=\sum_{n=0}^\infty\frac{(-1)^n}{n+1}x^{n+1}.\xqedhere{1.8in}{\lozenge}{}
\end{align*}
\begin{solution}{}
The geometric series
\begin{align*}
  \frac{1}{1-x} &= 1+x+x^2+x^3+\ldots\\
\intertext{so that}
  \frac{1}{1+x}= \frac{1}{1-(-x)} &= 1+(-x)+(-x)^2+(-x)^3+\ldots\\
\intertext{and}
  \frac{1}{1+x} &=1-x+x^2-x^3+\ldots\\
\intertext{so, finally}
\ln \left(1+x\right)&=x-\frac{1}{2}x^2+\frac{1}{3}x^3-\ldots
\end{align*}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:power series drills}{}
\underline{Without} using Taylor's Theorem, represent the following
functions as power series expanded about 0 (i.e., in the form
$\sum_{n=0}^\infty a_nx^n$).


\begin{description}
\item[(a)] $\ln\left(1-x^2\right)$
  \begin{solution}{}
    From the geometric series we have
    \begin{align*}
      \frac{1}{1-x} &= 1+x+x^2+x^3+\ldots\\
\intertext{so that}
      \frac{1}{1-x^2} &= 1+x^2+x^4+x^6+\ldots\\
      \intertext{and}
      \frac{-2x}{1-x^2} &= -2x(1+x^2+x^4+x^6+\ldots).\\
      &= -2(x+x^3+x^5+x^7+\ldots).\\
      \intertext{Integrating both sides gives:}
      \ln(1-x^2) &= -2\left(\frac{x^2}{2} +\frac{x^4}{4}
                   +\frac{x^6}{6} + \frac{x^8}{8}+ \ldots\right)\\
                 &= -x^2-\frac{x^4}{2}-\frac{x^6}{3} - \ldots -
                   \frac{x^{2n}}{n} - \ldots.
    \end{align*}
    So $$\ln(1-x^2) = -\sum_{n=1}^\infty\frac{x^{2n}}{n}.$$
  \end{solution}
\item[(b)] $\frac{x}{1+x^2}$
  \begin{solution}{}
    From part (a) we see that 
    \begin{align*}
      \frac{1}{1-x^2} &= 1+x^2+(x^2)^2+(x^2)^3+\ldots\\
\intertext{so that}
      \frac{1}{1+x^2}=\frac{1}{1-(-x^2)} &=
                                            1+(-x^2)+(-x^2)^2+(-x^2)^3+\ldots\\
\frac{1}{1+x^2} &= 1-x^2+x^4-x^6+\ldots\\
\intertext{and, finally}
\frac{x}{1+x^2} &= x-x^3+x^5-x^7+\ldots\\
    \end{align*}
  \end{solution}
\item[(c)] $\arctan \left(x^3\right)$
  \begin{solution}{}
    Integrating both sides of 
    \begin{align*}
      \frac{1}{1+x^2} &= 1-x^2+x^4-x^6+\ldots\\
\intertext{gives}
\arctan(x) &= x-\frac{x^3}{3}+\frac{x^5}{5}-\frac{x^7}{7}+\ldots\\
\intertext{and so }
\arctan(x^3) &= (x)^3-\frac{(x^3)^3}{3}+\frac{(x^3)^5}{5}-\frac{(x^3)^7}{7}+\ldots\\
            &= x^3-\frac{x^9}{3}+\frac{x^{15}}{5}-\frac{x^{21}}{7}+\ldots.
    \end{align*}

  \end{solution}
\item[(d)] $\ln\left(2+x\right)$ [Hint:
  $2+x=2\left(1+\frac{x}{2}\right)$]\xqedhere{2.4in}{\lozenge}{}
\end{description}
\begin{solution}{}
  \begin{align*}
    \ln\left(2+x\right) &= \ln\left(2(1+x/2)\right)\\
                        &= \ln(2)+\ln\left(1+x/2\right)\\
\intertext{and from problem~\ref{prob:alternating harmonic series} we
    have }
                        &= \ln(2) + \frac{x}{2} -
                          \frac12\left(\frac{x}{2}\right)^2 +
                          \frac13\left(\frac{x}{2}\right)^3 -
                          \frac14\left(\frac{x}{2}\right)^4 + \ldots\\
                        &= \ln(2) + \frac{x}{2} -
                          \frac{x^2}{2\cdot2^2} +
                          \frac{x^3}{3\cdot2^3} -
                          \frac{x^4}{4\cdot2^4} + \ldots\\
  \end{align*}
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:Maclaurin series of a^x}{}
Let $a$ be a positive real number. Find a power series for 
$a^x$ expanded about 0. [Hint: $a^x=e^{\ln\left(a^x\right)}$]\xqed{\lozenge}{}
\begin{solution}{}
  \begin{align*}
    a^x &= e^{\ln\left(a^x\right)}\\
        &= e^{x\ln\left(a\right)}\\
        &= \sum_{n=0}^\infty\frac{\left(x\ln\left(a\right)\right)^n}{n!}\\
        &= \sum_{n=0}^\infty\frac{\left(\ln\left(a\right)\right)^n}{n!}x^n
  \end{align*}
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:power series of sin(x) at an arbitrary point}{power
series representation of $\sin(x)$}
Represent the function $\sin x$  as a power series
expanded about $a$ 
(i.e., in the form    $\sum_{n=0}^\infty a_n\left(x-a\right)^n$). 
[Hint:  $\sin x=\sin \left(a+x-a\right)$.]\xqed{\lozenge}{}
\begin{solution}{}
  $$
  \sin a +\cos a(x-a) -\sin a(x-a)^2-\cos a(x-a)^3+\sin a(x-a)^4+\cos a(x-a)^5 - \ldots
$$
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:Maclaurin series}{}
\underline{Without} using Taylor's Theorem, represent the following
functions as a power series expanded about $a$ for the given value of
$a$ (i.e., in the form $\sum_{n=0}^\infty a_n\left(x-a\right)^n$).
\begin{description}
\item[(a)] $\ln x$,  $a=1$
  \begin{solution}{}
    \begin{align*}
      \ln x &= \ln(1-(1-x)) \\
            &= (x-1) -\frac{(x-1)^2}{2}+\frac{(x-1)^3}{3}-\cdots\\
            &= \sum_{n=1}^\infty\frac{(-1)^{n+1}(x-1)^n}{n}.
    \end{align*}
  \end{solution}
\item[(b)] $e^x$,  $a=3$
  \begin{solution}{}
    \begin{align*}
      e^x &= e^{3+(x-3)} \\
          &= e^3e^{x-3}\\
          &= e^3\left(1+(x-3) + \frac{(x-3)^2}{2!} +
            \frac{(x-3)^3}{3!} + \cdots\right)\\
          &= \sum_{n=0}^\infty \frac{e^3(x-3)^n}{n!}.
    \end{align*}
  \end{solution}
\item[(c)] $x^3+2x^2+3$ ,  $a=1$
$$
x^3+2x^2+3 = 6+7(x-1)+5(x-1)^2+(x-1)^3
$$
\item[(d)] $\frac{1}{x}$ ,  $a=5$
  \begin{solution}{}
    \begin{align*}
      \frac1x &= \frac{1}{5+(x-5)}\\
              &=
                \frac15\left(\frac{1}{1+\left(\frac{x-5}{5}\right)}\right)
              &= \frac15\left(1+\frac{-(x-5)}{5} +
                \frac{(x-5)^2}{5^2}+\frac{-(x-5)^3}{5^3}\right)+\cdots\\
              &= \sum_{n=0}^\infty\frac{(-1)^n(x-5)^n}{5^{n+1}}
    \end{align*}
  \end{solution}
\xqedhere{3.9in}{\lozenge}{}
\end{description}

\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:integration via series}{}
Evaluate the following integrals as series.
\begin{description}
\item[(a)] $\displaystyle\int_{x=0}^1e^{x^2}\d x$
\begin{solution}{}
  \begin{align*}
    \int_{x=0}^1e^{x^2}\d x &= \int_{x=0}^1\sum_{n=0}^\infty\frac{(x^2)^n}{n!}\d x \\
    &=\int_{x=0}^1\sum_{n=0}^\infty\frac{x^{2n}}{n!}\d x \\
    &=\left.\sum_{n=0}^\infty\frac{x^{2n+1}}{n!(2n+1)}\right|_{x=0}^1 \\
    &=\sum_{n=0}^\infty\frac{1}{n!(2n+1)} \\
  \end{align*}
\end{solution}
\item[(b)] $\displaystyle\int_{x=0}^1\frac{1}{1+x^4}\d x$
  \begin{solution}{}
    \begin{align*}
      \int_{x=0}^1\frac{1}{1+x^4}\d x &= \int_{x=0}^1\sum_{n=0}^\infty(-1)^n(x^4)^n\d x \\
      &= \int_{x=0}^1\sum_{n=0}^\infty(-1)^nx^{4n}\d x\\
      &= \left.\sum_{n=0}^\infty\frac{(-1)^nx^{4n+1}}{4n+1}\right|_{x=0}^1 \\
      &= \sum_{n=0}^\infty\frac{(-1)^n}{4n+1}
    \end{align*}
  \end{solution}
\item[(c)] $\displaystyle\int_{x=0}^1\sqrt[3]{1-x^3}\d x$\xqedhere{3.5in}{\lozenge}{}
\end{description}

\newpage{}
\end{problem}

\chapter{Questions Concerning Power Series}
\label{chpt:PowerSeriesQuestions}{}
\markboth{{\sc Questions Concerning Power Series}}{{\sc Questions Concerning Power Series}}

\begin{theorem}
\label{TaylorSeriesThm}
\IndexTheorem{TaylorSeriesThm}{}
If  $f(x)=\sum_{n=0}^\infty a_n(x-a)^n$, then
$a_n=\frac{f^{(n)}(a)}{n!}$, where $f^{(n)}(a)$ represents the $n^{th}$
derivative of $f$ evaluated at $a$.  \xqed{\blacktriangle}{}
\end{theorem}

\begin{problem}
\LabelProblem{prob:Taylor series1}{}
  Prove Theorem~\ref{TaylorSeriesThm}. 
  \begin{hint}
    $f(a)=a_0+a_1(a-a)+a_2(a-a)^2+\cdots=a_0$, differentiate to obtain
    the other terms.
  \end{hint}\xqed{\lozenge}{}
  \begin{solution}{}
    Observe that 
$$
f^{(n)}(x) = \sum_{n=0}^\infty\frac{a_k k!}{(n-k)!}(x-a)^{n-k}
$$
so that
$$
f^{(n)}(a) = a_nn!
$$
or
$$
a_n  = \frac{f^{(n)}(a)}{n!}.
$$
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}\ \\
\LabelProblem{prob:Cauchy's counterexample1}{Cauchy's counterexample}  
\begin{description}
\item[(a)] Adopting the notation $y=x^{-1}$ and $f^{(n)}(x)
  =p_n(y)e^{-y^2},$ find $p_{n+1}(y)$ in terms of $p_{n}(y).$ [Note:
  Don't forget that you are differentiating with respect to $x,$ not
  $y.$]
\begin{solution}{}
  First observe that if $y=x^{-1}$ then $\dfdx{y}{x} = -x^{-2} =
  -y^2.$

  If 
  \begin{align*}
    f^{(n)}(x)&=p_n(y)e^{-y^2}\\
  \intertext{then}
    f^{(n+1)}(x)&=p_n(y)\left(-2y\dfdx{y}{x}\right)e^{-y^2} +
                  p_n^\prime(y)\dfdx{y}{x}e^{-y^2}\\
    &= e^{-y^2}\underbrace{\left(p_n(y)(-2y)(-y^2) +
      p_n^\prime(y)(-y^2)\right)}_{=p_{n+1}(y)}\\
  \end{align*}
Therefore $p_{n+1}(y) = p_n(y)(-2y)(-y^2) +    p_n^\prime(y)(-y^2)$
and the expression on the right is clearly a polynomial since both a
polynomial and its derivative are polynomials.
\end{solution}
\item[(b)] Use induction on $n$ to show that $p_n(y)$ is a polynomial
  for all $n\in\NN.$\xqedhere{.38in}{\lozenge}
\begin{solution}{}
  Clearly $p_0(y)=1$ is a polynomial and  part (a) gives the inductive
  step.
\end{solution}
\end{description}
\newpage{}
\end{problem}

\begin{problem}\ \\
\LabelProblem{prob:Cauchy's counterexample2}{Cauchy's counterexample}  
\begin{description}
\item[(a)] Let $m$ be a nonnegative integer. Show that
  $\limit{y}{\pm\infty}{\frac{y^m}{e^{y^2}}}=0.$ [Hint: Induction and
  a dash of L'H\^{o}pital's rule should do the trick.]
  \begin{solution}{}
    Applying L'H\^{o}pital's rule $m$ times gives us a constant in the
    numerator and, by the previous problem $p_{n+1}(y)e^{-y^2}$ in the
    denominator. Thus  $\limit{y}{\pm\infty}{\frac{y^m}{e^{y^2}}}=0.$
  \end{solution}
\item[(b)] Prove that $\limit{y}{\pm\infty}{\frac{q(y)}{e^{y^2}}}=0$
  for any polynomial $q.$
  \begin{solution}{}
    This follows immediately from part (a).
  \end{solution}
\item[(c)] Show that for every nonnegative integer $n,$
  $f^{(n)}(0)=0.$\xqedhere{1.2in}{\lozenge}
\end{description}
\begin{solution}{}
  \noindent\underline{Proof by Induction:}\\
  \begin{description}
  \item[Base Case:] $f(0) =0.$
  \item[Inductive Step:] Assume that $f^{(n)}(0)=0.$ We show that
    $f^{(n+1)}(0)=0.$
    \begin{align*}
      f^{(n+1)}(0)&=\limit{h}{0}{\frac{f^{(n)}(h)-f^{(n)}(0)}{h}}.\\
\intertext{From the previous problem, and substituting $y=h^{-1}$ this becomes:}
      f^{(n+1)}(0)&= \limit{h}{\infty}{p_n(y)e^{-y^2}}\\
      \intertext{and from part (a) of this problem we see that }
      f^{(n+1)}(0)&= 0.
    \end{align*}
  \end{description}
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:Taylor's formula-binomial series via}{}
  Use Taylor's formula to obtain the general binomial
  series
  $$(1+x)^\alpha=1+\sum_{n=1}^\infty\frac{\prod_{j=0}^{n-1}\left(\alpha-j\right)}{n!}x^n.\xqedhere{1.3in}{\lozenge}{}$$
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:Taylor's formula-series expansions of elementary functions using}{}
  Use Taylor's formula to obtain the Taylor series for the functions
  $e^x$, sin $x$, and cos $x$ expanded about $a$.\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{theorem}
\label{TaylorsTheorem}
  If $f^\prime,\,f^{\prime\prime},\,\ldots,\,f^{(n+1)}$ are all continuous on an interval
  containing $a$ and $x$, then
  \begin{align*}
    f(x)=f(a)+\frac{f^{\prime}(a)}{1!}(x-a)+\frac{f^{\prime
      \prime}(a)}{2!}(x-a)^2&+\cdots+\frac{f^{(n)}(a)}{n!}(x-a)^n\\
&+ \frac{1}{n!}\int_{t=a}^xf^{(n+1)}(t)(x-t)^n\d{t}.\xqed{\blacktriangle}
\end{align*}
\end{theorem}

\begin{problem}
\LabelProblem{prob:Taylor's Theorem-proof}{}
  Provide a formal induction proof for Theorem~\ref{TaylorsTheorem}.\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:Taylor Series-log(2)}{}
  Use the fact that
$$
1-\frac{1}{2}+\frac{1}{3}-\cdots+\frac{(-1)^{2k+1}}{2k}\leq\ln 2\leq
1-\frac{1}{2}+\frac{1}{3}-\cdots+\frac{(-1)^{2k+2}}{2k+1}
$$
  to determine how many terms of the series
  $\sum_{n=1}^\infty\frac{(-1)^{n+1}}{n}$ should be added together to
  approximate $\ln 2$ to within .$0001$ without actually computing what
  $\ln 2$ is.\xqed{\lozenge}{}
  \begin{solution}{}
    In general, if $a\le x\le b$ then $\abs{x-a} \le b-a$ and
    $b-x \le b-a,$ so
    $\abs{\sum_{n=1}^\infty\frac{(-1)^{n+1}}{n} - \ln(2)} < .0001$
    when 
    \begin{align*}
\left(1-\frac{1}{2}+\frac{1}{3}-\cdots+\frac{(-1)^{2k+1}}{2k}+\frac{(-1)^{2k+2}}{2k+1}\right)\\
\hskip1in - \left(1-\frac{1}{2}+\frac{1}{3}-\cdots+\frac{(-1)^{2k+1}}{2k}\right)
&\le .0001.\\
    \end{align*}
    Since all but the one term of the left side of the above equation
    cancels out we have:
      $$
      \frac{(-1)^{2k+2}}{2k+1} \le .0001
      $$
Solving this for $k$ gives $k>5000,$ so the number of term required is
$2k=10,000.$
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:rearrangement of alternating Harmonic series-diverges to infinity}{}
  Show that there is a rearrangement of
  $1-\frac{1}{2}+\frac{1}{3}-\frac{1}{4}+\cdots$ which diverges to
  $\infty$.\xqed{\lozenge}{}
  \begin{solution}{}
    Our proof will be by induction.
\vskip5mm{}
    \noindent{}{\bf \underline{Base case $(n=1):$}} Choose $O_1\in\NN$ such that
    $\exists$ $ k_1$ such that $$\sum_{i=1}^{k_1}\frac{1}{2i-1}> 2.$$

    Then $\left(\sum_{i=1}^{k_1}\frac{1}{2i-1}\right)-\frac12>1.$
\vskip5mm{}
    \noindent{}\underline{\bf{}Induction Assumption:} Assume that
    $k_1, k_2, \cdots, k_n$ has been constructed such
    that
    \begin{equation}
      \label{eq:1}
      \begin{split}
        \left[\left(\sum_{i=1}^{k_1}\frac{1}{2i-1}\right)-\frac12\right]
        &+ \left[\left(\sum_{i=k_1+1}^{k_2}\frac{1}{2i-1}\right) -
          \frac14\right] + \cdots \\
        &\quad\quad+ \left[\sum_{i=k_{n-1}+1}^{k_n}\frac{1}{2i-1} -\frac{1}{2n}\right] >
        n.
      \end{split}
      \end{equation}
      Observe that the summation in inequality~(\ref{eq:1}) is a
      rearrangement of all of the terms of the Alternating Harmonic
      Series up through $-\frac{1}{2n}.$
      
      Since $\sum_{i=1}^{\infty}\frac{1}{2i-1} = \infty$ we
    can find an integer $k+1$ such that
    $$\sum_{i=k_{n-1}+1}^{k_n}\frac{1}{2i-1} > 2.$$ And since
      $\frac{1}{2i-1} <1$ $\forall\  n\in\NN$ we see that
      $\left(\sum_{i=k_{n-1}+1}^{k_n}\frac{1}{2i-1}\right) -\frac{1}{2(k+1)}> 1.$
      Therefore 
    \begin{equation*}
      \begin{split}
        \left[\left(\sum_{i=1}^{k_1}\frac{1}{2i-1}\right)-\frac12\right]
        &+ \left[\left(\sum_{i=k_1+1}^{k_2}\frac{1}{2i-1}\right) -
          \frac14\right] \\
        &\quad+ \cdots\\
        &\quad\quad+ \left[\sum_{i=k_{n-1}+1}^{k_n}\frac{1}{2i-1} -\frac{1}{2n}\right]\\
        &\quad\quad\quad+\left[\sum_{i=k_n+1}^{k_{n+1}}\frac{1}{2i-1}
          -\frac{1}{2(n+1)}\right]>n+1.
      \end{split}
    \end{equation*}

      Observe that the summation in inequality~(\ref{eq:1}) is a
      rearrangement of all of the terms of the Alternating Harmonic
      Series up through $-\frac{1}{2(n+1)}.$
      Therefore, taking $k_0=0$ we see that  the rearrangement
      $$
      \sum_{n=k_0}^\infty \left(     \sum_{i=k_n+1}^{k_{n+1}}\frac{1}{2i-1} -\frac{1}{2n}\right)
      $$
      diverges to infinity.
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:RearrangeDivToNegInf}{}
  Show that there is a rearrangement of 
  $1-\frac{1}{2}+\frac{1}{3}-\frac{1}{4}+\cdots$ which diverges to
  $-\infty$.\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:Taylor Series2}{}
  Use Taylor's formula to find the Taylor series of the given function
  expanded about the given point $a$.
  \begin{description}
  \item[(a)]  $f(x)=\ln\left(1+x\right),$ $a=0$
    \begin{solution}{}
$$
      \ln\left(1+x\right) = \sum_{n=1}^\infty\frac{(-1)^{n+1}}{n}x^n
$$
    \end{solution}
  \item[(b)]  $f(x)=e^x,$ $a=-1$
    \begin{solution}{}
      $$e^x = \frac{1}{e}\sum_{n=0}^\infty\frac{(x+1)^n}{n!}$$
    \end{solution}
  \item[(c)]  $f(x)=x^3+x^2+x+1,$ $a=0$
    \begin{solution}{}
      This function is its own Taylor series.
    \end{solution}
  \item[(d)]  $f(x)=x^3+x^2+x+1,$ $a=1$\xqedhere{2.75in}{\lozenge}{}
    \begin{solution}{}
      $$
      f(x) = 4+6(x-1) + 4(x-1)^2+(x-1)^3
      $$
    \end{solution}
  \end{description}
\newpage{}
\end{problem}

\part{Interregnum}
\begin{problem}
\LabelProblem{prob:HarmonicMotion}{}
  Show that $T=Ce^{\rho^2kt}$  satisfies the equation 
  $T^\prime=\rho^2k T$, where $C,$ and $\rho$ are arbitrary constants.  Use the
  physics of the problem to show that if 
    $u$ is not constantly zero, then $k<0$.  \lbrack Hint:  Consider 
    $\lim_{t\rightarrow\infty}u(x,t)$.\rbrack\xqed{\lozenge}{}
    \begin{solution}{}
      
    \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:Heat Equation-solving for X(x)}{}
Show that $X=A\sin\left(px\right)+B\cos\left(px\right)$ satisfies the
equation $X\,''=-p^2X$, where $A$ and $B$ are arbitrary constants. Use
the boundary conditions $u(0,t)=u(1,t)=0$, $\forall\,t\geq 0$  to
show that $B=0$ and $A\sin p=0$. Conclude that if $u$ is not
constantly zero, then $p=n\pi$, where $n$ is any integer. \xqed{\lozenge}{}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:Heat Equation!sum of fundamental solutions}{}
  Show that if  $u_1$ and  $u_2$  satisfy the equations 
  $\rho^2\frac{\partial^2u}{\partial x^2}=\frac{\partial u}{\partial t}$
   and $u(0,t)=u(1,t)=0, \forall\,t\geq 0$ then  $u=A_1u_1+A_2u_2$
  satisfy these as well, where  $A_1$ and  $A_2$ are arbitrary constants.\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:SinOrthogonality}{}
Let $n$ and $m$ be positive integers.  Show
$$
\int_{x=0}^1\sin\left(n\pi x\right)\sin\left(m\pi x\right)\d x=
\left\{\begin{matrix}
0&\text{if }n\neq m\\
\frac{1}{2}&\text{if }n=m
\end{matrix}\right.. \xqedhere{1in}{\lozenge}{}
$$
\begin{solution}{}
  \begin{description}
  \item[$\underline{n=m}$]
    \begin{align*}
      \int_{x=0}^1\sin^2\left(n\pi x\right)\d x 
          &= \frac12 \int_{x=0}^1\left(1-\cos(n\pi x)\right)\d x\\
          &= \frac12\left[x-\sin(n\pi x)\right]_{x=0}^1\\
          &= \frac12.
    \end{align*}
  \item[$\underline{n\neq m}$] 
    \begin{align*}
      \int_{x=0}^1\sin\left(n\pi x\right)\sin\left(m\pi x\right)\d x
             &= \frac{1}{2}\int_{x=0}^1\cos\left((n+m)\pi
               x\right)-\cos\left((n-m)\pi x\right)\d x\\
             &= \frac{1}{2}\left[\frac{1}{(n+m)\pi}\sin\left((n+m)\pi
               x\right)-\frac{1}{(n-m)\pi}\sin\left((n-m)\pi
               x\right)\right]_{x=0}^1\\ 
             &= 0.
    \end{align*}
  \end{description}
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:Fourier Series-Sine series}{}
  Let $n$ be a positive integer.  Show that if 
  $$
  f(x)=\frac{1}{2}-\abs{x-\frac{1}{2}}
  $$ 
then 
  $$
  \int_{x=0}^1f(x)\sin\left(n\pi x\right)d x =
  \frac{2}{\left(n\pi\right)^2}\sin\left(\frac{n\pi}{2}\right) 
  $$ 
and show that the Fourier sine series of $f$ is given by
$$
f(x)=\sum_{n=1}^\infty\frac{4}{\left(n\pi\right)^2}\sin\left(\frac{n\pi}{2}%
  \right)\sin\left(n\pi
    x\right)=\frac{4}{\pi^2}\sum_{k=0}^\infty\frac{\left(-1\right)^k}{\left(2k+1\right)^2}\sin\left(\left(2k+1\right)\pi
    x\right).\xqedhere{.45in}{\lozenge}{}
$$
  \begin{solution}{}
    Observe that 
    \[
    f(x) = \frac12-\abs{x-\frac12} =
    \begin{cases}
      -x+1&\text{ if $x\ge 1/2$}\\
      x &  \text{ if $x<   1/2$}
    \end{cases}
    \]
    so that 
    \[
    \int_0^1f(x)\sin(n\pi x)\d x = \int_0^{1/2}f(x)\sin(n\pi x)\d x +\int_{1/2}^1f(x)\sin(n\pi x)\d x\\
    \]
    
    Taking these last two integrals one at a time we see that:
    \begin{align*}
      \int_0^{1/2}f(x)\sin(n\pi x)\d x &= \int_0^{1/2}x\sin(n\pi x)\d x.\\
      \intertext{Integrating by parts we take $u=x$ and $\d v = \sin(n\pi
        x)\d x$ so that $\d u = \d x$ and $v=\frac{-\cos(n\pi x)}{n\pi}.$ Thus}
      \int_0^{1/2}f(x)\sin(n\pi x)\d x &= \left.-\frac{x}{n\pi}\cos(n\pi
        x)\right|_0^{1/2}+ \int_0^{1/2}\frac{\cos(n\pi x)}{n\pi}\d x\\
      &= \left.\frac{1}{(n\pi)^2}\sin n\pi x\right|_0^{1/2}\\
      &= \frac{\sin\left(\frac{n\pi}{2}\right)}{(n\pi)^2}
    \end{align*}
    So that
    \begin{equation}
      \label{eq:p50-1}
      \int_0^{1/2}f(x)\sin(n\pi x)\d x =
      \begin{cases}
        1& n \equiv 1\mod{4}\\
        -1& n \equiv 3\mod{4}\\
        0& \text{ otherwise}
      \end{cases}.
    \end{equation}

The second integral is
    \begin{align*}
      \int_{1/2}^1f(x)\sin(n\pi x)\d x &= \int_{1/2}^1(1-x)\sin(n\pi x)\d
      x.\\
      \intertext{Integrating by parts again gives}
      &= -\left.\frac{\sin(n\pi x)}{(n\pi)^2}\right|_{1/2}^1\\
      &= -\frac{\sin\left(\frac{n\pi}{2}\right)}{(n\pi)^2}
    \end{align*}
    so that
    \begin{equation}
      \label{eq:p50-2}
      \int_{1/2}^1f(x)\sin(n\pi x)\d x =
      \begin{cases}
        1& n \equiv 1\mod{4}\\
        -1& n \equiv 3\mod{4}\\
        0& \text{ otherwise}
      \end{cases}.
    \end{equation}
    Combining equation~\ref{eq:p50-1} and equation~\ref{eq:p50-2} we
    have
    \[
    f(x)=\sum_{n=1}^\infty\frac{4}{\left(n\pi\right)^2}\sin\left(\frac{n\pi}{2}%
    \right)\sin\left(n\pi
      x\right)=\frac{4}{\pi^2}\sum_{k=0}^\infty\frac{\left(-1\right)^k}{\left(2k+1\right)^2}\sin\left(\left(2k+1\right)\pi
      x\right).
    \]
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:FourierDiverge}{}
  Show that when $x=\frac{1}{4}$
$$  
4\sum_{k=0}^\infty\left(-1\right)^{k+1}
  \sin\left(\left(2k+1\right)\pi
    x\right)=4\left(-\frac{1}{\sqrt{2}}+\frac{1}{\sqrt{2}}+\frac{1}{\sqrt{2}}-
    \frac{1}{\sqrt{2}}-\frac{1}{\sqrt{2}}+\cdots\right).
$$\xqed{\lozenge}{}

\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:Fourier Series-orthogonality}{}
  Let $n$ and $m$ be positive integers.  Show
$$
\int_{x=0}^1\cos\left(n\pi x\right)\cos\left(m\pi
    x\right)\d x=\left\{
  \begin{matrix}
    0&\text{if }n\neq m\\
    \frac{1}{2}&\text{if }n=m
  \end{matrix}
\right..
$$\xqed{\lozenge}{}

\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:fouriercoef}{}
Use the result of Problem~\ref{prob:Fourier Series-orthogonality} to
show that if 
$$
f(x)=\sum_{n=1}^\infty B_n\cos\left(n\pi x\right)
$$ 
on $[0,1]$, then 
$$
B_m=2\int_{x=0}^1f(x)\cos\left(m\pi
  x\right)\d x.\xqedhere{3in}{\lozenge}{}
$$

\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:Fourier Series-cosine series}{}
  Apply the result of Problem~\ref{prob:fouriercoef} to show that the Fourier cosine
  series of $f(x)=x-\frac{1}{2}$  on $[\,0,1]$  is given by
$$
\frac{-4}{\pi^2}\sum_{k=0}^\infty\frac{1}{\left(2k+1\right)^2}\cos
  \left((2k+1)\pi x\right).
$$

Let
$C(x,N)=\frac{-4}{\pi^2}\sum_{k=0}^N\frac{1}{\left(2k+1\right)^2}\cos
\left((2k+1)\pi x\right)$ and plot $C(x,N)$ for $N=1,2,5,50$
$x\in[\,0,1]$. How does this compare to the function
$f(x)=x-\frac{1}{2}$ on $[\,0,1]$?  What if you plot it for
$x\in[\,0,2]?$\xqed{\lozenge}{}

\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}\ \\
\LabelProblem{prob:Fourier Series-differentiation}{}
\begin{description}
\item[(a)] Differentiate the series
$$
\frac{-4}{\pi^2}\sum_{k=0}^\infty\frac{1}{\left(2k+1\right)^2}\cos
  \left((2k+1)\pi x\right)
$$ 
term by term and plot various partial
  sums for that series on $[\,0,1]$.  How does this compare to the
  derivative of $f(x)=x-\frac{1}{2}$ on that interval?
\item[(b)] Differentiate the series you obtained in part a and plot
    various partial sums of that on $[\,0,1]$.  How does this compare to the
    second derivative of $f(x)=x-\frac{1}{2}$ on that interval?\xqed{\lozenge}{}
\end{description}

\begin{solution}{}
  \begin{itemize}
  \item [(a)] $n=1$\\
    \includegraphics*[height=3.5in,width=4in]{P55a-1}\\
    $n=5$\\
    \includegraphics*[height=3.5in,width=4in]{P55a-5}\\
    $n=10$\\
    \includegraphics*[height=3.5in,width=4in]{P55a-10}\\
  \item [(b)] $n=1$\\
    \includegraphics*[height=3.5in,width=4in]{P55b-1}\\
    $n=5$\\
    \includegraphics*[height=3.5in,width=4in]{P55b-5}\\
    $n=10$\\
    \includegraphics*[height=3.5in,width=4in]{P55b-10}\\
  \end{itemize}
\end{solution}
\newpage{}
\end{problem}




\part{In Which We Find (Some) Answers}

\chapter{Convergence of Sequences and Series}
\label{chpt:Convergence}
\markboth{{\sc Convergence Of Sequences And Series}}{{\sc Convergence Of Sequences And Series}}


\begin{problem}
\LabelProblem{prob:absolute value}{}
Let $a$ and $b$ be real numbers with $b>0.$ Prove $|a|<b$ if and only
if $-b<a<b.$ Notice that this can be extended to $|a|\leq b$ if and
only if $-b\leq a\leq b.$

   \begin{solution}{}
     Recall that by definition:
     \[
     \abs{x}=
     \begin{cases}
       x & \text{if $x\ge0$}\\
       -x& \text{if $x<0$}
     \end{cases}.
     \]
     {\bf Claim:} If $\abs{a}<b$ then $-b<a<b.$

     \begin{proof}
       There are two cases:
       \begin{description}
       \item[Case 1:] $a\ge0$\\
         In this case, since $b>0,$ we have $-b< \underbrace{a}_{=\abs{a}}
         \le b.$
       \item[Case 2:] $a<0$\\
         In this case, $-a>0$ so
         \begin{align*}
           -b<\underbrace{-a}_{=\abs{a}}&<b\\
           \intertext{and therefore}
           b>a&>-b\\
           \intertext{or} -b&<a<b.
         \end{align*}
       \end{description}
     \end{proof}
     {\bf Claim:} If $-b<a<b$ then $\abs{a}<b.$

     \begin{proof}
       
     \end{proof}
 \end{solution}

 \xqed{\lozenge}{}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:sequences1}{}
  Use the definition of convergence to zero to prove the following.
  \begin{description}
  \item[(a)] $\displaystyle\lim_{n\rightarrow\infty}\frac{1}{n^2}=0$
  \begin{solution}{}
    Let $\eps>0$ be given. Take $N>\frac{1}{\sqrt{\eps}}.$ Then for every $n>N$
    \begin{align*}
      \abs{\frac{1}{n^2}} &= \frac{1}{n^2}\\
      &< \frac{1}{N^2}\\
      &< \frac{1}{(\sqrt{\eps})^2}\\
      &= \eps.
    \end{align*}
  \end{solution}
  \item[(b)]
    $\displaystyle\lim_{n\rightarrow\infty}\frac{1}{\sqrt{n}}=0$\xqedhere{3.7in}{\lozenge}{}
  \begin{solution}{}
    Let $\eps>0$ be given. Take $N>\frac{1}{\eps^2}.$ Then for every $n>N$
    \begin{align*}
      \abs{\frac{1}{\sqrt{n}}} &= \frac{1}{\sqrt{n}}\\
      &< \frac{1}{\sqrt{N}}\\
      &< \frac{1}{(\sqrt{\eps^2})}\\
      &= \eps.
    \end{align*}
  \end{solution}
  \end{description}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:sequences2}{}
  Use the definition of convergence to zero to prove 
  $$\lim_{n\rightarrow\infty}\frac{n^2+4n+1}{n^3}=0.\xqedhere{1.75in}{\lozenge}{}$$
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:sequences3}{}
  Let $b$ be a nonzero real number with $|b|<1$ and let
  $\eps>0$.    
\begin{description}
  \item[(a)]  Solve the inequality $|b|^n<\eps$ for  $n$
    \begin{solution}{}
      \noindent{}\underline{\sc First solution:}\\
Since the natural logarithm is a strictly increasing function we know
that if $x<y$ then $\log x < \log y.$ Thus if
      \begin{align*}
        |b|^n &< \eps\\
\intertext{then}
\intertext{Therefore }
        n\log|b| &< \log\eps.\\
\intertext{Since $\abs{b}<1,$ $\log\abs{b}<0$ so }
        n &> \frac{\log\eps}{\log|b|}.\\
      \end{align*}
      \noindent{}\underline{\sc Second solution:}\\
Since $\abs{b}<1$ the $\log_{\abs{b}}(x)$ is a strictly decreasing function so if $x<y$ then $\log x > \log y.$ Thus if
      \begin{align*}
        |b|^n &< \eps\\
\intertext{then}
\intertext{Therefore }
        n &> \log_{\abs{b}}\eps = \frac{\log\eps}{\log|b|}.\\\\
      \end{align*}
      
    \end{solution}
  \item[(b)] Use part (a) to prove
    $\lim_{n\rightarrow\infty}b^n=0.$\xqedhere{2.3in}{\lozenge}{}
    \begin{solution}{}
      Let $\eps>0$ be given. Take $N>\frac{\log\eps}{\log|b|}.$ Then
      for all $n>N$
      \begin{align*}
        n&>\frac{\log(\eps)}{\log\abs{b}}\\
        n\log\abs{b} &< \log(\eps)\\
\intertext{and since the exponential is also a strictly increasing
  function}
\abs{b}^n &< \eps.
      \end{align*}

    \end{solution}
\end {description}

\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:sequences-not converge to zero}{}
  Negate the definition of   $\lim_{n\rightarrow\infty}s_n=0$  to
  provide a formal definition for  \
  $\lim_{n\rightarrow\infty}s_n\neq 0$.\xqed{\lozenge}{}
  \begin{solution}{}
  If $\exists$ $N\in\RR$ such that $\forall$ $\eps>0,$ $\exists$ $n>N$
  such that $$\abs{s_n}>\eps.$$
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:sequences4}{}
  \label{prob:SeriesConverge}{}
  Use the definition to prove  $\lim_{n\rightarrow\infty}\frac{n}{n+100}\neq 0$.\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:sequences5}{}
  Let $b>0$.  Use the definition to prove  
  $\lim_{n\rightarrow\infty}b^{\left(\frac{1}{n}\right)}=1$.  
  [Hint:  You will probably need to separate this into two cases: 
  $0<b<1$ and $b\geq 1$.]\xqed{\lozenge}{}
  \begin{solution}{}
Case 1: Suppose $b=1$. Let $\epsilon>0$ and let $N$ be any real number. If $n>N$, then 
\begin{align*}
\abs{b^{1/n}-1}=\abs{1-1}=0<\epsilon.\\
\end{align*}
Case 2: Suppose $b > 1$. Let $\epsilon >0$ and let $N=\frac{\log (b)}{\log (1+\epsilon)}$. If $n > N$, then 

\begin{align*}
\frac{1}{n}<\frac{1}{N}=\frac{\log (1+\epsilon)}{\log (b)} &\implies \frac{1}{n}\log (b)<\log (1+\epsilon)\\
&\implies \log (b^{1/n})<\log (1+\epsilon)\\
&\implies b^{1/n}<1+\epsilon \\
&\implies b^{1/n}-1=\abs{b^{1/n}-1}<\epsilon.\\
\end{align*}
Case 3.1: Suppose $0<b<1$. Let $0<\epsilon<1$ and let 
$N=\frac{\log (b)}{\log(1-\epsilon)}$. If $n > N$, then 

\begin{align*}
\frac{1}{n}<\frac{1}{N}=\frac{\log (1-\epsilon)}{\log (b)} &\implies \frac{1}{n}\log (b)>\log (1-\epsilon)\\
&\implies \log (b^{1/n})>\log (1-\epsilon) \text{ (since $\log(b)<0$}\\
&\implies b^{1/n}>1-\epsilon \\
&\implies b^{1/n}-1>-\epsilon\\
&\implies 1-b^{1/n}=\abs{b^{1/n}-1}<\epsilon.\\
\end{align*}
Case 3.2: Suppose $0<b<1$. Let $\epsilon \geq 1$ and let 
$N$ be any real number. If $n > N$, then 
\begin{align*}
b>0 &\implies b^{1/n}>0\\
&\implies -b^{1/n}<0\\
&\implies 1-b^{1/n}<1\leq \epsilon\\
&\implies \abs{b^{1/n}-1}<\epsilon.\\
\end{align*}
Therefore we can conclude that $\lim_{n \to \infty} b^{1/n}=1$.
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}\
\LabelProblem{prob:sequences!not converge to s}{}
\begin{description}
\item[(a)] Provide a rigorous definition for 
  $\lim_{n\rightarrow\infty}s_n\neq s.$
  \begin{solution}{}
    Let $\left(s_n\right)_{n=1}^\infty$ be a sequence. We say that
    $s_n$ does {\bf not} converge to $s$ $ \left((s_n) \not\rightarrow
      s\right)$ if there is a real number, $\eps,$ such that for every
      $N\in\RR$ there is an integer $n,$ $n\in\NN,$ such that
    \[
    \abs{s_n-s}>\eps.
    \]
  \end{solution}
\item[(b)] Use your definition to show that for any
  real number $a$,  
  $\lim_{n\rightarrow\infty}\left(\left(-1\right)^n\right)\neq a$. \
  [Hint:  Choose $\eps=1$ and use the fact that
  $\Big|a-(-1)^n\Big|<1$ is equivalent to
  $\left(-1\right)^n-1<a<\left(-1\right)^n+1$ to show that no choice
  of $N$ will work for this $\eps$.]
  \begin{solution}{}
    \noindent{}{\bf Proof by Contradiction:} Suppose that
    $\limit{n}{\infty}{(-1)^n}=a.$ 

    In that case for every $\eps>0$ there is an $N\in\RR$ such that if
    $n>N$
    \begin{align*}
      \abs{a-(-1)^n} &< \eps\\
     \intertext{which is equivalent to }
     -1&<a-(-1)^n<1\\
     \intertext{or}
     (-1)^n-1<a<(-1)^n+1.
    \end{align*}
    There is at least one value of $n>N$ which is even and one which
    is odd. In both cases this last inequality must be satisfied.
    \begin{description}
     \item[\underline{Case 1:}] $n$ is even. In this case 
       \[   0<a<2.\] So $a$ is positive.
       \item[\underline{Case 2:}] $n$ is odd. In this case 
       \[   -2<a<0.\] So $a$ is negative.
     \end{description}
    Since both cases must be true and $a$ cannot be {\bf
      simultaneously} positive and negative we have a contradiction. 
    Therefore $(-1)^n$ diverges.
  \end{solution}
\end{description}\xqed{\lozenge}{}

\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:ConstantSequence}{the limit of a constant sequence}
  Let $\left(c\right)_{n=1}^\infty=(c,c,c,\ldots)$ be a constant
  sequence.  Show that   $\lim_{n\rightarrow\infty}c=c.$\xqed{\blacktriangle}{}
  \begin{solution}{}
    Let $\eps>0$ be given. Take $N=1.$ Then for every integer $n>N$ 
\[
\abs{c-c} = 0 < \eps.
\]
Therefore $\limit{n}{\infty}{c}=c.$
  \end{solution}
\newpage{}
\end{problem}

\begin{lemma}\ 
\label{lem:triangle}
\IndexLemma{lem:triangle}
  \begin{description}
  \item[(a) Triangle Inequality] Let $a$ and $b$ be real numbers.  Then
$$
\abs{a+b}\leq\abs{a}+\abs{b}.
$$
\item[(b) Reverse Triangle Inequality] Let $a$ and $b$ be real numbers. 
    Then 
$$
|a|-|b|\leq\abs{a-b}
\xqedhere{1.7in}{\blacktriangle}{}$$
\end{description}
\end{lemma}
\hrule{}
\begin{problem}\ 
\LabelProblem{prob:ReverseTriangleInequality}{}
  \begin{description}
  \item[(a)] Prove Lemma~\ref{lem:triangle}.  [ Hint:  For the Reverse Triangle Inequality,
  consider $|a|=|a-b+b|$.]
\item[(b)]  Show $\abs{\abs{a}-\abs{b}}\leq \abs{a-b}.$  [ Hint:  You want to show
  $|a|-|b|\leq|a-b|$ and $-(|a|-|b|)\leq|a-b|.$]\xqedhere{3.1in}{\lozenge}{}
\end{description}

\begin{solution}{}
\leftline{{\bf  Part (a) of the Lemma: The Triangle Inequality}}\\
\[
\abs{a+b}\leq\abs{a}+\abs{b}
\]

\begin{proof}
Observe that
\begin{align*}
  -\abs{a} &\le a \le \abs{a}\\
\intertext{and}
  -\abs{b} &\le b \le \abs{b}.
\end{align*}
Adding these gives
\[
-(\abs{a}+\abs{b}) \le a+b \le \abs{a} +\abs{b}.
\]
Therefore
\[\abs{a+b} \le \abs{a} +\abs{b}.\]
\end{proof}
\leftline{{\bf Part (b) of the Lemma: The Reverse Triangle  Inequality}}\\
\[
\abs{a}-\abs{b}\leq\abs{a-b}
\]
\begin{proof}
  Observe that
  \begin{align*}
    \abs{a} &= \abs{a-b+b}.\\
    \intertext{So, by part (a) above:} \abs{a}&\le\abs{a-b}+\abs{b}.
    \intertext{Therefore} \abs{a}-\abs{b}&\le\abs{a-b}.
  \end{align*}
\end{proof}

\leftline{\bf Part (b) of the Problem.}
\begin{proof}
\leftline{\bf{} To Show:  $\abs{\abs{a}-\abs{b}}\leq \abs{a-b}$}
  From part (b) of the lemma (The Reverse Triangle Inequality), we have
  \begin{align*}
    \abs{a}-\abs{b}&\le\abs{a-b}.\\
\intertext{Also from part (b) we have}
    \abs{b}-\abs{a}&\le\abs{b-a}.\\
\intertext{Therefore}
    \abs{a}-\abs{b}&\ge-\abs{b-a} = -\abs{a-b}.\\
\intertext{Combining these gives}
-\abs{a-b}\le\abs{a}-\abs{b}\le\abs{a-b}\\
\intertext{which is equivalent to }
\abs{\abs{a}-\abs{b}}&\le\abs{a-b}.
  \end{align*}
\end{proof}
\end{solution}
\newpage{}
\end{problem}

\begin{theorem}
\label{thm:SumOfSequences}{}
\IndexTheorem{thm:SumOfSequences}{}
  If  $\displaystyle\lim_{n\rightarrow\infty}a_n=a$  and  
  $\displaystyle\lim_{n\rightarrow\infty}b_n=b$, then 
  $\displaystyle\lim_{n\rightarrow\infty}\left(a_n+b_n\right)=a+b$.\xqed{\blacktriangle}{}
\end{theorem}
\hrule{}
\begin{problem}
\LabelProblem{prob:SumOfSequences}{}
  Prove Theorem~\ref{thm:SumOfSequences}.\xqed{\lozenge}{}
  \begin{solution}{}
    Let $\eps>0$ be given. 

    Since $\limit{n}{\infty}{a_n}=a$ there is
    an $ N_1\in\RR$  such that $n>N_1\imp\abs{a_n-a}<\frac{\eps}{2}.$ 

    Since $\limit{n}{\infty}{b_n}=b$ there is
    an $ N_2\in\RR$  such that $n>N_2\imp\abs{b_n-b}<\frac{\eps}{2}.$

    Take $N>\max(N_1,N_2).$ Then if $n>N$ we have
    \begin{align*}
      \abs{(a_n-b_n)-(a-b)} &= \abs{(a_n- a) + (b-b_n)}\\
       &<\abs{(a_n- a)} + \abs{(b-b_n)}\\
       &= \frac{\eps}{2} + \frac{\eps}{2}\\
       &=\eps.
    \end{align*}
Therefore $\limit{n}{\infty}{(a_n+b_n)} = a+b.$
  \end{solution}
\newpage{}
\end{problem}

\begin{lemma}{\bf{}(A convergent sequence is bounded.)}
\label{lemma:BoundedConvergent}
\IndexLemma{lemma:BoundedConvergent}
%\index{Lemma by description!convergent sequences are bounded}
    If 
  $\lim_{n\rightarrow\infty}a_n=a$, then there exists $B>0$ such that
  $|a_n|\leq B$ for all $n$.\xqed{\blacktriangle}{}
\end{lemma}

\begin{problem}
\LabelProblem{prob:BoundedConvergent}{}
Prove Lemma~\ref{lemma:BoundedConvergent}.  [ Hint: We know that
there exists $N$ such that if $n>N$, then $\abs{a_n-a}<1$.  Let
$B=\max\left(\abs{a_1},\abs{a_2},\ldots,\abs{a_{\lceil{N}\rceil}},\abs{a}+1\right),$
where $ \lceil{N}\rceil$ represents the smallest integer greater than or equal
to $N$. Also, notice that this is not a convergence proof so it is not
safe to think of $N$ as a large number.\footnote{Actually, this is a
  dangerous habit to fall into even in convergence proofs.}]\xqed{\lozenge}{}
\begin{solution}{}
  Since $\abs{a_n-a}$ approaches zero as $n$ increases  there is an integer $N\in\NN$ such if $n>N$ then 
\[ 
\abs{a-a_n} < 1.
\]
Let $B=\max(\abs{a_1},\ldots,\abs{a_N},\abs{a}+1).$ 
There are two cases:
\begin{description}
\item[Case 1:] $1\le n \le N$

In this case $\abs{a_n} \le \max(\abs{a_1},\ldots,\abs{a_N}) \le\max(\abs{a_1},\ldots,\abs{a_N},\abs{a}+1).$ 
\item[Case 2:] $n>N$

In this case we have
\begin{align*}
  \abs{a_n}-\abs{a}&<\abs{a_n-a}\\
\intertext{by the Reverse Triangle Inequality. Thus}  
  \abs{a_n}-\abs{a}&<1\\
\intertext{so}
  \abs{a_n}&<\abs{a}+1<B.\\
\end{align*}

Therefore a convergent sequence is bounded.
\end{description}

\end{solution}
\newpage{}
\end{problem}

\begin{theorem}
\label{thm:LimitOfProduct}
\IndexTheorem{thm:LimitOfProduct}{}
   If  $\displaystyle\lim_{n\rightarrow\infty}a_n=a$  and  
   $\displaystyle\lim_{n\rightarrow\infty}b_n=b$,  then 
   $\displaystyle\lim_{n\rightarrow\infty}\left(a_n  b_n\right)=a  b$.\xqed{\blacktriangle}{}
 \end{theorem}

\begin{problem}
\LabelProblem{prob:sequences-termwise product}{}
  Prove Theorem~\ref{thm:LimitOfProduct}.\xqed{\lozenge}{}
  \begin{solution}{}
    Let $\eps>0$ be given. Take $B$ to be an upper bound of
    $\abs{a_n}$  for $n=1, 2, \ldots,$ and  take
    $\delta<\min\left(\frac{\eps}{2B}, \frac{\eps}{2(\abs{b}
        +1)}\right).$ Then $\exists N\in\RR$ such that $\forall
    n>N, \abs{a-a_n}<\delta$ and $\abs{b-b_n}<\delta.$

Therefore
\begin{align*}
  \abs{a_nb_n-ab} &= \abs{a_nb_n-a_nb + a_nb-ab}\\
  &\le \abs{a_n}\abs{b_n-b} + \abs{b}\abs{a_n-a}\\
  &\le \abs{a_n}\abs{b_n-b} +(\abs{b}+1)\abs{a_n-a}\\
  &\le B        \abs{b_n-b} +(\abs{b}+1)\abs{a_n-a}\\
  &\le \frac{B\eps}{2B} +    \frac{\eps(\abs{b}+1)}{2(\abs{b} +1)}\\
  &\le \eps.
\end{align*}
Therefore    $\displaystyle\lim_{n\rightarrow\infty}\left(a_n  b_n\right)=a  b$.
  \end{solution}
\newpage{}
\end{problem}

\begin{corollary}{\bf{}(Corollary to Theorem~\ref{thm:LimitOfProduct}.)}
\label{cor:1}
\IndexCorollary{cor:1}{}
   If  $\displaystyle\lim_{n\rightarrow\infty}a_n=a$ and
  $c\in\mathbb{R}$, then   $\displaystyle\lim_{n\rightarrow\infty}c\cdot
  a_n=c\cdot a.$\xqed{\lozenge}{}
\end{corollary}

\begin{problem}
\LabelProblem{prob:sequences-constant times}{}
  Prove the above corollary to Theorem~\ref{thm:LimitOfProduct}.\xqed{\lozenge}{}
  \begin{solution}{}
    This follows immediately from Theorem~\ref{thm:LimitOfProduct} and
    Problem~\ref{prob:ConstantSequence}.
  \end{solution}
\newpage{}
\end{problem}

\begin{theorem}
\label{thm:LimitOfQuotient}
\IndexTheorem{thm:LimitOfQuotient}{}
  Suppose   $\displaystyle\lim_{n\rightarrow\infty}a_n=a$  and  
  $\displaystyle\lim_{n\rightarrow\infty}b_n=b$.  Also suppose $b\neq 0$ and
  $b_n\neq 0,\forall\,n.$  Then  
  $\displaystyle\lim_{n\rightarrow\infty}\left(\frac{a_n}{b_n}\right)=\frac{a}{b}$. \xqed{\blacktriangle}{}
\end{theorem}

\begin{problem}
\LabelProblem{prob:sequences-termwise quotient}{}
  Prove Theorem~\ref{thm:LimitOfQuotient}.\xqed{\lozenge}{}
  \begin{solution}{}
    \begin{align*}
      \abs{\frac{a_n}{b_n}-\frac{a}{b}}&=\abs{\frac{a_n}{b_n}-\frac{a_n}{b}+\frac{a_n}{b}-\frac{a}{b}}\\
                                       &\le\abs{\frac{a_n}{b_n}-\frac{a_n}{b}}+\abs{\frac{a_n}{b}-\frac{a}{b}}\\
                                       &\le\abs{a_n}\abs{\frac{1}{b_n}-\frac{1}{b}}+\abs{\frac{1}{b}}\abs{a_n-a}\\      
    \end{align*}
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:sequences-identifying theorems used in a complex problem}{}
Identify all of the theorems implicitly used to show that
$$
\lim_{n\rightarrow\infty}\frac{3n^3-100n+1}{5n^3+4n^2-7}=\lim_{n%
  \rightarrow\infty}\frac{n^3\left(3-\frac{100}{n^2}+\frac{1}{n^3}\right)}{n^3%
  \left(5+\frac{4}{n}-\frac{7}{n^3}\right)}=\frac{3}{5}.
$$
Notice that this presumes that all of the individual limits
exist. This will become evident as the limit is
decomposed.\xqed{\lozenge}{}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{theorem}{\bf(Squeeze Theorem for Sequences)}
\label{thm:SqueezeTheorem}
\IndexTheorem{thm:SqueezeTheorem}{}
 Let
  $\left(r_n\right),\left(s_n\right),$ and $\left(t_n\right)$ be
  sequences of real numbers with $r_n\leq s_n\leq t_n,\forall$
  positive integers $n$.  Suppose 
  $\lim_{n\rightarrow\infty}r_n=s=\lim_{n\rightarrow\infty}t_n.$ 
  Then $\left(s_n\right)$ must converge and 
  $\lim_{n\rightarrow\infty}s_n=s$.\xqed{\blacktriangle}{}
\end{theorem}

\begin{problem}
\LabelProblem{prob:sequences-Squeeze Theorem}{}
  Prove Theorem~\ref{thm:SqueezeTheorem}{}.  \lbrack Hint:  This is probably a
  place where you would want to use
  $s-\eps<s_n<s+\eps$ instead of 
  $|s_n-s|<\eps$.\rbrack\xqed{\lozenge}{}
  \begin{solution}{}
    Let $\eps>0$ be given. Since $r_n\rightarrow s$  $\exists
    N_1\in\RR$ such that $\forall n>N_1$ $r_n\in(s-\eps,s+\eps).$

Since $t_n\rightarrow s$  $\exists
    N_2\in\RR$ such that $\forall n>N_2$ $t_n\in(s-\eps,s+\eps).$

Thus
\[s-\eps<r_n\le s_n\] and \[s_n\le t_n < s+\eps.\]

Therefore $\displaystyle s-\eps < s_n < s+\eps.$ 

Therefore $\limit{n}{\infty}{s_n}=s.$
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
  \LabelProblem{prob:sequences-integers diverge to infinity}{}
Show that $\left(n\right)_{n=1}^\infty$ diverges to infinity.\xqed{\lozenge}{}
\begin{solution}{}
  Take $\eps=1/2$ and let $N\in\RR$ be given. Then there is an integer
  $n$ such that $n>N$ and $n>1>1/2.$  

Therefore $\left(n\right)_{n=1}^\infty$ diverges to infinity.
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
  \LabelProblem{prob:diverge to infinity implies diverge}{}
Show that if $\left(a_n\right)_{n=1}^\infty$ diverges to infinity then
$\left(a_n\right)_{n=1}^\infty$ diverges.\xqed{\lozenge}{}
\begin{solution}{}

\noindent{}{\bf{}First Proof}\\
{\bf{}Proof by Contradiction:} Suppose that
    $\left(a_n\right)_{n=1}^\infty$ diverges to infinity and that it
    converges. 

    If the sequence converges then it is bounded, by
    Lemma~\ref{lemma:BoundedConvergent}. But if it is bounded then it
    cannot diverge to infinity. Thus we have a contradiction.

    Therefore if a sequence diverges to infinity, then it diverges.
\vskip1cm{}
\noindent{}{\bf{}Second Proof}\\
Let $\eps>0,$ and $ r\in\RR$ be fixed real numbers. Since
$\left(a_n\right)_{n=1}^\infty$ diverges to infinity there is an
$N\in\RR$ such that for all $ n>N,$ $a_n>0$ and $a_n \ge \eps + \abs{r}.$
Therefore
\[
 \abs{a_n-r} > \abs{a_n}-\abs{r} = a_n -\abs{r}  > \eps.
\]

Therefore 
$\left(a_n\right)_{n=1}^\infty$ diverges.
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
  \LabelProblem{prob:div to infty sum}{}
Suppose $\limit{n}{\infty}{a_n}=\infty$ and
$\limit{n}{\infty}{b_n}=\infty.$
\begin{description}
\item[(a)] Show that $\limit{n}{\infty}{a_n+b_n}=\infty$
\item[(b)] Show that $\limit{n}{\infty}{a_nb_n}=\infty$
\item[(c)] Is it true that 
  $\limit{n}{\infty}{\frac{a_n}{b_n}}=\infty?$ Explain.\xqedhere{2.25in}{\lozenge}{}
\end{description}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
  \LabelProblem{prob:diverge to pos or neg infty combinations}{}
Suppose $\limit{n}{\infty}{a_n}=\infty$ and
$\limit{n}{\infty}{b_n}=-\infty$ and $\alpha\in\RR.$ Prove or give a counterexample:
\begin{description}
\item[(a)] $\limit{n}{\infty}{a_n+b_n}=\infty$
\begin{solution}{}
This statement is false. \\
{\sc Counterexample:} Take $a_n =n, $ and $b_n=-n.$ Then
$\limit{n}{\infty}{a_n+b_n}=-\infty.$
\end{solution}
\item[(b)] $\limit{n}{\infty}{a_nb_n}=-\infty$
\begin{solution}{}
  This statement is true. \\
  \begin{proof}
    Let $r\in\RR, r>1$ be given.
    Since $a_n\rightarrow \infty$ there is a real number $N_1$ such
    that for every $n>N_1,$ $a_n>\abs{r}.$ 

    Since $b_n\rightarrow -\infty$ there is a real number $N_2$ such
    that for every $n>N_2,$ $b_n<-\abs{r}.$ Take $N>\max(N_1,N_2).$
    Then $\forall n>N,$ 
    \begin{align*}
      a_nb_n &< \abs{r}(-\abs{r}\\
      &= -\abs{r^2}\\
      &<-\abs{r}.
    \end{align*}
Therefore $a_nb_n\rightarrow -\infty.$
  \end{proof}

\end{solution}
\item[(c)] $\limit{n}{\infty}{\alpha a_n}=\infty$
\begin{solution}{}
This statement is false. \\
{\sc Counterexample:} Take $\alpha<0.$ Then $\limit{n}{\infty}{\alpha a_n}=-\infty$
\end{solution}
\item[(d)] $\limit{n}{\infty}{\alpha b_n}=-\infty$\xqedhere{3.5in}{\lozenge}{}
\begin{solution}{}
This statement is false. \\
{\sc Counterexample:} Take $\alpha<0.$ Then $\limit{n}{\infty}{\alpha a_n}=\infty$
\end{solution}
\end{description}
\newpage{}
\end{problem}

 \begin{problem}
   \LabelProblem{prob:diverge but not to infinity}{}
 Show that each of the following sequences diverge.
 \begin{description}
 \item[(a)] $\left(\left(-1\right)^n\right)_{n=1}^\infty$
 \item[(b)] $\left(\left(-1\right)^nn\right)_{n=1}^\infty$
 \item[(c)] $a_n =
   \begin{cases}
     1& \text{ if $n=2^p$ for some $p\in\NN$}\\
     \frac1n& \text{otherwise.}
   \end{cases}$\xqedhere{2.3in}{\lozenge}{}
 \end{description}
 \begin{solution}{}
   
 \end{solution}
 \newpage{}
\end{problem}

 \begin{problem}
 \LabelProblem{prob:sequences-divergence to infinity}{}
 Suppose that $\left(a_n\right)_{n=1}^\infty$ diverges but not to
 infinity and that $\alpha$ is a real number. What conditions on
 $\alpha$ will guarantee that:
   \begin{description}
   \item[(a)] $\left(\alpha a_n\right)_{n=1}^\infty$ converges?
   \item[(b)] $\left(\alpha a_n\right)_{n=1}^\infty$ diverges?
   \end{description}\xqed{\lozenge}{}
   \begin{solution}{}
     There are two cases:  $\alpha\neq0$ and $\alpha=0.$  
     \begin{description}
     \item[Case 1: $\alpha\neq0$] Since
       $\left(a_n\right)_{n=1}^\infty$ diverges there is an $\eps_1$
       such that $\forall\ r_1\in\RR, \text{ and } N\in\RR\  \exists\ n>N$ such that 
       \[
       \abs{a_n-r_1}>\eps_1.
       \]
       
       Take $\eps=\abs{\alpha}\eps_1$ and $r=r_1\alpha.$ Then $\forall\
       N\in\RR$ such that 
       \begin{align*}
         \abs{a_n-r_1} &> \eps_1\\
         \abs{a_n-\frac{r}{\alpha}} &> \frac{\eps}{\abs{\alpha}}\\
         \frac{1}{\abs{\alpha}}\abs{\alpha a_n-r} &>
         \frac{\eps}{\abs{\alpha}}.\\
       \end{align*}
       Therefore $\forall\ r\in\RR, \text{ and } N\in\RR\  \exists\
       n>N$ such that  
       \[
       \abs{\alpha a_n-r} > \eps
       \]
       so $\left(\alpha a_n\right)_{n=1}^\infty$ diverges.
     \item[Case 2: $\abs{\alpha}=0$] This is the special case of
       Problem~\ref{thm:ConstantSequence} where $c=0.$
     \end{description}
   \end{solution}
 \newpage{}
\end{problem}

 \begin{problem}
   \LabelProblem{prob:GeometricSequenceDivergence}{Geometric
     Sequence!divergence condition}
   Show that if $\abs{r}>1$ then $\left(r^n\right)_{n=1}^\infty$
   diverges. Will it diverge to infinity?\xqed{\lozenge}{}
   \begin{solution}{}
     \noindent{\bf{}Proof 1:} Let $N\in\RR$ be given. Take
     $n>\frac{\ln(N)}{\ln(\abs{r})}.$ Then
     \begin{align*}
       \abs{r}^n &>\abs{r^{\frac{\ln(N)}{\ln(\abs{r})}}}\\
       &=N.
     \end{align*}
     Therefore $\abs{r}^n$ diverges to infinity.

     \noindent{\bf{}Case 1, $r>1:$} In this case $\abs{r} = r$ so $r^n$
       also diverges to infinity.

     \noindent{\bf{}Case 2, $r<-1:$} In this case $\abs{r} = -r$ so
       $r^n$ will be positive when $n$ is even, and negative when $n$
       is odd. Therefore $r^n$ does not diverge to infinity.

     \noindent{\bf{}Proof 2:} Since $\abs{r}>1,$ $\abs{r}= 1+\alpha$
     for some $\alpha>0.$ Therefore
     \begin{align*}
       \abs{r}^n &= 1+\alpha r + \frac{\alpha}{2}r^2+\ldots \\
                 &> 1+\alpha r.
\intertext{Let $N\in\RR^+$ be given. Then $\forall$ $n>\frac{N^{1/n}-1}{\alpha}$} \\
       \abs{r}^n &> \abs{1+n\alpha}^n \\
       &=                (1+n\alpha)^n \\
       &\ge
         \left(1+\left(\frac{N^{1/n}-1}{\alpha}\right)\alpha\right)^n \\
       &=(1+N^{1/n}-1)^n \\
       &=N.
     \end{align*}
     Therefore $\abs{r}^n$ diverges to infinity.

     \noindent{\bf{}Case 1, $r>1:$} In this case $\abs{r} = r$ so $r^n$
       also diverges to infinity.

     \noindent{\bf{}Case 2, $r<-1:$} In this case $\abs{r} = -r$ so
       $r^n$ will be positive when $n$ is even, and negative when $n$
       is odd. Therefore $r^n$ does not diverge to infinity.

       
   \end{solution}
 \newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:sequences!termwise absolute value}{}
  Prove that if  $\lim_{n\rightarrow\infty}s_n=s$ then 
  $\lim_{n\rightarrow\infty}|s_n|=|s|.$  Prove that the converse is
  true when $s=0,$ but it is not necessarily true otherwise.\xqed{\lozenge}{}
  \begin{solution}{}
    \begin{itemize}
    \item To Show: if  $\lim_{n\rightarrow\infty}s_n=s$ then $\lim_{n\rightarrow\infty}|s_n|=|s|.$

      \begin{proof}
        Let $\eps>0$ be given, and suppose $s_n\rightarrow s.$ Then by
        definition $\exists\,N\in\RR$ such that $\forall\, n>N$
        $\abs{{s_n-s}} < \eps.$

By Problem~\ref{prob:ReverseTriangleInequality}, part (b) we have 
$$
        \abs{\abs{s_n}-\abs(s)} < \abs{{s_n-s}} < \eps.
$$
Therefore $\abs{s_n}\rightarrow \abs{s}.$
      \end{proof}
    \item To Show: If $\abs{s_n}\rightarrow 0$ then $s_n\rightarrow
      0.$

      \begin{proof}
        Let $\eps>0$ be given
        Assume that  $\abs{s_n}\rightarrow 0.$ Then $\exists\,
        N\in\RR$ such that $\forall\, n>N$
        $\abs{s_n}=\abs{\abs{s_n}}<\eps.$
        Therefore $s_n\rightarrow0.$
      \end{proof}
    \item Counterexample: Consider $s_n=-1+\frac1n,$ $n=1, 2, 3,
      \ldots.$
      
       Clearly $s_n\rightarrow-1$ while $\abs{s_n} = 1-\frac1n
       \rightarrow1 \neq -1.$
    \end{itemize}
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}\ 
\LabelProblem{prob:sequences-uniqueness of limit}{}
  \begin{description}
  \item[(a)] Let $\left(s_n\right)$ and $\left(t_n\right)$ be sequences with
  $s_n\leq t_n,\forall n.$  Suppose 
  $\lim_{n\rightarrow\infty}s_n=s$ and 
  $\lim_{n\rightarrow\infty}t_n=t.$  Prove  $s\leq t.$  \lbrack
  Hint:  Assume for contradiction, that $s>t$ and use the definition
  of convergence with $\eps=\frac{s-t}{2}$ to produce an $n$ with
  $s_n>t_n.$\rbrack  \xqed\lozenge
  \begin{solution}{}
    \begin{proof}
      {\sc By Contradiction:} Assume that $s>t.$\\
      Since $s_n\rightarrow s$ there is a real number $N_1$ such that $\forall n>N_1:$
      \[
      s_n\in\left(s-\frac{s-t}{2},s+\frac{s-t}{2}\right)
      \]
      or
      \[
      s_n\in\left(\frac{s+t}{2},\frac{3s-t}{2}\right).
      \]
      Therefore 
      \[
      s_n>\frac{s+t}{2}.
      \]
      
      Similarly, $t_n\in\left(\frac{s-3t}{2},\frac{s+t}{2}\right)$ which implies that 
      \[
      t_n<\frac{s+t}{2}.
      \]
      Therefore
      \[
      t_n<\frac{s+t}{2}< s_n
      \]
      which contradicts our assumption that $s_n\leq t_n,\forall n.$ Therefore $s\le t.$
    \end{proof}
  \end{solution}
\item[(b)] Prove that if a sequence converges, then its limit is unique. 
    That is, prove that if   $\lim_{n\rightarrow\infty}s_n=s$ and \
    $\lim_{n\rightarrow\infty}s_n=t$, then $s=t$.\xqed\lozenge
    \begin{solution}
      \begin{proof}
        Suppose $a_n\rightarrow s$ and $a_n\rightarrow t.$ Take
        $s_n=a_n$ and $t_n=a_n.$ 

        Since $s_n \le t_n,$ $s_n\rightarrow s,$ and $t_n\rightarrow
        t,$ we see by part (a) above that: \[s\le t.\]

        Also since $t_n\le s_n,$ $t_n\rightarrow t,$ and
        $s_n\rightarrow s,$ we see by part (a) above that: \[t\le s.\]

        Since $s\le t$ \underline{and} $t\le s$ we conclude that $s=t.$
      \end{proof}
    \end{solution}
  \end{description}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:bounded-sequence-over-n-converges}{}
  Prove that if the sequence $\left(s_n\right)$ is bounded then 
  $\lim_{n\rightarrow\infty}\left(\frac{s_n}{n}\right)=0$.\xqed{\lozenge}{}
  \begin{solution}{}
Let $\eps>0$ be given. Suppose $\abs{s_n}<B\ne0, \forall\ n\in\NN.$ Take $N>\frac{B}{\eps}.$ Then
\[  \abs{\frac{s_n}{n}} \le \frac{B}{n} \le \frac{B}{N} = \frac{B}{B/\eps}= \eps.\]
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}\ 
\LabelProblem{prob:series-geometric}{}
  \begin{description}
  \item[(a)]  Prove that if $x\neq 1$, then
    \[
    1+x+x^2+\cdots+x^n=\frac{1-x^{n+1}}{1-x}.
    \]\xqed{\lozenge}
  \begin{solution}{}
    Observe that
    \[1-x^{n+1} = (1+x+x^2+\cdots+x^n)(1-x).\]
    Therefore, when $x\neq1$ we have
    \[1+x+x^2+\cdots+x^n=\frac{1-x^{n+1}}{1-x}.\]
  \end{solution}
\item[(b)] Use (a) to prove that if $|x|<1,$ then 
    $\lim_{n\rightarrow\infty}\left(\sum_{j=0}^nx^j\right)=\frac{1}{1-x}.$\xqed{\lozenge}
  \begin{solution}{}
    We will show that $\limit{n}{\infty}{\abs{\sum_{j=0}^n x^j -
        \frac{1}{1-x}}} = 0,$ from which the conclusion follows
    immediately.

    Let $\eps>0$ be given. Observe that $x$ is fixed, and that we are
    assuming that $\abs{x}<1.$ Take $N\in\RR,$ such that $\abs{x^{n+1}}<\eps\abs{1-x}.$ Then
    \begin{align*}
      \abs{\sum_{j=0}^n x^j - \frac{1}{1-x}} 
            &= \abs{\frac{1-x^{n+1}}{1-x} - \frac{1}{1-x}} \\ 
            &= \frac{\abs{x^{n+1}}}{\abs{1-x}}\\
            &< \frac{\eps\abs{1-x}}{\abs{1-x}}\\
            &= \eps.
    \end{align*}
    Therefore $\limit{n}{\infty}{\abs{\sum_{j=0}^n x^j -
        \frac{1}{1-x}}} = 0.$
  \end{solution}
  \end{description}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:sequences-ratio of}{}
  Prove $$\lim_{n\rightarrow\infty}\frac{a_0+a_1n+a_2n^2+%
    \cdots+a_kn^k}{b_0+b_1n+b_2n^2+\cdots+b_kn^k}=\frac{a_k}{b_k},$$
  provided $b_k\neq 0$.  \lbrack Notice that since a polynomial only
  has finitely many roots, then the denominator will be non-zero when
  $n$ is sufficiently large.\rbrack\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:sequences-diffenences of}{}
  Prove that if  $\lim_{n\rightarrow\infty}s_n=s$ and 
  $\lim_{n\rightarrow\infty}\left(s_n-t_n\right)=0,$ then 
  $\lim_{n\rightarrow\infty}t_n=s.$\xqed{\lozenge}{}
  \begin{solution}{}
    Let $\eps> 0$ be given. 

  Since $\limit{n}{\infty}{s_n-t_n} =0,\ \exists N_1\in\RR$ such that
  $n>N_1\imp\abs{s_n-t_n}<\frac{\eps}{2}.$

  Since $\limit{n}{\infty}{s_n} =s, \ \exists N_2\in\RR$ such that
  $n>N_2\imp\abs{s_n-s}<\frac{\eps}{2}.$

  Take $N=\max(N_1,N_2).$ Then for every $n>N,$
  \begin{align*}
    \abs{s-t_n} &= \abs{s-s_n+s_n-t_n}\\
    &\leq \abs{s-s_n} + \abs{s_n-t_n}\\
    &= \eps/2 +\eps/2\\
    &= \eps.
  \end{align*}
Therefore $\lim_{n\rightarrow\infty}t_n=s.$
  \end{solution}
\vskip1cm{}
  \begin{solution}{\underline{\bf Alternative Solution}}
    Since $(a_n)$  and $(s_n-t_n)$ both converge we have
    \begin{align*}
      \limit{n}{\infty}{t_n} &=\limit{n}{\infty}{\left[s_n-(s_n-t_n)\right]} \\
                             &=\limit{n}{\infty}{s_n}-\limit{n}{\infty}{(s_n-t_n)} \\
                             &= s-0\\
                             &= s.
    \end{align*}
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}\ 
\LabelProblem{prob:sequences-bounded}{}
  \begin{description}
  \item[(a)] 
    Prove that if  $\lim_{n\rightarrow\infty}s_n=s$ and $s<t,$ then there
    exists a real number $N$ such that if $n>N$ then $s_n<t.$
    \begin{solution}{}
      Since $s_n\rightarrow s\ \exists N\in\RR$ such that $n>N\imp
      \abs{s_n-s}<t-s.$ Therefore
      \begin{alignat*}{3}
        s-t &<s_n-s&&<t-s\\
        2s-t&<\ \ s_n  &&<t.\\
      \end{alignat*}
      In particular \[s_n<t.\]
    \end{solution}
  \item[(b)]
    Prove that if $\lim_{n\rightarrow\infty}s_n=s$ and $r<s,$ then there
    exists a real number $M$ such that if $n>M$ then
    $r<s_n.$\xqedhere{2.5in}{\lozenge}{}
    \begin{solution}{}
      By Corollary~\ref{cor:1}, if $s_n\rightarrow s$ then
      $-s_n\rightarrow -s.$ If $r<s$ then $-s<-r.$ Thus
      $\left(-s_n\right)_{n=0}^\infty, -s,$ and $-r$ satisfy all of
      the conditions of part (a) of this problem. Therefore
      \begin{align*}
        -s_n&<-r \text{ or }\\
        r&<s_n.
      \end{align*}
    \end{solution}
\end{description}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:RatioTest}{}
  Suppose $\left(s_n\right)$ is a sequence of positive numbers such
  that
  $$
\lim_{n\rightarrow\infty}\left(\frac{s_{n+1}}{s_n}\right)=L.
$$
  \begin{description}
  \item[(a)] Prove that if $L<1,$ then  
  $\lim_{n\rightarrow\infty}s_n=0.$
\lbrack Hint:  Choose $R$ with $L<R<1.$  By the previous problem,  $\exists$ $N$ such that if
    $n>N$, then $\frac{s_{n+1}}{s_n}<R.$  Let $n_0>N$ be fixed and show
    $s_{n_0+k}<R^ks_{n_0}.$  Conclude that  
    $\lim_{k\rightarrow\infty}s_{n_0+k}=0$ and let $n=n_0+k.$\rbrack
\begin{solution}{}
  Choose $R$ such that $\abs{L}<R<1.$ Then by
  problem~\ref{prob:sequences-bounded}{} $\exists\ N\in\RR$ such that
  $n>N\imp\frac{s_{n+1}}{s_n}<R.$ Take $n_0>N.$ 

\underbar{\bf{}Claim 1:} $\forall\ k\in\NN,\  s_{n_0+k}<R^ks_{n_0}.$\\
\underbar{\bf{}Proof of Claim 1:} (Proof by Induction on $k$.)\\
{\bf Base case $(k=1):$} Since $n_0>N,$
\begin{align*}
  \frac{s_{n_0+1}}{s_{n_0}} &< R \text{ or }\\
        s_{n_0+1}           &< Rs_{n_0}.
\end{align*}
{\bf Induction Hypothesis:}  $s_{n_0+(k-1)}<R^{k-1}s_{n_0}$\\
\begin{align*}
  \frac{s_{n_0+k}}{s_{n_0+(k-1)}}&< R\\
        s_{n_0+k}                &< Rs_{n_0+(k-1)}.\\
\intertext{Therefore}
        s_{n_0+k}                &< R^ks_{n_0}.
\end{align*}\hfill\halmos{}(Claim 1)

\underbar{\bf{}Claim 2:} $\limit{n}{\infty}{s_n}=0.$\\
\underbar{\bf{}Proof of Claim 2:} \\
Let $\eps>0$ be given. Since $R<1$ we know from
problem~\ref{prob:sequences3} that $R^k\rightarrow 0.$

Take $K$ such that $k>K\imp R^k<\frac{\eps}{s_{n_0}},$ and
take $N=n_0+k.$ Then for every $n>N$
\begin{align*}
  \abs{s_n} &<R^ks_{n_0}\\
  &<\frac{\eps}{s_{n_0}}s_{n_0}\\
  &<\eps.
\end{align*}

Therefore $\limit{n}{\infty}{s_n}=0.$
\end{solution}
  \item[(b)] Let $c$ be a positive real number.  Prove  
$\displaystyle\lim_{n\rightarrow\infty}\left(\frac{c^n}{n!}\right)=0.$\xqedhere{1.2in}{\lozenge}{}
\begin{solution}{}
  Take $s_n=\frac{c^n}{n!}$ and observe that
\[
    \frac{s_{n+1}}{s_n} =
    \frac{\frac{c^{n+1}}{(n+1)!}}{\frac{c^n}{n!}} =
    \frac{c}{n+1}\rightarrow0.
\]
Therefore by part (a) $s_n=\frac{c^n}{n!} \rightarrow0.$
\end{solution}
\end{description}

\newpage{}
\end{problem}

\chapter{Convergence of the Taylor Series: A ``Tayl'' of Three Remainders}
\markboth{{\sc Convergence of Taylor Series}}{{\sc A ``Tayl'' of Three Remainders}}
\label{chapt:taylor-series}

\begin{lemma}
\label{lemma:TriangleForIntegral}
\IndexLemma{lemma:TriangleForIntegral}
%\index{Lemma by description!Triangle Inequality!for integrals}
   {\bf{}\lbrack Triangle Inequality for Integrals\rbrack} If $f$ and
   $\abs{f}$ are integrable functions and $a\leq b$, then
$$
\left|\int_{t=a}^bf(t)\d t\right|\leq\int_{t=a}^b|f(t)|\d t.
\xqedhere{1.5in}{\blacktriangle}{}$$
\end{lemma}

\begin{problem}
\LabelProblem{prob:Triangle Inequality for Integrals}{Triangle Inequality for Integrals}
  Prove Lemma~\ref{lemma:TriangleForIntegral}{}.$\,\,$\lbrack Hint:  $-|f(t)|\leq
  f(t)\leq|f(t)|$.\rbrack\xqed{\lozenge}{}
  \begin{solution}{}
    Since $f(t)\in\RR,$ we see that
    \begin{alignat*}{3}
      -\abs{f(t)} &< f(t) &&<\abs{f(t)}.\\
\intertext{Therefore}
      -\int_{t=a}^x\abs{f(t)}\d t &< \int_{t=a}^xf(t)\d t
      &&<\int_{t=a}^x\abs{f(t)}\d t\\
    \end{alignat*}
which is equivalent to
\[
       \abs{\int_{t=a}^xf(t)\d t}<\int_{t=a}^x\abs{f(t)}\d t.
\]
  \end{solution}
\newpage{}
\end{problem}

\begin{theorem}
\label{thm:TaylorSeries}
\IndexTheorem{thm:TaylorSeries}{}
  If there exists a real number $B$ such that
  $|f^{(n+1)}(t)|\leq B$  for all nonnegative integers $n$ and for
  all $t$ on an interval containing $a$ and $x$, then
  $$\lim_{n\rightarrow\infty}\left(\frac{1}{n!}\int_{t=a}^xf^{(n+1)}(t)(x-t)^n\d
    t\right)=0$$
  and
  so $$f(x)=\sum_{n=0}^\infty\frac{f^{(n)}(a)}{n!}(x-a)^n.\xqedhere{1.5in}{\blacktriangle}{}$$
\end{theorem}

\begin{problem}
\LabelProblem{prob:Taylor Series-prove}{$f^{(n)}<B,\forall
  n\in\NN\imp$ Taylor series converges}
Prove Theorem~\ref{thm:TaylorSeries}.  \lbrack Hint: You might want to
use Problem~\ref{prob:RatioTest} of
Chapter~\ref{chpt:Convergence}. Also there are two cases to consider:
$a<x$ and $x<a$ (the case $x=a$ is trivial).  You will find that this
is true in general. This is why we will often indicate that $t$ is between
$a$ and $x$ as in the theorem.  In the case $x<a$,
notice that
\begin{align*}
  \left|\int_{t=a}^xf^{(n+1)}(t)(x-t)^n\d t\right|&=\left|(-1)^{n+1}\int_{t=x}^af^{(n+1)}(t)(t-x)^n\d t\right|\\
&=\left|\int_{t=x}^af^{(n+1)}(t)(t-x)^n\d t\right|.]\xqedhere{.95in}{\lozenge}{}
\end{align*}
\begin{solution}{}
  \begin{description}
  \item[\underline{Case 1: $x>a$}]\ \\
Since $x-t\ge0$ we see that:
    \begin{align*}
      \abs{\frac{1}{n!}\int_a^xf^{(n+1)}(t)(x-t)^n\d t} &\leq \frac{1}{n!}\int_a^x\abs{f^{(n+1)}(t)}\d t \\
      &\leq \frac{B}{n!}\int_a^x(x-t)^n\d t\\
      &= \left.\frac{-B(x-t)^{n+1}}{(n+1)!}\right|_a^x\\
      &= \frac{B(x-a)^{n+1}}{(n+1)!}
    \end{align*}
By part b) of Problem~\ref{prob:RatioTest} $\limit{n}{\infty}{\frac{B(x-a)^{n+1}}{(n+1)!}}\rightarrow0.$
\item[\underline{Case 2: $x<a$}]\ \\
This time  $x-t\le0$ so:
    \begin{align*}
      \abs{\frac{1}{n!}\int_a^xf^{(n+1)}(t)(x-t)^n\d t} &\leq \frac{1}{n!}\abs{-\int_x^af^{(n+1)}(t)(x-t)^n\d t} \\
      &=\frac{1}{n!}\abs{\int_x^af^{(n+1)}(t)(x-t)^n\d t} \\
      &\leq \frac{1}{n!}\int_x^a\abs{f^{(n+1)}(t)}\abs{(t-x)^n}\d t \\
      &\leq  \frac{B}{n!}\int_x^a(t-x)^n\d t \\
      &= \left.\frac{B(t-x)^{n+1}}{(n+1)!}\right|_x^a\\
      &= \frac{B(a-x)^{n+1}}{(n+1)!}
    \end{align*}
and again, by part b) of Problem~\ref{prob:RatioTest} $\limit{n}{\infty}{\frac{B(a-x)^{n+1}}{(n+1)!}}\rightarrow0.$

  \end{description}
\end{solution}
\newpage{}
\end{problem}. 

\begin{problem}
\LabelProblem{prob:Taylor Series-using}{Taylor expansion of $\sin,$
  $\cos$ and $e^x$}
  Use Theorem~\ref{thm:TaylorSeries} to prove that for any real number $x$
  \begin{description}
  \item[a)] $ \displaystyle\sin x=\sum_{n=0}^\infty\frac{(-1)^nx^{2n+1}}{(2n+1)!}$
  \begin{solution}{}
    Since all of the derivatives of $\sin(x)$ are bounded above by $1$
    the result follows. The series converges for all $x\in\RR.$
  \end{solution}
  \item[b)] $\displaystyle\cos x=
    \sum_{n=0}^\infty\frac{(-1)^nx^{2n}}{(2n)!}$
  \begin{solution}{}
    Same as part a).
  \end{solution}
  \item[c)] $\displaystyle
    e^x=\sum_{n=0}^\infty\frac{x^n}{n!}$
  \begin{solution}{}
    On any interval $[a,b]$ the derivative of $e^x$ is bounded  above
    by $e^b$ the result follows on $[a,b].$ Since $a$ and $b$ are
    arbitrary the result follows on $\RR.$
  \end{solution}
  \end{description}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:ExponentAddition}{}
Recall that if $f(x)=e^x$ then $f^\prime(x) = e^x.$ Use this along
with the Taylor series expansion of $e^x$ about $a$ to show that 
$$
e^{a+b}=e^ae^b.\xqedhere{2in}{\lozenge}{}
$$
\begin{solution}{}
  Let $x=a+b.$ Then the Taylor Series of $e^x$ expanded about $a$ is:
  \begin{align*}
    e^x &= \sum_{n=0}^\infty\frac{f^{(n)}(a)}{n!}(x-a)^n\\
        &= \sum_{n=0}^\infty\frac{e^a}{n!}(x-a)^n\\
        &= e^a\sum_{n=0}^\infty\frac{1}{n!}(x-a)^n\\
        &= e^a\sum_{n=0}^\infty\frac{b^n}{n!}\\
\intertext{and since $x=a+b$ we see that}
    e^{a+b} &= e^ae^b.
  \end{align*}
\end{solution}
\newpage{}
\end{problem}

\begin{theorem}
\label{thm:LagrangeRemainder}
\IndexTheorem{thm:LagrangeRemainder}{}
  {\bf{}(Lagrange's Form of the Remainder)}  Suppose $f$ is
  a function such that $f^{(n+1)}(t)$  is continuous on an interval
  containing $a$ and $x$.  Then
$$
f(x)-\left(\sum_{j=0}^n\frac{f^{(j)}(a)}{j!}(x-a)^j\right)=\frac{f^{\,%
      (n+1)}(c)}{(n+1)!}(x-a)^{n+1}
$$
where $c$ is some number between $a$ and $x$.\xqed{\blacktriangle}{}
\end{theorem}

\begin{problem}
\LabelProblem{prob:Lagrange Remainder-for x<a}{Lagrange Remainder!for $x<a$}
Prove Theorem~\ref{thm:LagrangeRemainder} for the case where $x<a$.  [Hint: Note that 
$$
\int_{t=a}^xf^{(n+1)}(t)(x-t)^n\d
t=(-1)^{n+1}\int_{t=x}^af^{(n+1)}(t)(t-x)^n\d t.$$  
Use the same argument on this integral. It will work out in the
end. Really! You just need to keep track of \emph{all } of the
negatives.]
 \xqed{\lozenge}{}
 \begin{solution}{}
   There are two cases:
   \begin{description}
   \item[Case 1 $x\ge a:$] Let
     $m=\min_{t\in[a,x]}\left(f^{(n+1)}(t)\right)$ and
     $M=\max_{t\in[a,x]}\left(f^{(n+1)}(t)\right).$ (Comment: We are
     assuming that $f^{(n+1)}(t)$ is continuous on the interval
     $[a,x].$) Then $\forall t\in[a,x]$
     \begin{alignat*}{3}
       m&\le& f^{(n+1)}(t) &\le& M \\[2mm]
       m(x-t)^n&\le& f^{(n+1)}(t)(x-t)^n &\le& M(x-t)^n \\[2mm]
       \int_{t=a}^xm(x-t)^n\d t&\le&\int_{t=a}^x f^{(n+1)}(t)(x-t)^n\d t &\le&\int_{t=a}^x M(x-t)^n\d t \\[2mm]
       m\left[\frac{-(x-t)^{n+1}}{n+1}\right]_{t=a}^x&\le& \int_{t=a}^xf^{(n+1)}(t)(x-t)^n\d t &\le&\  M\left[\frac{-(x-t)^{n+1}}{n+1}\right]_{t=a}^x\\[2mm]
       m\frac{(x-a)^{n+1}}{n+1}&\le& \int_{t=a}^xf^{(n+1)}(t)(x-t)^n\d t &\le& M\frac{(x-a)^{n+1}}{n+1}\\[2mm]
       m&\le& \frac{\int_{t=a}^xf^{(n+1)}(t)(x-t)^n\d t}{\frac{(x-a)^{n+1}}{n+1}} &\le& M.\\[2mm]
     \end{alignat*}
     Thus, by the Intermediate Value Theorem, there is a number
     $c\in[a,x]$  such that 
   \begin{align*}
     f^{(n+1)}(c) &=  \frac{\int_{t=a}^xf^{(n+1)}(t)(x-t)^n\d t}{\frac{(x-a)^{n+1}}{n+1}}\\
\intertext{or}
     \frac{1}{(n+1)!}\int_{t=a}^xf^{(n+1)}(t)(x-t)^n\d t &= \frac{f^{(n+1)}(c)(x-a)^{n+1}}{(n+1}
   \end{align*}
   \item[Case 2 $a\ge x:$] Let
     $m=\min_{t\in[x,a]}\left(f^{(n+1)}(t)\right)$ and
     $M=\max_{t\in[x,a]}\left(f^{(n+1)}(t)\right).$ As before,
     \begin{alignat*}{3}
       m&\le& f^{(n+1)}(t) &\le& M \\[2mm]
       m(t-x)^n &\le& f^{(n+1)}(t)(t-x)^n &\le& M(t-x)^n \\[2mm]
       \int_{t=x}^am(t-x)^n\d t  &\le&\int_{t=x}^a f^{(n+1)}(t)(t-x)^n\d t &\le&\int_{t=x}^a M(t-x)^n\d t \\[2mm]
       \left.m\frac{(t-x)^{n+1}}{n+1}\right|_{t=a}^x &\le& \int_{t=x}^af^{(n+1)}(t)(t-x)^n\d t &\le& \left.M\frac{(t-x)^{n+1}}{n+1}\right|_{t=a}^x\\[2mm]
       m\frac{(a-x)^{n+1}}{n+1}  &\le& \int_{t=x}^af^{(n+1)}(t)(t-x)^n\d t &\le& M\frac{(a-x)^{n+1}}{n+1}\\[2mm]
       m  &\le& \frac{\int_{t=x}^af^{(n+1)}(t)(t-x)^n\d t}{\frac{(a-x)^{n+1}}{n+1}} &\le& M.\\[2mm]
       m  &\le& \frac{\left[(-1)^{n+1}\right]\int_{t=a}^xf^{(n+1)}(t)(x-t)^n\d t}{\left[(-1)^{n+1}\right]\frac{(x-a)^{n+1}}{n+1}} &\le& M.\\[2mm]
       m  &\le& \frac{\int_{t=a}^xf^{(n+1)}(t)(x-t)^n\d t}{\frac{(x-a)^{n+1}}{n+1}} &\le& M.\\[2mm]
    \end{alignat*}
     Thus in either case we have, by the Intermediate Value Theorem, a number
     $c\in[a,x]$  such that 
   \begin{align*}
     f^{(n+1)}(c) &=  \frac{\int_{t=a}^xf^{(n+1)}(t)(x-t)^n\d t}{\frac{(x-a)^{n+1}}{n+1}}\\
\intertext{or}
     \frac{1}{(n+1)!}\int_{t=a}^xf^{(n+1)}(t)(x-t)^n\d t &= \frac{f^{(n+1)}(c)(x-a)^{n+1}}{(n+1)!}
   \end{align*}
   \end{description}
 \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:Taylor Series-geometric series and}{Geometric
  series!is a Taylor series}
  This problem investigates the Taylor series
  representation $$\frac{1}{1+x}=1-x+x^2-x^3+\cdots.$$
  \begin{description}
  \item[(a)]  Use the fact that
  $\frac{1-(-x)^{n+1}}{1+x}=1-x+x^2-x^3+\cdots+(-x)^n$  to compute
  the remainder

  $\frac{1}{1+x}-\left(1-x+x^2-x^3+\cdots+(-x)^n\right)$.


  Specifically, compute this remainder when $x=1$ and conclude that
  the Taylor Series does not converge to $\frac{1}{1+x}$ when $x=1$.
  \begin{solution}{}
    Let $R(n)$ be the $n$th order remainder. Then 
\[
R(n) =
\begin{cases}
  -1/2 & \text{ when $n$ is even}\\
  1/2  & \text{ when $n$ is odd.}
\end{cases}
\]
  \end{solution}
\item[(b)]  Compare the remainder in part a with the Lagrange form of the
  remainder to determine what $c$ is when $x=1$.
  \begin{solution}{}
    When $x=1$ the Lagrange form of the remainder is $R(n) =\frac{(-1)^{n+1}}{(1+c)^{n+2}}.$ When $n$ is even we have 
\[
      \frac{(-1)^{n+1}}{(1+c)^{n+2}} = -1/2
\]
so that
\[
      c=2^{\frac{1}{n+2}}-1.
\]
When $n$ is odd we get the same.
  \end{solution}
\item[(c)]  Consider the following argument:
If $f(x)=\frac{1}{1+x}$, then 
$$
f^{(n+1)}(c)=\frac{(-1)^{n+1}(n+1)!}{(1+c)^{n+2}}
$$
so the Lagrange form of the remainder when $x=1$ is given by
$$
\frac{(-1)^{n+1}(n+1)!}{(n+1)!(1+c)^{n+2}}=\frac{(-1)^{n+1}}{(1+c)^{n+2}}
$$
where $c\in[\,0,1]$.  It can be seen in part b that $c\neq 0$.  Thus
$1+c>1$ and so by Problem~\ref{prob:sequences3} of
Chapter~\ref{chpt:Convergence}, the Lagrange remainder converges to
$0$ as $n\rightarrow\infty$.


This argument would suggest that the Taylor series converges to
$\frac{1}{1+x}$ for $x=1$.  However, we know from part (a) that this is
incorrect.  What is wrong with the argument?\xqed{\lozenge}{}
\begin{solution}{}
Problem \#59 of Chapter 4 reuires that $\abs{b}<0$ \underline{and}
that $b$ is fixed. For this problem we have
$$
b=\frac{(-1)^{n+1}}{(1+c)^{n+2}}
$$
but since $c$ is not fixed, neither is $b.$

Therefore problem \#59 does not apply.
\end{solution}
\end{description}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:Taylor Series-Binomial Series and}{binomial series
  is a Taylor series}
  Show that if $-\frac{1}{2}\leq x\leq c\leq 0$, then
  $|\frac{x}{1+c}|\leq 1$ and modify the above proof to show that the
  binomial series converges to $\sqrt{1+x}$ for
  $x\in\left[-\frac{1}{2},0\right]$.\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}\ \\
\LabelProblem{prob:Lagrange Remainder-for ln(2)}{Lagrange Remainder!for $\ln 2$}
  \begin{description}
  \item[(a)]  Compute the Lagrange form of the remainder for the
  Maclaurin series for $\ln\left(1+x\right)$.
  \begin{solution}{}
    $$    
    f^{(n+1)}(x)  = \frac{(-1)^nn!}{(1+x)^{n+1}}
      $$
so the Lagrange form of the remainder is:
\begin{align*}
  {\cal L}(f(x)) &= \frac{f^{(n+1)}(c)}{(n+1)!}x^{n+1}\\
                 &= \frac{(-1)^nn!}{(n+1)!}\frac{x^{n+1}}{(1+c)^{n+1}}\\
                 &= \frac{(-1)^n}{(n+1)}\frac{x^{n+1}}{(1+c)^{n+1}}\\
\end{align*}


  \end{solution}
\item[(b)] Show that when $x=1$, the Lagrange form of the remainder
  converges to $0$ and so the equation 
  $\ln 2=1-\frac{1}{2}+\frac{1}{3}-\frac{1}{4}+\cdots$  is actually
  correct.\xqed{\lozenge}{}
\begin{solution}{}
  When $x=1$ the Lagrange form of the remainder of $f(x)=\ln(1+x)$ is
   $ {\cal L}(f(x)) = \frac{f^{(n+1)}(c)}{(n+1)!}x^{n+1}$ so 
   \begin{align*}
     \abs{{\cal L}(f(1))} &= \abs{\frac{f^{(n+1)}(c)}{(n+1)!}}\\
                          &= \abs{\frac{(-1)^{n}n!}{(n+1)!(1+c)^{n+1}}}\\
                          &\leq \frac{1}{n+1}.
   \end{align*}
Therefore ${\cal L}(f(1)) \rightarrow 0$ as $n\rightarrow \infty.$

Therefore $\ln 2=1-\frac{1}{2}+\frac{1}{3}-\frac{1}{4}+\cdots.$
\end{solution}
\end{description}
\newpage{}
\end{problem}

\begin{theorem}{\bf{}(Cauchy's Form of the Remainer in Taylor Series)}
\label{thm:CauchyRemainder}
\IndexTheorem{thm:CauchyRemainder}{}
    Suppose $f$ is a function such that $f^{(n+1)}(t)$  is continuous
  on an interval containing $a$ and $x$.  Then
$$
f(x)-\left(\sum_{j=0}^n\frac{f^{(j)}(a)}{j!}(x-a)^j\right)=\frac{f^{\,%
      (n+1)}(c)}{n!}(x-c)^n(x-a)
$$
  where $c$ is some number between $a$ and $x$.\xqed{\blacktriangle}{}
\end{theorem}

\begin{problem}
\LabelProblem{prob:Cauchy Remainder}{Cauchy Remainder}
Prove Theorem~\ref{thm:CauchyRemainder} using an argument similar to
the one used in the proof of Theorem~\ref{thm:LagrangeRemainder}.
Don't forget there are two cases to consider.\xqed{\lozenge}{}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:Binomial Series of g(c)=frac{c-x}{1+c} is increasing}{Binomial Series!$g(c)=\frac{c-x}{1+c}$ is increasing}
  Suppose $-1<x\leq c\leq 0$ and consider the function
  $g(c)=\frac{c-x}{1+c}.$  Show that on $[x,0],$ $g$ is increasing
  and use this to conclude that for $-1<x\leq c\leq 0,$
$$
\frac{c-x}{1+c}\leq|x|.
$$

Use this fact to finish the proof that the binomial series converges
to $\sqrt{1+x}$ for $-1<x<0$.\xqed{\lozenge}{}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:Integral, Lagrange, Cauchy forms of
  remainder}{Integral, Lagrange, Cauchy forms of remainder for various
functions}
  Find the Integral form, Lagrange form, and Cauchy form of the
  remainder for Taylor series for the following functions expanded
  about the given values of $\,a$.
  \begin{description}
  \item[(a)] $f(x)=e^x$, \ $a=0$
  \begin{solution}{}
    
  \end{solution}
  \item[(b)] $f(x)=\sqrt{x}$, $a=1$
  \begin{solution}{}
    
  \end{solution}
  \item[(c)] $f(x)=(1+x)^\alpha$, \ $a=0$
  \begin{solution}{}
    
  \end{solution}
  \item[(d)] $f(x)=\frac{1}{x}$, $a=3$
  \begin{solution}{}
    
  \end{solution}
  \item[(e)] $f(x)=\ln x,\ a=2$
  \begin{solution}{}
    
  \end{solution}
  \item[(f)] $f(x)=\cos x, a=\frac{\pi}{2}$
  \begin{solution}{}
    
  \end{solution}
  \end{description}\xqed{\lozenge}{}
\newpage{}
\end{problem}

\chapter{Continuity: What It Isn't and What It Is}
\label{chpt:Continuity}
\markboth{{\sc Continuity: What It Isn't and What It Is}}{{\sc Continuity: What It Isn't and What It Is}}

\begin{problem}\ 
\LabelProblem{prob:continuity!Weierstrass's function}{}
  \begin{description}
  \item[(a)]  Given
  $f(x)=\sum_{n=0}^\infty\left(\frac{1}{2}\right)^n\cos\left(a^n\pi
    x\right)$, what is the smallest value of $a$ for which $f$
  satisfies Weierstrass' criterion to be continuous and nowhere
  differentiable.
\item[(b)] Let
  $f(x,N)=\sum_{n=0}^N\left(\frac{1}{2}\right)^n\cos\left(13^n\pi
    x\right)$ and use a computer algebra system to plot $f(x,N)$ for
  $N=0,1,2,3,4,10$ and $x\in[0,1]$.
\item[(c)]  Plot $f(x,10)$  for $x\in[\,0,c]$, where
  $c=0.1,0.01,0.001,0.0001,0.00001$.  Based upon what you see in
  parts b and c, why would we describe the function to be somewhat
  ``fractal'' in nature?\xqed{\lozenge}{}
\end{description}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:continuity!lines}{}
  Use the definition of continuity to show that if $m$ and $b$ are
  fixed (but unspecified) real numbers then the function
$$
f(x) = mx+b
$$
is continuous at every real number $a.$\xqed{\lozenge}{}
\begin{solution}{}
  Let $\eps>0$ and $a\in\RR$ be given. There are two cases:
  \begin{description}
  \item[Case 1 $m=0:$] Take $\delta=\eps.$ Then $\forall x \text{ such that } \abs{x-a} < \delta$ we see that $\abs{f(x) - f(a)} =
    b-b = 0 <\eps.$
  \item[Case 2 $m\neq 0:$] Take $\delta<\frac{\eps}{\abs{m}}.$ Then
    $\forall x \text{ such that } \abs{x-a} < \delta$ we see that
    $\abs{f(x) - f(a)} =   \abs{(mx-b) - (ma-b)} = \abs{m(x-a)}
    <\abs{m}\delta = \abs{m}\frac{\eps}{\abs{m}} = \eps.$
  \end{description}
\end{solution}
\newpage{}
\end{problem}

\begin{problem}\ 
\LabelProblem{prob:continuity!smaller delta, bigger eps}{continuity!smaller $\delta$, bigger $\eps$}
  \begin{description}
  \item[(a)] Given a particular $\eps>0$ in the definition
  of continuity, show that if a particular $\delta_0>0$ satisfies the
  definition, then any  $\delta$  with  $0<\delta<\delta_0$  will
  also work for this $\eps$.
\begin{solution}{}
Suppose that $\abs{x-a} < \delta_0 \imp \abs{f(x)-f(a)}  < \eps.$ Then
 $\abs{x-a} < \delta<\delta_0 \imp \abs{f(x)-f(a)}  < \eps$ also.
\end{solution}
\item[(b)] Show that if a $\delta$ can be found to satisfy the conditions
  of the definition of continuity for a particular $\eps_0>0$,
  then this  $\delta\,$ will also work for any $\,\eps\,$ with \
  $0<\eps_0<\eps$.\xqed{\lozenge}{}
\begin{solution}{}
  Suppose that $\abs{x-a} < \delta \imp \abs{f(x)-f(a)}  < \eps_0.$
  Then $\abs{x-a} < \delta \imp \abs{f(x)-f(a)} <\eps < \eps_0$ also.
\end{solution}
\end{description}

\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:extended sqrt is continuous at zero}{}
  Use the definition of continuity to show that
$$
f(x)=
  \begin{cases}
    \sqrt{x} & \text{ if } x\ge0\\
    -\sqrt{-x} & \text{ if } x<0
  \end{cases}
$$
 is continuous at $a=0$.\xqed{\lozenge}{}
 \begin{solution}{}
   Le $\eps>0$ be given. The for every $x\in\RR$ such that
   $\abs{x}<\delta$
   \begin{align*}
     \abs{f(x)-f(0)}&=\abs{\pm\sqrt{x}}\\
                    &= \sqrt{x}\\
                    &<\sqrt{\delta}\\
                    &=\sqrt{\eps^2}\\
                    &=\eps.
   \end{align*}
 \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:sqrt{x} is continuous  at zero}{}
  Use the definition of continuity to show that
$
f(x)= \sqrt{x}
$
 is continuous at $a=0$. How is this problem different from
 problem~\ref{prob:extended sqrt is continuous at zero}? How is it similar?\xqed{\lozenge}{}
 \begin{solution}{}
   
 \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:continuity!at any positive real number}{}
  Use the definition of continuity to show that $f(x)=\sqrt{x}$ is
  continuous at any positive real number $a$.\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}\ 
\LabelProblem{prob:continuity!sin( x)}{}
  \begin{description}
  \item[(a)] Use a unit circle to show that for
  $0\leq\theta<\frac{\pi}{2}$,  sin $\theta\leq\theta$  and 
  $1-\cos \theta\leq\theta$  and conclude $\abs{\sin
  \theta}\leq\abs{\theta}$  and   $\abs{1-\cos \theta}\leq\abs{\theta}$
   for $-\frac{\pi}{2}<\theta$ $<\frac{\pi}{2}$.
\begin{solution}{}
  From the diagram\\
\centerline{\includegraphics*[height=2in,width=2in]{Prob105}}
we see that when $0<\theta<\frac{\pi}{2},$
$1-\cos(\theta) \le
\overline{AB} \le \theta.$ 

Moreover since $\cos(x)$ is an even function  $1-\cos(\theta)>0$ we see that 
$$
\abs{1-\cos{\theta}}<\theta
$$
for $\frac{-\pi}{2}<\theta<\frac{\pi}{2}.$ 

Also on $0<\theta<\frac{\pi}{2}$ $\sin(\theta)$ is positive so we have
$$-\theta<\sin(\theta)\le\overline{AB}\le\theta$$
 and since $\sin(\theta) $ is
an odd function we see that 
\begin{align*}
-\theta&<\sin(\theta)\le\theta\\
\theta&>-\sin(\theta)\ge\theta\\
\theta&>\sin(-\theta)\ge\theta\\
\end{align*}
Therefore on the interval $\left(\frac{-\pi}{2},\frac{\pi}{2}\right)$
$$
-\theta<\sin(\theta)<\theta
$$
or 
$$
\abs{\sin(\theta)}<\theta.
$$


\end{solution}
\item[(b)] Use the definition of continuity to prove that $f(x)=\sin x$ 
  is continuous at any point $a$.  \lbrack Hint: $\sin
  x=\sin\left(x-a+a\right)$.\rbrack
\begin{solution}{}
Let $\eps>0$ be given. Take $\delta<\min\left(\frac{\eps}{\abs{\cos(a)} +
  \abs{\sin(a)}}, \frac{\pi}{2}\right).$ Then $\forall\ x$ such that 
$\abs{x-a}<\delta$ we have
  \begin{align*}
    \abs{f(x)-f(a)} &=   \abs{\sin(x)-\sin(a)}\\
                    &=   \abs{\sin(x-a+a)-\sin(a)}\\
                    &=   \abs{\sin(x-a)\cos(a) + \cos(x-a)\sin(a)-\sin(a)}\\
                    &=   \abs{\sin(x-a)\cos(a) + \sin(a)\left(\cos(x-a)-1\right)}\\
                    &\le \abs{\sin(x-a)\cos(a)} + \abs{\sin(a)\left(\cos(x-a)-1\right)}\\
                    &=   \abs{\cos(a)}\abs{\sin(x-a)} + \abs{\sin(a)}\abs{\left(\cos(x-a)-1\right)}\\
                    &\le \abs{\cos(a)}\abs{x-a} + \abs{\sin(a)}\abs{x-a}\\
                    &=   \abs{x-a}\left(\abs{\cos(a)} + \abs{\sin(a)}\right)\\
                    &=   \eps.
  \end{align*}
\end{solution}
\end{description}\xqed{\lozenge}{}
\newpage{}
\end{problem}

\begin{problem}\ 
\LabelProblem{prob:continuity!e^x}{}
  \begin{description}
  \item[(a)] Use the definition of continuity to show that
  $f(x)=e^x$ is continuous at $a=0$.
  \begin{solution}{}
% \noindent{\bf First Solution:}\\
% Let $\eps>0$ be given. Take $\delta<\log(\eps+1).$ Then if $\abs{x}<\delta$ we have 
% \begin{align*}
%   \abs{f(x)-f(0)} &= \abs{e^x-1}\\
%                   &< \abs{e^\delta-1}\\
%                   &= \abs{e^{\log(\eps+1)}-1}\\
%                   &= \eps.
% \end{align*}
% \noindent{\bf Second Solution:}
    Let $\eps>0$ be given. There are two cases:
    \begin{description}
    \item[\underline{Case 1: $\eps\ge1$}]\ \\
      Take $\delta<\log2.$ Then $\forall$ $x$ such that $\abs{x} <\delta$ we have
      \begin{alignat*}{6}
        -&\log(2)& &<& &x& &<& \log&(2)&\\
        &1/2&      &<& &e^x& &<& &2&\\
-\eps < -&1/2& &<&\  e^x&-&1\  &<& &1& < \eps.
      \end{alignat*}
Therefore $\abs{e^x-1}<\eps$ when $\eps\ge1.$
    \item[\underline{Case 2: $\eps<1$}]\ \\
      Take $\delta=\min\left(\log(1+\eps), -\log(1-\eps)\right).$ Then $\forall$ $x$ such that $\abs{x}<\delta$ we see that: 
      \begin{alignat*}{6}
        \log&(1-\eps)& &<&\  &x& \ &<&\  \log&(1+\eps)&\\
        &1-\eps&       &<&\  &e^x& \ &<&      &1+\eps& \\ 
        &-\eps&       &<&\  e^x&-&1 \ &<&      &\eps& \\ 
      \end{alignat*}
Therefore $\abs{e^x-1}<\eps$  when $\eps<1.$
    \end{description}
Therefore $f(x) = e^x$ is continuous at $x=0$
  \end{solution}
  \item[(b)] Show that $f(x)=e^x$ is continuous at any point $a$.  \lbrack
    Hint:  Rewrite $e^x-e^a$ as $e^{a+(x-a)}-e^a$ and use what you
    proved in part a.\rbrack\xqed{\lozenge}{}
    \begin{solution}{}
      Let $\eps>0$ be given. Take $y=x-a.$ Since $f(y)=e^y$ is continuous at $y=0$ by part a) there is a $\delta_1>0$ such that if $\abs{y}<\delta_1$ then:
      \begin{align*}
        \abs{e^y-1} &< \frac{\eps}{e^a}.\\
        \intertext{Take $\delta=\delta_1.$ Then $\forall$ $y=x-a$ such
          that $\abs{y}= \abs{x-a} <\delta$ we have: }
        \abs{e^a(e^y-1)} &< \abs{e^a\frac{\eps}{e^a}}\\
        \abs{e^x-e^a)} &< \eps\\
      \end{align*}
Therefore $f(x) = e^x$ is continuous at every real number.
    \end{solution}
\end{description}

\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:continuity!topologist's sine function at zero}{}
 Use the definition of continuity to show that 
$$
f(x)=
  \begin{cases}
    x\,\sin\left(\frac{1}{x}\right),&\text{if }x\neq 0\\
    0\text{,}&\text{if }x=0
  \end{cases}
$$
is continuous at $0$.\xqed{\lozenge}{}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}\ 
\LabelProblem{prob:continuity!Dirichelet's function at zero}{}
  \begin{description}
  \item[(a)] Use the definition of continuity to show that the
  function 
$$
D(x)=
  \begin{cases}
    x&\text{if }x\text{ is rational}\\
    0&\text{if }x\text{ is irrational}
  \end{cases}
$$
is continuous at $0$.
\begin{solution}{}
Let $\eps > 0 $ be given. Take $\delta=\eps.$ There are two cases:
\begin{description}
\item[Case 1, $x$ is rational:]
In this case
  $\abs{x}<\delta\imp\abs{D{x}-D(0) } = \abs{x} < \delta=\eps.$
\item[Case 2, $x$ is irrational] 
In this case
  $\abs{x}<\delta\imp\abs{D{x}-D(0) } = 0 <\eps.$
 \end{description}

\end{solution}
\item[(b)] Let $a\neq 0$.  Use the definition of continuity to show
  that $D$ is not continuous at $a$.  \lbrack Hint: You might want to
  break this up into two cases where $a$ is rational or irrational.
  Show that no choice of $\delta>0$ will work for $\eps=|\,a|$. Note
  that Theorem~\ref{thm:IrrationalBetweenIrrationals} of
  Chapter~\ref{cha:numb-real-rati} will probably help here.\rbrack
\begin{solution}{}
  Again there are two cases:
  \begin{description}
  \item[Case 1, $a\in\QQ:$] Let $\eps=\frac{\abs{a}}{2}.$ Then $\forall\
       \delta>0 \exists\bar{x}\in(a-\delta, a+\delta)$ such that
       $\bar{x}\in\RR-\QQ,$ and
       \begin{align*}
         \abs{D(x)-D(a)} &= \abs{D(a)} \\
         &= \abs{a} \\
         &> \frac{\abs{a}}{2} \\
         &= \eps.
       \end{align*}
     \item[Case 2, $a\in\RR-\QQ:$]In this case $\forall \delta>0,
       \exists \bar{x}\in
       \left(a-\frac{\abs{a}}{2},a+\frac{\abs{a}}{2}\right)$ such that
       $\bar{x}\in\QQ.$ Therefore
       \begin{align*}
         \abs{D(\bar{x})-D(a)}&=\abs{D(\bar{x})} \\
         &=\abs{\bar{x}} \\
         &\ge \abs{a-\frac{\abs{a}}{2}} \\
         &=          \frac{\abs{a}}{2}.
       \end{align*}

  \end{description}

\end{solution}
\end{description}\xqed{\lozenge}{}
\newpage{}
\end{problem}

\begin{theorem}
\label{thm:LimDefOfContinuity}
\IndexTheorem{thm:LimDefOfContinuity}{}
  The function $f\,$is continuous at $a$ if and only if
  $f$ satisfies the following property: $$\forall\text{
      sequences }\left(x_n\right)\text{, if
    }\,\,\lim_{n\rightarrow\infty}x_n=a\text{  then  
    }\lim_{n\rightarrow\infty}f(x_n)=f(a).\xqedhere{.5in}{\blacktriangle}{}$$
\end{theorem}

\begin{problem}
\LabelProblem{prob:continuity!Heaviside's function}{}
  Use Theorem~\ref{thm:LimDefOfContinuity} to show that 
$$
f(x)=
  \begin{cases}
    \frac{\abs{x}}{x},&\text{if }x\neq 0\\
    a,                   &\text{if }x=0
  \end{cases}
$$ 
is not continuous at $0$, no matter what value $a$ is.\xqed{\lozenge}{}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:continuity!Dirichelet's function not at zero}{}
 Use Theorem~\ref{thm:LimDefOfContinuity} to show that 
$$
D(x)=
  \begin{cases}
    x\text{,}&\text{if }x\text{ is rational}\\
    0\text{,}&\text{if }x\text{ is irrational}
  \end{cases}
$$ 
is not continuous at $a\neq 0$.\xqed{\lozenge}{}
\begin{solution}{}
There are two cases:
\begin{description}
\item[Case 1:]  $a$ is rational.\\
In this case choose $x_n\in\RR-\QQ$ such that $x_n\in(a,a+1/n).$ Then
$x_n\rightarrow a\neq 0.$ But $D(x_n)=0,$ $\forall\ n\in\NN$ so that
$D(x_n)\rightarrow 0 \neq a.$ Therefore $D(x)$ is not continuous at
$a$ when $a$ is rational.
\item[Case 2:] $a$ is irrational.
In this case choose $x_n\in\QQ$ such that $x_n\in(a,a+1/n).$ Then
$x_n\rightarrow a,$ but $\limit{n}{\infty}{D(x_n)} =
\limit{n}{\infty}{x_n} = a \neq 0 = D(a).$ Therefore $D(x)$ is not continuous at
$a$ when $a$ is irrational.
\end{description}
Therefore $D(x)$ is not continuous at
$a\neq0.$
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
  The function $T(x)=\sin\left(\frac{1}{x}\right)$ is
  often called the topologist's sine curve.  Whereas $\sin x$ has
  roots at $n\pi,$ $n\in\ZZ$ and oscillates infinitely often as
  $x\rightarrow\pm\infty$, $T$ has roots at
  $\frac{1}{n\pi},\,n\in\ZZ,\,n\neq 0$, and oscillates
  infinitely often as $x$ approaches zero.  A rendition of the graph
  follows.\\
\centerline{\includegraphics*[height=2in,width=4in]{TextGraphics/Ch5fig7}}

  Notice that $T$ is not even defined at $x=0$.  We can extend
  $T$ to be defined at 0 by simply choosing a value for $T(0):$
$$
T(x)=
  \begin{cases}
    \sin\left(\frac{1}{x}\right),&\text{if }x\neq 0\\
    b,&\text{if }x=0
  \end{cases}.
$$
Use Theorem~\ref{thm:LimDefOfContinuity} to show that $T$ is not continuous at $0$, no
  matter what value is chosen for $b$.
\LabelProblem{prob:continuity!Topologist's Sine function at zero}{}
\begin{solution}{}
  \begin{description}
  \item[Case 1:] $b\neq 1$\\
  Consider the sequence $(a_n)_{n=1}^\infty,$ where
  $a_n=\left(\frac{\pi(4n+1)}{2}\right).$ Clearly $a_n\rightarrow0.$
  However $T(a_n)= \sin\left(\frac{2}{\pi(4n+1)}\right) = 1.$
  Therefore by Theorem~\ref{thm:LimDefOfContinuity} $T(x)$ is not
  continuous at zero.
\item[Case 2:] $b=1$\\
  Consider the sequence $(a_n)_{n=1}^\infty,$ where
  $a_n=\left(\frac{\pi(4n-1)}{2}\right).$ Clearly $a_n\rightarrow0.$   However $T(a_n)= \sin\left(\frac{2}{\pi(4n+1)}\right) = -1.$
  Therefore by Theorem~\ref{thm:LimDefOfContinuity} $T(x)$ is not
  continuous at zero.
  \end{description}
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:continuity!limit definition}{}
  Turn the ideas of the previous two paragraphs into a
  formal proof of Theorem~\ref{thm:LimDefOfContinuity}.\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:continuity!preserved by multiplication}{}
  Use Theorem~\ref{thm:LimDefOfContinuity} to show that if  $f$ and  $g$ 
  are continuous at $a$, then  $f\cdot g$  is continuous at $a$.\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{lemma}
\label{lem:BoundedAwayFromZero}
\IndexLemma{lem:BoundedAwayFromZero}
%\index{Lemma by description!$g(a)\neq0$ implies $g$ is bounded away from zero on an
%  open interval around a}
  If $g$ is continuous at $a$  and $g(a)\neq 0,$ then
  there exists $\delta>0$ such that $g(x)\neq 0$  for all 
  $x\in(a-\delta,a+\delta)$.\xqed{\blacktriangle}{}
\end{lemma}

\begin{problem}
\LabelProblem{prob:continuity!continuous functions bounded away from zero}{}
  Prove  Lemma~\ref{lem:BoundedAwayFromZero}.  [Hint:  Consider the case
  where $g(a)>0.$ Use the definition  with
  $\eps=\frac{g(a)}{2}$.  The picture is below; make it formal.\\
\centerline{\includegraphics*[height=3in,width=4in]{TextGraphics/Ch5fig8}}
For the case $g(a)<0$, consider the function $-g$.]\xqed{\lozenge}{}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:continuity!preserved by division}{}
  Use Theorem~\ref{thm:LimDefOfContinuity}, to prove that if   $f$ and  $g$
   are continuous at $a$ and $g(a)\neq 0$, then  $f/g$  is
  continuous at $a$.\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{theorem}
\label{thm:ContComp}{}
\IndexTheorem{thm:ContComp}{}
  Suppose $f$  is continuous at $a$ and $g$ is
  continuous at  $f(a)$.  Then  $g\circ f$  is continuous at
  $a.\,\,$\lbrack Note that  $(g\circ f)(x)=g(f(x))$.\rbrack \xqed{\blacktriangle}{}
\end{theorem}

\begin{problem}
\LabelProblem{prob:continuity!preserved by composition}{}
Prove Theorem~\ref{thm:ContComp}{}
\begin{description}
\item[(a)] Using the definition of continuity.
\item[(b)] Using Theorem~\ref{thm:LimDefOfContinuity}.\xqed{\lozenge}{}
\end{description}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:continuity!examples of continuous functions}{}
  Show that each of the following is a continuous function at every
  point in its domain.
  \begin{enumerate}
  \item Any polynomial.
  \item Any rational function. (A rational function is defined to be a
    ratio of polynomial.
  \item $\cos x.$
  \item The other trig functions: $\tan(x),$ $\cot(x),$ $\sec(x),$ and
 $\csc(x).$\xqed{\lozenge}{}
  \end{enumerate}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:continuity!sin(e^x)}{}
  What allows us to  conclude that $f(x)=\sin\left(e^x\right)$
  is continuous at any point $a$ without referring back to the
  definition of continuity?\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:continuity!limits via}{}
  Compute the following limits.  Be sure to point out
  how continuity is involved.
  \begin{description}
  \item[(a)] $\displaystyle\lim_{n\rightarrow\infty}\sin\left(\frac{n\pi}{2n+1}\right)$
  \item[(b)] $\displaystyle\lim_{n\rightarrow\infty}\sqrt{\frac{n}{n^2+1}}$
  \item[(c)] $\displaystyle\lim_{n\rightarrow\infty}e^{\left(\text{sin }\left(1/n\right)\right)}$
  \end{description}\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:continuity!of limit{x}{a}{frac{x^2-a^2}{x-a}}}{}
  Use the definition of a limit to verify that 
$$
\limit{x}{a}{\frac{x^2-a^2}{x-a}}=2a.\xqedhere{1.9in}{\lozenge}{}
$$
\begin{solution}{}
  Let $\eps>0$ be given. Take $\delta=\eps.$ Then $\forall x\neq a$
  such that $\abs{x-a}<\delta$ we see that
  \begin{align*}
    \abs{\frac{x^2-a^2}{x-a}-2a} &= \abs{x+a-2a}\\
    &= \abs{x-a}\\
    &< \delta\\
    &= \eps.
  \end{align*}
Therefore $\limit{x}{a}{\frac{x^2-a^2}{x-a}}=2a.$
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:continuity!verifying limits via}{}
  Use the definition of a limit to verify each of the following
  limits.
  \begin{description}
  \item[(a)] $\limit{x}{1}{\frac{x^3-1}{x-1}}=3$\\
    \begin{hint}
      \begin{align*}
        \abs{\frac{x^3-1}{x-1}-3} &= \abs{x^2+x+1-3}\\
        &\leq\abs{x^2-1}+\abs{x-1}\\
        &=\abs{(x-1+1)^2-1}+\abs{x-1}\\
        &=\abs{(x-1)^2+2(x-1)}+\abs{x-1}\\
        &\leq\abs{x-1}^2 + 3\abs{x-1}.
      \end{align*}
    \end{hint}
    \begin{solution}
  Let $\eps>0$ be given. Take
  $\delta<\min\left(\sqrt{\frac{\eps}{6}},\frac\eps3\right).$ Then for
  every $x\neq a$ such that $\abs{x-a}<\delta$ we see that 
      \begin{align*}
        \abs{\frac{x^3-1}{x-1}-3} &= \abs{x^2+x+1-3}\\
        &\leq\abs{x^2+x-2}\\
        &\leq\abs{x^2-1+x-1}\\
        &\leq\abs{x^2-1}+\abs{x-1}\\
        &=\abs{(x-1+1)^2-1}+\abs{x-1}\\
        &=\abs{(x-1)^2-2(x-1)}+\abs{x-1}\\
        &\leq\abs{x-1}^2 + 3\abs{x-1}\\
        &\leq\abs{x-1}^2 + 3\abs{x-1}\\
        &\leq \left(\sqrt{\eps/2}\right)^2 + 3\left(\frac\eps6\right)\\
        &\leq \eps.
      \end{align*}
    \end{solution}
  \item[(b)] $\limit{x}{1}{\frac{\sqrt{x}-1}{x-1}}=1/2$\\
    \begin{hint}
      \begin{align*}
        \abs{\frac{\sqrt{x}-1}{x-1}-\frac12}&= \abs{\frac{1}{\sqrt{x}+1}-\frac12}\\
        &=\abs{\frac{2-\left(\sqrt{x}+1\right)}{2\left(\sqrt{x}+1\right)}}\\
        &=\abs{\frac{1-x}{2\left(1+\sqrt{x}\right)^2}}\\ 
        &\leq\frac12\abs{x-1}.
      \end{align*}
    \end{hint}
  \end{description}
  \begin{solution}{}
    Let $\eps>0$ be given. Take $\delta<2\eps.$ Then for all $x\neq 1$
    such that $\abs{x-a} <\delta$ we see that
      \begin{align*}
        \abs{\frac{\sqrt{x}-1}{x-1}-\frac12}&= \abs{\frac{1}{\sqrt{x}+1}-\frac12}\\
        &=\abs{\frac{2-\left(\sqrt{x}+1\right)}{2\left(\sqrt{x}+1\right)}}\\
        &=\abs{\frac{1-x}{2\left(1+\sqrt{x}\right)^2}}\\ 
        &\leq\frac12\abs{x-1}\\
        &\leq\frac12\delta\\
        &\leq\frac12(2\eps)\\
        &\leq\eps.
      \end{align*}
  \end{solution}
\xqed{\lozenge}
\newpage{}
\end{problem}

\begin{theorem}
\label{thm:CalcLimits}
\IndexTheorem{thm:CalcLimits}{}
  Suppose $\limit{x}{a}{f(x)}=L$ and $\limit{x}{a}{g(x)}=M,$ then
  \begin{description}
  \item[(a)] $\limit{x}{a}{\left(f(x)+g(x)\right)}=L+M$
  \item[(b)] $\limit{x}{a}{\left(f(x)\cdot g(x)\right)}=L\cdot M$
  \item[(c)] $\limit{x}{a}{\left(\frac{f(x)}{g(x)}\right)}=L/M$
 	provided $M\ne0$ and $g(x)\ne{}0$, for $x$ sufficiently close
        to a (but not equal to $a$). \xqedhere{2.8in}{\blacktriangle}{}
  \end{description}
\end{theorem}

\begin{problem}
\LabelProblem{prob:continuity!limit laws from calculus via}{}
  Prove parts (b) and (c) of Theorem~\ref{thm:CalcLimits}.\xqed{\lozenge}{}
  \begin{solution}{}
    \begin{description}
    \item[Part (a):] 
    \item[Part (b):] 
    \end{description}
  \end{solution}
\newpage{}
\end{problem}

\begin{theorem}{\bf{}(Squeeze Theorem for functions)}
\label{thm:SqueezeTheoremFunctions}
\IndexTheorem{thm:SqueezeTheoremFunctions}{}
  Suppose $f(x)\le g(x) \le h(x),$ for $x$ sufficiently close to $a$
  (but not equal to $a$). If
  $\limit{x}{a}{f(x)}=L=\limit{x}{a}{h(x)},$ then
  $\limit{x}{a}{g(x)}=L$ also.\xqed{\blacktriangle}{}
\end{theorem}

\begin{problem}
\LabelProblem{prob:continuity!Squeeze Theorem via}{}
  Prove Theorem~\ref{thm:SqueezeTheoremFunctions}. 
  [Hint:
    Use the Squeeze Theorem for sequences
    (Theorem~\ref{thm:SqueezeTheorem}) from
    Chapter~\ref{chpt:Convergence}.]\xqed{\lozenge}{}
    \begin{solution}{}
      Suppose
      $x_n\rightarrow a.$ Then for $n\in\NN$ sufficiently large,
\[
f(x_n)<g(x_n)<h(x_n).
\]
Therefore, by the Squeeze Theorem for
sequences~\ref{thm:SqueezeTheorem} $g(x_n)\rightarrow L.$ Since
$(x_n)$ was arbitrary we have 
\[
\limit{x}{a}{g(x)}=L.
\]
    \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:continuity!sin(x/x) at zero}{}
  Use the fact that $$\text{area}(\Delta OAC)<\text{area}(\text{sector
  }
  OAC)<\text{area}(\Delta OAB)$$ to show that if $0<x<\pi/2,$ then
  $\cos x<\sin x/x<1.$ Use the fact that all of these functions are
  even to extend the inequality for $-\pi/2<x<0$ and use the Squeeze
  Theorem to show $\limit{x}{0}{\textstyle\frac{\sin x}{x}}=1.$\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}


\begin{theorem}{\bf{}(Differentiability Implies Continuity)}
\label{thm:DiffImpCont}
\IndexTheorem{thm:DiffImpCont}{}
  If $f$ is differentiable at a point $c$ then $f$ is continuous at
  $c$ as well.\xqed{\blacktriangle}{}
\end{theorem}
\begin{problem}
  \LabelProblem{prb:DiffImpCont}{}
 Prove Theorem~\ref{thm:DiffImpCont}\xqed{\lozenge}{}
  \begin{solution}{}
    \underline{\bf First Proof:}\\
    Let $\eps>0$ be given.
    \begin{description}
    \item[{\bf{}Case 1:}] $f^\prime(c)=0.$\\
      There is a $\delta_1>0$ such that if $\abs{x-c} <\delta_1$ then
      $$
      \abs{\frac{f(x)-f(c)}{x-c}}<\sqrt{\eps},
      $$
      because $f(x)$ is differentiable, and there is a $\delta_2>0$ such that if $\abs{x-c} <\delta_2$ then
      $$\abs{x-c}<\sqrt{\eps}.$$
      Take $\delta=\min(\delta_1,\delta_2).$ Then $\forall\  x$ such
      that $\abs{x-c}<\delta$ we see that
      \begin{align*}
        \abs{f(x)-f(c)} &= \abs{\frac{f(x)-f(c)}{(x-c)}(x-c)}\\
        &= \abs{\frac{f(x)-f(c)}{x-c}}\abs{x-c}\\
        &<\sqrt{\eps}\cdot\sqrt{\eps}\\
        &=\eps.
      \end{align*}
    \item[{\bf{}Case 2:}] $f^\prime(c)\neq 0.$
      There is a $\delta_1>0$ such that if $\abs{x-c} <\delta_1$ then
      $$
      \abs{\frac{f(x)-f(c)}{x-c}-f^\prime(c)}<\sqrt{\frac{\eps}{2}},
      $$
      because $f(x)$ is differentiable, and there is a $\delta_2>0$ such that if $\abs{x-c} <\delta_2$ then
      $$\abs{x-c}<\frac{\eps}{2f^\prime(c)}.$$
      Take $\delta=\min\left(\delta_1,\delta_2,\sqrt{\frac{\eps}{2}}\right).$ Then $\forall\  x$ such       
      that $\abs{x-c}<\delta$ we see that
      \begin{align*}
        \abs{f(x)-f(c)} &= \abs{\frac{f(x)-f(c)}{(x-c)}(x-c)}\\
                        &= \abs{\frac{f(x)-f(c)}{(x-c)}-f^\prime(c)+f^\prime(c)}\abs{(x-c)}\\
                        &\le \abs{\frac{f(x)-f(c)}{(x-c)}-f^\prime(c)}\abs{x-c}+\abs{f^\prime(c)}\abs{(x-c)}\\
                        &\le \sqrt{\frac{\eps}{2}}\cdot\sqrt{\frac{\eps}{2}}+\frac{\eps}{2}\\
                        &=\eps.
      \end{align*}
    \end{description}

\underline{\bf Second Proof:}
Let $\eps>0$ be given. Let
$\delta<\frac{\eps}{\abs{f^\prime(a)}+\eps}.$ Then for every $x$ such
that $0<\abs{x-a}<\delta$ we have 
\begin{align*}
  \abs{\frac{f(x)-f(a)}{x-a}-f^\prime(a)}&<\eps\\
  \abs{f(x)-f(a) -(x-a)f^\prime(a)}&<\eps\abs{x-a.}\\
\intertext{But the Reverse Triangle Inequality we have }
  \abs{f(x)-f(a)} - \abs{(x-a)f^\prime(a)}&<\eps\abs{x-a}\\
  \abs{f(x)-f(a)} &<\eps\abs{x-a}+ \abs{(x-a)f^\prime(a)}\\
                  &<\abs{x-a}\left(\eps+ \abs{f^\prime(a)}\right)\\
                  &<\eps.
\end{align*}

\underline{\bf Third Proof:}
Observe that
\begin{align*}
  f(x)-f(c) &=   \left(f(x)-f(c)\right)\cdot\frac{(x-c)}{(x-c)} \\
  &= \frac{f(x)-f(c)}{x-c}\cdot(x-c). \\
\intertext{Since $f(x)$ is differentiable at $x=c,$
  $\limit{x}{c}{\frac{f(x)-f(c)}{x-c}}$ exists. Also
  $\limit{x}{c}{(x-c)}=0,$ so} \\
 \limit{x}{c}{(f(x)-f(c))} &=
                             \limit{x}{0}{\frac{f(x)-f(c)}{x-c}}\cdot\limit{x}{c}{(x-c)} \\
  &= f^\prime(c)\cdot0 \\
  &= 0.
\end{align*}
Therefore $f(x)$ is continuous at $x=c.$
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
  \LabelProblem{prob:FermatsTheoremMaxima} {}
  Show that $f^\prime(c) \geq 0$ and conclude that $f^\prime(c) =0.$\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
  \LabelProblem{prob:FermatsTheoremMinima} {}
  Show that if $f(c) \leq f(x)$ for all $x$ in some interval $(a,b)$
  then $f^\prime(c) =0$ too.\xqed{\lozenge}{}
  \begin{solution}{}
    Let $g(x) = -f(x).$ Then $\forall\, x\in(a,b),$ $g(c)\ge g(x).$ By
    the previous problem $g^\prime(c) = 0$ so $f^\prime(c) =
    -g^\prime(c) =0.$
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:MVT}{}
  Prove the Mean Value Theorem. 
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
  \LabelProblem{prob:PosDerivIncFunc1}{}
  Show that if $f^\prime(x) < 0$ for every $x$ in the interval $(a,b)$
  then $f$ is decreasing on $(a,b).$ \xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
  \LabelProblem{prob:PosDerivIncFunc2}{positive derivative at a point
    implies increasing on an interval}
Prove Corollary~\ref{cor:PosDerivIncFunc2}.\xqed{\lozenge}{}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
  \LabelProblem{prob:PosDerivIncFunc3}{negative derivative at a point
    implies decreasing on an interval}
  Show that if $f$ is differentiable on some interval $(a,b)$ and that
  $f^\prime(c)<0$ for some $c\in (a,b).$ Show that there is an interval,
  $I\subset (a,b),$ containing $c$ such that for every $x, y$ in $I$
  where $x\le y,$   $f(x)\le f(y).$\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:continuity!constant functions}{}
  Use the definition of continuity to prove that the
  constant function $g(x)=c$ is continuous at any point $a$.\xqed{\lozenge}{}
  \begin{solution}{}
    Let $\eps>0$ be given. Let $a\in\RR$ be any real number. Take
    $\delta>0.$ Then
    for every $x\in\RR$ such that 
$$
\abs{x-c}<\delta
$$
we see that 
$$
\abs{f(x)-f(a)} = \abs{c-c} = 0 <\eps.
$$
Therefore $f(x)$ is continuous at every real number $a.$
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}\ 
\LabelProblem{prob:continuity!ln(x)}{}
  \begin{description}
  \item[(a)] Use the definition of continuity to prove that $\ln x$ is
    continuous at $1$.  \lbrack Hint: You may want to use the fact 
    $\abs{\ln x}<\eps\,\Leftrightarrow-\eps<\ln x<\eps$ to
    find a $\delta$.\rbrack
  \item[(b)] Use part (a) to
    prove that $\ln x$ is continuous at any positive real number
    $a$. [Hint: $\ln(x)=\ln(x/a)+\ln(a).$ This is a combinabtion of
    functions which are continuous at $a.$ Be sure to explain how you
    know that $\ln(x/a)$ is continuous at $a.$]\xqed{\lozenge}{}
\end{description}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:continuity!formal definition of discontinuity}{}
  Write a formal definition of the statement $f$ is not continuous
  at $a$, and use it to prove that the function
  $f(x)=
  \begin{cases}
    x&\text{if }x\neq 1\\
    0&\text{if }x=1
  \end{cases}
  $
  is not continuous at $a=1$.\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\chapter{Intermediate and Extreme Values}
\label{chpt:IVTEVT}
\markboth{{\sc Intermediate And Extreme Values}}{{\sc Intermediate And Extreme Values}}

\begin{problem}
\LabelProblem{prob:NIP-LowerLessThanUpper}{}
  Let $(x_n), (y_n)$ be sequences as in the NIP. Show that for all $n,
  m \in\NN,$ $x_n\le y_m.$\xqed{\lozenge}{}
  \begin{solution}{}
    \begin{description}
    \item[First Proof] \ \\
      One of the assumptions of the NIP is that when
      $n=m,$ $x_n\le y_n$ so we need only consider the case $n\neq m.$
      There are two cases:
      \begin{description}
      \item[$n<m:$] In this case we see that
        \[x_n\le y_n \le y_m.\]
      \item[$n>m:$] In this case we see that
        \[x_n\le x_m \le y_m.\]
      \end{description}
    \item[Second Proof:] \ \\
      From the NIP, there is a unique real number, $c,$ such that
      $c\in[x_n,y_n],$ $\forall n\in\NN.$ Therefore $x_n\leq c,$
      $\forall n\in\NN,$ and $c\leq y_n,$  $\forall n\in\NN.$ Thus
\(x_n\leq x_m\) $\forall n,m \in\NN.$
    \end{description}
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:LUBP implies irrational numbers}{}
  \begin{description}
  \item[(a)] Find two sequences of rational numbers
  $\left(x_n\right)\,$and $\left(y_n\right)$ which satisfy properties
  1-4 of the NIP and such that there is no rational number $c$
  satisfying the conclusion of the NIP.  \lbrack Hint:  Consider the
  decimal expansion of an irrational number.\rbrack
\item[(b)] Find two sequences of rational numbers $\left(x_n\right)\,$
  and $\left(y_n\right)$ which satisfy properties 1-4 of the NIP and
  such that there is a rational number $c$ satisfying the conclusion
  of the NIP.\xqed{\lozenge}{}
\end{description}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{theorem}
\label{thm:ConvergeToC}
\IndexTheorem{thm:ConvergeToC}{}
Suppose that we have two sequences $\left(x_n\right)$ and
$\left(y_n\right)$ satisfying all of the assumptions of the Nested
Interval Property.  If $c$ is the unique number such that $x_n\leq
c\leq y_n$ for all $n$, then $\lim_{n\rightarrow\infty}x_n=c\,$ and
$\lim_{n\rightarrow\infty}y_n=c$.\xqed{\blacktriangle}{}
\end{theorem}

\begin{problem}
\LabelProblem{prob:NIP endpoint sequences converge}{}
  Prove Theorem~\ref{thm:ConvergeToC}.\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{theorem}
\label{thm:SqrtsExist}
\IndexTheorem{thm:SqrtsExist}{}
 Suppose $a\in\mathbb{R},\,a\geq 0$.  There exists a
  real number $c\geq 0$ such that $c^2=a$.\xqed{\blacktriangle}{}
\end{theorem}

\begin{problem}
\LabelProblem{prob:square roots exist}{}
  Turn the above outline into a formal proof of Theorem~\ref{thm:SqrtsExist}.\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:existence of Euler's constant}{}
The purpose of this problem is to show that  \
  $$\lim_{n\rightarrow\infty}\left(\left(1+\frac{1}{2}+\frac{1}{3}+\cdots+%
      \frac{1}{n}\right)-\ln\left(n+1\right)\right)$$ exists.
  \begin{description}
  \item[(a)] Let
    $x_n=\left(1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{n}\right)-\ln\left(n+1% 
  \right)$.  Use the following diagram to show
$$
x_1\leq x_2\leq x_3\leq\cdots
$$
\centerline{\includegraphics*[height=1.6in,width=4in]{TextGraphics/Ch6fig7}}
\begin{solution}{}
  From the diagram it is clear that $x_n$ is the sum of the areas of
  the upper right-hand corners of each of the shown rectangles. That
  is, if $p_n$ is the upper right-hand corner of the $n$th rectangle then
  $$
  x_n = \sum_{k=1}^np_k < \sum_{k=1}^{n+1}p_k < x_{n+1}.
  $$
  Therefore 
$$
x_1\leq x_2\leq x_3\leq\cdots.
$$
\end{solution}
\item[(b)]  Let
  $z_n=\ln\left(n+1\right)-\left(\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{n+1}%
  \right)$.  Use a similar diagram to show that
  $z_1\leq z_2\leq z_3\leq\cdots.$
  \begin{solution}{}
    Computing the height of each rectangle from  the right endpoint
    and setting $q_n$ to be the area of the region between the curve
    and the top of the $n$th rectangle we get 
  $$
  z_n = \sum_{k=1}^nq_k < \sum_{k=1}^{n+1}q_k < z_{n+1}.
  $$
  \end{solution}
\item[(c)] Let $y_n=1-z_n.$ Show that $\left(x_n\right)$ and
  $\left(y_n\right)$ satisfy the hypotheses of the nested interval
  property and use the NIP to conclude that there is a real
number $\gamma$ such that $x_n\leq\gamma\leq y_n$ for all $n$.
  \begin{solution}{} Observe that
    \begin{align*} y_n-x_n &= 1-z_n-x_n\\ &= 1- \ln(n+1) +(1/2
                                            +1/3+\ldots +1/n+1/(n+1))
      \\
                                         &\ \ \ \ \ \ - (1+1/2 +1/3+\ldots +1/n) + \ln(n+1)\\ &=
1/(n+1).
    \end{align*} Since $y_n-x_n>0$ we have $y_n>x_n
\,\forall\,n\in\NN.$

    Since $\abs{y_n-x_n}=1/(n+1)$ we have
$\limit{n}{\infty}{\abs{y_n-x_n}}=0.$

    Therefore $\left(x_n\right)$ and $\left(y_n\right)$ satisfy the
hypotheses of the nested interval property.

Therefore $\left(x_n\right)$ and $\left(y_n\right)$ satisfy the
hypotheses of the nested interval property
  \end{solution}
\item[(d)]  Conclude that
  $\lim_{n\rightarrow\infty}\left(\left(1+\frac{1}{2}+\frac{1}{3}+\cdots+%
      \frac{1}{n}\right)-\ln\left(n+1\right)\right)=\gamma$.
\end{description}
\begin{solution}{}
Therefore   $\lim_{n\rightarrow\infty}\left(\left(1+\frac{1}{2}+\frac{1}{3}+\cdots+%
      \frac{1}{n}\right)-\ln\left(n+1\right)\right)=\gamma$.\xqed{\lozenge}{}
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:gamma!approximating}{}
  Use the fact that  $x_n\leq\gamma\leq y_n$  for all
  $n$ to approximate $\gamma$ to three decimal places.\xqed{\lozenge}{}
  \begin{solution}{}
  $\gamma\approx0.577215$  
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}\ 
\LabelProblem{prob:gamma!slow convergence to}{}
  \begin{description}
  \item[(a)] Use the fact that for large $n$, \
  $1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{n}\approx$ln$\left(n+1\right)+%
  \gamma$ to determine approximately how large $n$ must be to make\\
$$
1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{n}\geq 100.
$$
\begin{solution}{}
  Since
  \begin{align*}
    1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{n} - \ln(n+1) &\approx +
                                                              \gamma \\
    \intertext{we have} \\
    1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{n} &\approx \ln(n+1) +
                                                              \gamma \\
    \intertext{so we need}
    \ln(n+1)    +   \gamma &\geq 100\\
    \ln(n+1)&\geq 100-\gamma \\
    n       &\geq e^{100}-1 \\
    \intertext{or}
    n       &\geq 2.688\times10^{43}\\
  \end{align*}
\end{solution}
\item[(b)]  Suppose we have a supercomputer which can add 10 trillion terms
  of the harmonic series per second.  Approximately how many earth
  lifetimes would it take for this computer to sum the harmonic series
  until it surpasses 100?
\end{description}\xqed{\lozenge}{}
\begin{solution}{}
  Assuming the earth is approximately six billion $(10^9)$ years old
\end{solution}
\newpage{}
\end{problem}

\begin{theorem}{\bf{}(Intermediate Value Theorem)}
\label{IntermediateValueTheorem}
% \IndexTheoremGeneral{IntermediateValueTheorem}{Intermediate Value Theorem (IVT)}
% \IndexTheoremTheorems{IntermediateValueTheorem}{Intermediate Value Theorem}
  Suppose $f(x)$  is
  continuous on $[a,b]$ and $v$ is any real number between $f(a)$
  and $f(b).$  Then there exists a real number $c\in[\,a,b]$ such
  that  $f(c)=v.$\xqed{\blacktriangle}{}
\end{theorem}

  \begin{problem}
\LabelProblem{prob:IVT!half of proof}{}
    Turn the ideas of the previous paragraphs into a
    formal proof of the IVT for the case  $f(a)\leq v\leq f(b)$.\xqed{\lozenge}{}
    \begin{solution}{}
      \noindent{}{\bf Inductive Construction:} Let $x_1=a,$ and
      $y_1=b$ so that $x_1\le y_1$ and $f(x_1)\le v \le f(y_1).$ Then
      $[x_1,y_1]$ is our first intervals.

      Assume $[x_n,y_n]$ and $[f(x_n),f(y_n)]$ have been constructed
      as above. To construct $[x_{n+1}, y_{n+1}]$ let $m$ be the
      midpoint of $[x_n,y_n].$

      If $f(m) \le v$ take $x_{n+1}=m$ and $y_{n+1}=y_n.$

      If $f(m) \ge v$ take $x_{n+1}=x_n$ and $y_{n+1}=m.$

    In either case we have $x_{n+1}\le y_{n+1}$ and  $f(x_{n+1})\le v
    \le f(y_{n+1}).$

    By construction, $\left\{[x_n,y_n]\right\}_{n=1}^\infty$ is a set
  of Nested Intervals. Therefore there is a unique $c\in
  [x_n,y_n],\forall\,n\in\NN.$

  \noindent{}{\bf{}Claim:} $f(c)=v.$

  \noindent{}{\bf Proof of Claim:} (by Contradiction)\\
  \begin{description}
  \item[Case 1:] $f(c)>v$
    In this case, by problem~\ref{prob:sequences-bounded}, part b,
    there is a real number $N$ such that if $n>N$ then $f(x_n) > v.$
    But by construction, $f(x_n) \le v.$

    This is a contradiction.
  \item[Case 2:] $f(c)<v$
    As in  part a, we obtain the contradiction $f(y_n)<v.$
    (Use Problem~\ref{prob:sequences-bounded}, part a.
  \end{description}
  Therefore $f(c)=v.$
\end{solution}
  \newpage{}
\end{problem}

  \begin{problem}
\LabelProblem{prob:IVT!other half of proof}{}
 We can modify the proof of the case $f(a)\leq v\leq
    f(b)$  into a proof of the IVT for the case  $f(a)\geq v\geq
    f(b)$.  However, there is a sneakier way to prove this case by
    applying the IVT to the function $-f$.  Do this to prove the IVT
    for the case  $f(a)\geq v\geq f(b)$.\xqed{\lozenge}{}
    \begin{solution}{}
      Suppose $f(a)\geq v\geq f(b).$ Then $-f(a)\leq -v\leq -f(b)$

      Define $h(x)=-f(x),$ so that
      $$
      h(a)\leq -v\leq h(b)
      $$
      By the previous problem $\exists\ c\in[a,b]$ such that
      $$
      h(c)=-v=-f(c).
      $$
      Therefore
      $$
      f(c)=v.
      $$
    \end{solution}
  \newpage{}
\end{problem}

  \begin{problem}
\LabelProblem{prob:IVT!odd degree polynomial must have a root}{}
    Use the IVT to prove that any polynomial of odd degree must have a
    real root.\xqed{\lozenge}{}
    \begin{solution}{}
      
    \end{solution}
  \newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:convergence of subsequences}{}
Suppose  $\lim_{n\rightarrow\infty}x_n=c$. \
  Prove that  $\lim_{k\rightarrow\infty}x_{n_k}=c$ for any
  subsequence $\left(x_{n_k}\right)$ of $\left(x_n\right)$.  \lbrack
  Hint:  $n_k\geq k$.\rbrack\xqed{\lozenge}{}
  \begin{solution}{}
\noindent{\bf Claim:} If $\left(x_{n_k}\right)_{k=1}^\infty$ is a subsequence of $\left(x_n\right)_{n=1}^\infty$ then $n_k\ge k.$\\
\begin{proof}\\
  \underline{\bf by Induction:}\\
  \underline{\bf Base case:} $k=1.$
  Since $n_k$ is a positive integer, clearly $n_k\ge 1.$\\
  \underline{\bf Induction Hypothesis:} $n_k\ge k.$ 
  Since $n_k$ is a strictly \emph{increasing} sequence of integers we have $n_{k+1} \ge n_k+1 \ge k+1.$
\end{proof}
    Let $\eps>0$ be given and suppose $x_k\rightarrow c$ as
    $k\rightarrow\infty.$ Then $\exists\ N\in\RR$ such that $\forall\ 
    k>N, \abs{x_k-c}<\eps.$ Let $\left(x_{n_k}\right)_{k=1}^\infty$ be
    a subsequence of $\left(x_k\right).$ Since $x_{n_k} \ge x_k$ we see that $\forall\ k>N,$ $n_k\ge k> N.$ Therefore $\abs{x_{n_k}-c}<\eps.$
  \end{solution}
  \newpage{}
\end{problem}

\begin{theorem}
\label{BolzanoWeierstrass}
% \IndexTheoremGeneral{BolzanoWeierstrass}{Bolzano-Weierstrass Theorem (BWT)}
% \IndexTheoremTheorems{BolzanoWeierstrass}{Bolzano-Weierstrass Theorem}
  {\bf{}The Bolzano-Weierstrass Theorem} Let
  $\left(x_n\right)$ be a sequence of real numbers such that
  $x_n\in[\,a,b]$, $\forall$ $n$.  Then there exists $c\in[\,a,b]$
  and a subsequence $\left(x_{n_k}\right)$, such that \
  $\lim_{k\rightarrow\infty}x_{n_k}=c$.\xqed{\blacktriangle}{}
\end{theorem}

\begin{problem}
\LabelProblem{prob:Bolzano-Weierstrass!proof}{}
  Turn the ideas of the above outline into a formal
  proof of the Bolzano-Weierstrass Theorem.\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{theorem}
\label{thm:CompactBounded}
\IndexTheorem{thm:CompactBounded}{}
  A continuous function defined on a closed, bounded
  interval must be bounded.  That is, let $f$ be a continuous
  function defined on $[\,a,b]$.   Then there exists a positive real
  number $B$ such that $|f(x)|\leq B$ for all $x\in[\,a,b]$.\xqed{\blacktriangle}{}
\end{theorem}

\begin{problem}
\LabelProblem{prob:Bolzano-Weierstrass!implies compact sets bounded}{}
Use the Bolzano-Weierstrass Theorem to complete the proof of
Theorem~\ref{thm:CompactBounded}.\xqed{\lozenge}{}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{theorem}
\label{thm:LUB}
\IndexTheorem{thm:LUB}{}
{\bf{} (The Least Upper Bound Property (LUBP))} Let $S$ be a nonempty
subset of $\mathbb{R}$ which is bounded above.  Then $S$ has a
supremum.\xqed{\blacktriangle}{}
\end{theorem}

\begin{problem}
\LabelProblem{prob:Bolzano-Weierstrass!implies LUB}{}
  Complete the above ideas to provide a formal proof of
  Theorem~\ref{thm:LUB}{}.\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{corollary}
  \label{cor:IncBoundedConverge}
  Let $(x_n)$ be a bounded, increasing sequence of real numbers.  That
  is, $x_1\leq x_2\leq x_3\leq\cdots.$ Then $(x_n)$ converges to some
  real number $c$.\xqed{\blacktriangle}{}
\end{corollary}
\begin{problem}
\LabelProblem{prob:prove corollary cor:IncBoundedConverge}{}
  Prove Corollary~\ref{cor:IncBoundedConverge}.

  [Hint:  Let $c=\sup\{x_n|\,n=1,2,3,\ldots\}$.  To show
  that  $\lim_{n\rightarrow\infty}x_n=c$, let $\epsilon$
  $>0.\,\,$Note that $c-\epsilon$  is not an upper bound.  You take
  it from here!]\xqed{\lozenge}{}
  \begin{solution}{}
  Let $c=\sup \{x_n\|n\in\NN\}.$\\
  \noindent{}{\bf Claim:} $x_n\rightarrow c.$\\
    \begin{proof}
    Since $c-\eps<c,$ $c-\eps$ is not an upper bound of
    $\left\{x_n\right\}_{n=1}^\infty.$ Therefore $\exists\
    N\in\NN\subset\RR$ such that
    $$
    x_N>c-\eps.
    $$
    If $m>n$ then $x_m>x_N$ so
    \begin{align*}
      x_m&>c-\eps \\
      x_m-c&>-\eps \\
      c-x_m&<\eps.
    \end{align*}
    Since $x_m\le c,$ $c-x_m>0$ so
    $$
    \abs{c-x_m}<\eps,\ \ \forall\ m>N.
    $$
    Therefore $x_m\rightarrow c.$
    
  \end{proof}
  \end{solution}
    \newpage{}
\end{problem}
% \begin{problem}
% \LabelProblem{prob:prove corollary cor:IncBoundedConverge}{}
%   Prove Corollary~\ref{cor:IncBoundedConverge}.

%   \lbrack Hint:  Let $c=$sup$\{x_n|\,n=1,2,3,\ldots\}$.  To show
%   that  $\lim_{n\rightarrow\infty}x_n=c$, let $\epsilon$
%   $>0.\,\,$Note that $c-\epsilon$  is not an upper bound.  You take
%   it from here!\rbrack\xqed{\lozenge}{}
%   \begin{solution}{}
    
%   \end{solution}
% \newpage{}
% \end{problem}

\begin{problem}
\LabelProblem{prob:nested square roots}{}
Consider the following curious expression
$\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{\ldots}}}}.$ We will use
Corollary~\ref{cor:IncBoundedConverge} to show that this actually
converges to some real number.  After we know it converges we can
actually compute what it is.  Of course to do so, we need to define
things a bit more precisely.  With this in mind consider
the following sequence $\left(x_n\right)$ defined as follows:\\
  $$x_1=\sqrt{2}$$
  $$x_{n+1}=\sqrt{2+x_n}.$$
  \begin{description}
  \item[(a)]  Use induction to show that $x_n<2$ for
  $n=1,\,2,\,3,\,\ldots\,$.
  \begin{solution} 
    \begin{description}
    \item[First Solution:] 
      The proof will be by induction. \\
      {\bf Initial Case:} $x_1=\sqrt{2} < 2.$\\
      {\bf Induction Step:} Suppose $x_n<2.$ Then
      \begin{align*}
        x_{n+1}&= \sqrt{2+x_n}\\
               &< \sqrt{2+2}\\
               &= 2.
      \end{align*}
    \item[Second Solution:] 
      The proof will be by induction. \\
      {\bf Initial Case:} $x_1=\sqrt{2} < 2.$\\
      {\bf Induction Step:} Suppose $x_n<2.$ Then
      \begin{align*}
        x_n&<2\\
        x_n+2&<4\\
        \sqrt{x_n+2}&<2\\
      \end{align*}
    \end{description}
  \end{solution}
\item[(b)] Use the result from (a) to show that $x_n<x_{n+1}$ for
  $n=1,\,2,\,3,\,\ldots.$
  \begin{solution}{}
    \begin{description}
    \item[First Solution] 
      The proof will be by induction. \\
      {\bf Initial Case:} $x_2=\sqrt{2+\sqrt{2}}>\sqrt{2}=x_1$\\
      {\bf Induction Step:} Suppose $x_{n+1}>x_n.$ Then
      Observe that:
      \begin{align*}
        x_{n+1} &= \sqrt{2+x_n}
                  \intertext{so that, by part (a)}
                  x_{n+1} &> \sqrt{x_n+x_n}\\
                &> \sqrt{2}\cdot\sqrt{x_n}\\
                &> \sqrt{x_n}\cdot\sqrt{x_n} \\
        \intertext{so that }
        x_{n+1} &> x_n.
      \end{align*}
    \item[Second Solution] 
      The proof will be by induction. \\
      {\bf Initial Case:} $x_2=\sqrt{2+\sqrt{2}}>\sqrt{2}=x_1$\\
      {\bf Induction Step:} Suppose $x_{n+1}>x_n.$ Then
      \begin{align*}
        x_n&<x_{n+1}\\
        x_n+2&<x_{n+1}+2\\
        \sqrt{x_n+2}&<\sqrt{x_{n+1}+2}\\
        x_{n+1}&<x_{n+2}
      \end{align*}
    \end{description}
  \end{solution}
\item[(c)] From Corollary~\ref{cor:IncBoundedConverge}, we have that $\left(x_n\right)$ must converge
  to some number $c$.  Use the fact that $\left(x_{n+1}\right)$ must
  converge to $c$ as well to compute what $c$ must be.
\end{description}\xqed{\lozenge}{}
\begin{solution}{}
  We know that $x_{n+1}=\sqrt{2+x_n}.$ Taking the limit of both sides
  gives
$$ \limit{n}{\infty}{x_{n+1}} = \limit{n}{\infty}{\sqrt{2+x_n}}$$
or 
$$
c = \sqrt{2+c}.
$$

Solving this quadratic gives $c=2$ and $c=-1.$ Of these, only the
first makes sense because $x_n>0,\ \forall\ n\in\NN.$
\end{solution}
\newpage{}
\end{problem}

\begin{theorem}
\label{thm:EVT}{}
\IndexTheorem{thm:EVT}{}
  {\bf{}(Extreme Value Theorem (EVT))} Suppose $f$ is continuous on
  $[\,a,b]$.   Then there exists $c,d\in[\,a,b]$ such that $f(d)\leq
  f(x)\leq f(c)$, for all $x\in[\,a,b]$.\xqed{\blacktriangle}{}
\end{theorem}

\begin{problem}
\LabelProblem{prob:EVT}{}
 Formalize the above ideas into a proof of Theorem~\ref{thm:EVT}.\xqed{\lozenge}{}
 \begin{solution}{}
   
 \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:BW!implies NIP}{}
Use the Bolzano-Weierstrass Theorem to prove the NIP. That is, assume that the
Bolzano-Weierstrass Theorem holds and suppose we have two sequences of
real numbers, $ \left(x_n\right)$ and $ \left(y_n\right),$ satisfying:
  \begin{enumerate}
  \item $x_1\le x_2 \le x_3 \le \ldots$
  \item $y_1\ge y_2 \ge y_3 \ge \ldots$
  \item $\forall\ n, x_n\le y_n$
  \item $\displaystyle\lim_{n\rightarrow\infty}\left(y_n-x_n\right) = 0.$
  \end{enumerate}
  Prove that there is a real number $c$ such that $x_n\le c\le y_n,$
  for all $n.$ (The $c$ will, of necessity, be unique, but don't worry
  about that.)\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:subsequence!of rationals doesn't converge to an irrational}{}
Find a bounded sequence of rational numbers such that no subsequence
of it converges to a rational number.\xqed{\lozenge}{}
\begin{solution}{}
  Suppose the decimal representation of some irrational number between zero and one is given by: $0.d_1d_2d_3d_4d_5\ldots.$ Then $(a_n=0.d_1d_2\cdots d_n)_{n=1}^\infty $ is such a sequence.
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:LUBP implies NIP}{}
  Use the Least Upper Bound Property to prove the Nested Interval
  Property. That is, assume that every nonempty subset of the real
  numbers which is bounded above has a least upper bound; and suppose
  that we have two sequences of real numbers $\left(x_n\right)$ and
  $\left(y_n\right),$ satisfying:
  \begin{enumerate}
  \item $x_1\le x_2 \le x_3 \le \ldots$
  \item $y_1\ge y_2 \ge y_3 \ge \ldots$
  \item $\forall\ n, x_n\le y_n$
  \item $\displaystyle\lim_{n\rightarrow\infty}\left(y_n-x_n\right) = 0.$
  \end{enumerate}
Prove that there exists a real number $c$ such that $x_n\le c\le y_n,$
for all n. (Again, the $c$ will, of necessity, be unique, but don't
worry about that.)
[Hint: Corollary~\ref{cor:IncBoundedConverge} might work well here.]\xqed{\lozenge}{}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:LUBP doesn't hold in Q}{}
  Since the LUBP is equivalent to the NIP it does not hold for the
  rational number system. Demonstrate this by finding a nonempty set
  of rational numbers which is bounded above, but whose supremum is an
  irrational number.\xqed{\lozenge}{}
\begin{solution}{}
  Suppose the decimal representation of some irrational number between zero and one is given by: $0.d_1d_2d_3d_4d_5\ldots.$ Then $(a_n=0.d_1d_2\cdots d_n)_{n=1}^\infty $ is such a sequence.
\end{solution}

\newpage{}
\end{problem}

\begin{theorem}{\bf{}(Archimedean Property of $\RR$)}
\label{thm:ArchmedeanProperty}
\IndexTheorem{thm:ArchmedeanProperty}{}
  Given any positive real numbers $a$ and $b,$ there exists a positive
  integer $n,$ such that $na>b.$ \xqed{\blacktriangle}{}
\end{theorem}

\begin{problem}
\LabelProblem{prob:ArchimedeanProperty}{}
    Prove Theorem~\ref{thm:ArchmedeanProperty}. [Hint: Assume that
    there are positive real numbers $a$ and $b,$ such that $na\le b$
    $\forall n\in \NN.$  Then
    $\NN$ would be bounded above by $b/a.$  Let $s=\sup(\NN)$ and
    consider $s-1.$]\xqed{\lozenge}{}
    \begin{solution}{}
      \begin{proof} 
        {Our proof will be  by contradiction.}
        Suppose $\exists$ $a,b\in\RR^+$ such that 
        \[na\le b, \  \forall\ n\in\NN.\]
        Then \[n\le\frac{b}{a} \  \forall\ n\in\NN.\] In other words
        the set of positive integers is bounded above. Therefore (by B-W)
        $\NN$ has a least upper bound. Let $s=\text{\rm{}lub}(\NN)$
        and observe that there is an integer, $k,$ in the interval
        $(s-1,s].$ Since $k\in\NN$ we see that $k+1\in\NN$ as
        well. But $k+1>s$ which is a contradiction since $s$ is an
        upper bound on $\NN.$ 

        Therefore given any positive real numbers $a$ and $b,$ there
        exists a positive integer $n,$ such that $na>b.$
      \end{proof}
    \end{solution}
  \newpage{}
\end{problem}

  \begin{problem}
\LabelProblem{prob:ArchimedeanPropertyNotEquivalentToNIP}{}
    Does $\QQ$ satisfy the Archimedean Property
    and what does this have to do with the question of taking the
    Archimedean Property as an axiom of completeness?\xqed{\lozenge}{}
    \begin{solution}{}
      
    \end{solution}
  \newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:LUB-defining infimum (GLB)}{problem!LUB!defining infimum (GLB)}
Mimic the definitions of an upper bound of a set and the least upper
bound (supremum) of a set to give definitions for a lower bound of a
set and the greatest lower bound (infimum) of a set.  Note: The
infimum of a set $S$ is denoted by $\inf(S)$.\xqed{\lozenge}{}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:LUB-identifying suprema and infima}{problem!LUB!identifying suprema and infima}
  Find the least upper bound (supremum) and greatest
  lower bound (infimum) of the following sets of real numbers, if they
  exist. (If one does not exist then say so.)
  \begin{description}
  \item[(a)] $S=\{\frac{1}{n}\,|\,n=1,2,3,\ldots\}$
  \item[(b)] $T=\{r\,|\,r$ is rational and $r^2<2\}$
  \item[(c)] $(-\infty,0)\cup(1,\infty)$
  \item[(d)] $R=\{\frac{(-1)^n}{n}\,|\,n=1,2,3,\ldots\}$
  \item[(e)] $(2,3\pi]\cap\QQ$
  \item[(f)] The empty set $\emptyset$\xqed{\lozenge}{}
  \end{description}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:LUB-infimum and}{problem!LUB!infimum and}
  Let $S\subseteq\RR$ and let $T=\{-x|\,x\in S\}.$
  \begin{description}
  \item[(a)] Prove that $b$ is an upper bound of $S$ if and only if $-b$ is a
lower bound of $T$.
\begin{solution}{}
  Observe that $s\in S \imp -s\in T.$ 

Thus if
\begin{align*}
  b &\ge s,\  \forall\, s\in S\\
\intertext{then}
  -b &\le -s,\  \forall\, s\in S.\\
\intertext{Therefore }
  -b &\le t,\  \forall\, t\in T.\\
\end{align*}

Therefore $-b$ is a lower bound of $T.$

\end{solution}
\item[(b)] Prove that $b=\sup S$ if and only if $-b=\inf T.$ \xqed{\lozenge}{}
\end{description}

\newpage{}
\end{problem}

\chapter{Back to Power Series}
\label{chpt:PowerSeriesRedux}
\markboth{{\sc Back to Power Series}}{{\sc Back to Power Series}}

\begin{problem}
  \LabelProblem{prob:Cauchy's incorrect proof}{}
  Find the flaw in the following ``proof'' that $f$ is also continuous
  at $a.$ 

  Suppose $f_1, f_2, f_3, f_4 \ldots$ are all continuous at $a$ and
  that $\sum_{n=1}^\infty f_n=f.$ Let $\eps>0.$ Since $f_n$ is
  continuous at $a,$ we can choose $\delta_n>0$ such that if
  $\abs{x-a}<\delta_n,$ then $\abs{f_n(x)-f_n(a)}<\frac{\eps}{2^n}.$
  Let $\delta=\inf(\delta_1,\delta_2,\delta_3,\ldots).$ If
  $\abs{x-a}<\delta$ then
\begin{align*}
  \abs{f(x)-f(a)} &=  \abs{\sum_{n=1}^\infty f_n(x)  -  \sum_{n=1}^\infty f_n(a) }\\
   &= \abs{\sum_{n=1}^\infty \left(f_n(x)-f_n(a)\right) }\\
   &\le \sum_{n=1}^\infty \abs{f_n(x)-f_n(a) }\\
   &\le \sum_{n=1}^\infty \frac{\eps}{2^n}\\
   &\le \eps\sum_{n=1}^\infty \frac{1}{2^n}\\
   &=   \eps.
\end{align*}
Thus $f$ is continuous at $a.$\xqed{\lozenge}{}
\begin{solution}{}
  The flaw is that $\delta=\inf(\delta_1,\delta_2,\delta_3,\ldots)$
  might be zero. In that case then $x=a$ and all we proven is that
  $\abs{f(a)-f(a)}<\eps,$ which is true but does not show continuity.
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:uniform convergence}{}
 Let $0<b<1$ and consider the sequence of functions
  $\left(f_n\right)$ defined on $[0,b]$    by $f_n(x)=x^n$.  Use
  the definition to show that  $f_n\unif 0$
  on $[0,b]$.
  \lbrack Hint:  $|x^n-0|=x^n\leq b^n$.\rbrack\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{theorem}
\label{thm:UnifConv->Continuity}{}
\IndexTheorem{thm:UnifConv->Continuity}{}
  Consider a sequence of functions $\left(f_n\right)$
  which are all continuous on an interval $I.$  Suppose
  $f_n\unif f$ on $I$.  Then $f$ must be
  continuous on $I$.\xqed{\blacktriangle}{}
\end{theorem}

\begin{problem}
\LabelProblem{prob:uniform convergence!implies continuity of limit function}{}
  Provide a formal proof of Theorem~\ref{thm:UnifConv->Continuity} based on the above
  ideas.\xqed{\lozenge}{}
  \begin{solution}{}
    Take $N\in\RR$ such that $\forall\,\,n>N$ $\abs{f_n(x) -
      f(x)}<\frac{\eps}{3},$ $\forall\,\,x\in I.$

    Let $n>N$ be fixed. Since $f_n$ is continuous $\exists\,\, \delta>0$
    such that if $\abs{x-a}<\delta$ then
    $\abs{f_n(x)-f_n(a)}\le\frac{\eps}{3}.$
    Let $a\in I$ and suppose that $\abs{x-a}<\delta.$ Then
    \begin{align*}
      \abs{f(x) - f_n(x)} &= \abs{f(x)-f_n(x) + f_n(x) - f_n(a) +
                            f_n(a) -f(x)}\\
                         &\le \abs{f(x)-f_n(x)} + \abs{f_n(x) - f_n(a)} +
                           \abs{f_n(a) -f(x)}.\\
                         &\le \frac{\eps}{3} +\frac{\eps}{3}
                           +\frac{\eps}{3}\\
                           &\le \eps.
    \end{align*}
    Therefore $f(x)$ is continuous at every $a\in I.$

  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:xn converges pointwise}{$x^n$ converges pointwise
  on $[0,1]$}
  Consider the sequence of functions $\left(f_n\right)$
  defined on $[0,1]$ by $f_n(x)=x^n$.  Show that the sequence
  converges to the function 
$$f(x)=
  \begin{cases}
    0&\text{if  }x\in[0,1)\\
    1&\text{if }x=1
  \end{cases}
$$
pointwise on $\,[0,1]$, but not uniformly on $[0,1]$.\xqed{\lozenge}{}
\begin{solution}{}
  There are two cases:
  \begin{description}
  \item[Case 1, $x=1$:] In this case
    $\limit{n}{\infty}{f_n(x)}=\limit{n}{\infty}{1}=1=f(x).$
  \item[Case 2, $0\le x< 1$:] In this case there is a $b$ such that
    $x<b<1.$ Since $\limit{n}{\infty}{b^n} =0$ it follows from the
    comparison test that $\limit{n}{\infty}{x^n} =0$ also. 
  \end{description}
  Therefore $f_n\ptwise f$ on $I.$

  To show that  the convergence is not  uniform take $\eps=1/2,$ 
  take $\delta>0,$  and consider $a=1.$ For every $x\in (\delta,1],$
  $\limit{n}{\infty}{abs{f_n(a)-f_n(x)}}=1> 1/2=\eps.$
\end{solution}
\newpage{}
\end{problem}

\begin{theorem}
\label{th:UniformIntegralConvergence}
Suppose $f_n$ and $f$ are integrable and $f_n\unif f$ on
$[a,b]$. Then
$$
\limit{n}{\infty}{\int_{x=a}^b
f_n(x)\d x}=\int_{x=a}^bf(x)\d x.
\xqedhere{1.4in}{\blacktriangle}{}$$
\end{theorem}
\begin{problem}
\LabelProblem{prob:UniformConvergenceAndIntegration}{uniform convergence!integration and}
Prove Theorem~\ref{th:UniformIntegralConvergence}.
  \lbrack Hint:  For $\eps>0$,
  we need to make  $|f_n(x)-f(x)|<\frac{\eps}{b-a}$,  for all
  $x\in[a,b]$.\rbrack \xqed{\lozenge}{}
  \begin{solution}{}
    Observe that $(s_n)_{n=1}^\infty = 
    \left(
      \int_a^bf_n(x)\d{x}
    \right)_{n=1}^\infty$ is a sequence.

    Let $\eps>0$ be given and take $n$ sufficiently large that
    $$
    \abs{f_n(x)-f(x)}<\frac{\eps}{b-a}.
    $$

    Then
    \begin{align*}
      \abs{\int_a^bf_n(x)\d{x}-\int_a^bf(x)\d{x}} &=
                                                    \abs{\int_a^bf_n(x)-f(x)\d{x}} \\
      &\leq\int_a^b\abs{f_n(x)-f(x)}\d{x} \\
      &\leq\int_a^b\frac{\eps}{b-a}\d{x} \\
      &=\frac{\eps}{b-a}(b-a) \\
      &=\eps.
    \end{align*}

  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:pointwise vs. uniform convergence}{}
  Consider the sequence of functions 
$\left(f_n\right)$
  given by
$$f_n(x)=
\begin{cases}
  n&\text{if }x\in\left(0,\frac{1}{n}\right)\\
    0&\text{otherwise}
\end{cases}.
$$

  \begin{description}
  \item[(a)]  Show that $f_n\ptwise 0$ on $[0,1]$, but
  $\displaystyle\lim_{n\rightarrow\infty}\int_{x=0}^1$
  $f_n(x)\d x\neq\int_{x=0}^10\d x$
\item[(b)]  Can the convergence be uniform?  Explain.
\end{description}\xqed{\lozenge}{}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{corollary}
\label{cor:IntConvUni}
If $\sum_{n=0}^\infty a_nx^n$ converges
uniformly\footnote{Notice that we must explicitly assume uniform
  convergence. This is because we have not \underline{yet} proved that
  power series actually do converge uniformly.} to $f$ on an interval
containing $0$ and $x$ then $\int_{t=0}^xf(t)\d
t=\sum_{n=1}^\infty\left(\frac{a_n}{n+1}x^{n+1}\right).$\xqed{\blacktriangle}{}
\end{corollary}
\begin{problem}
\LabelProblem{prob:uniform convergence!integrating power series}{}
  Prove Corollary~\ref{cor:IntConvUni}.
  [Hint: Remember that 
$$
\displaystyle \sum_{n=0}^\infty f_n(x) = 
            \lim_{N\rightarrow\infty}\sum_{n=0}^N f_n(x).
]$$\xqed{\lozenge}{}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{theorem}
\label{thm:UniformDerivativeConvergence}
\IndexTheorem{thm:UniformDerivativeConvergence}{}
Suppose for every $n\in\NN$ $f_n$ is differentiable, $f_n^\prime$ is
continuous, $f_n\ptwise f,$ and $f_n^\prime\unif g$ on an interval,
$I.$ Then $f$ is differentiable and $f^\prime = g$ on
$I.$\xqed{\blacktriangle}{}
\end{theorem}

\begin{problem}
\LabelProblem{prob:uniform convergence!differentiation and}{}
  Prove Theorem~\ref{thm:UniformDerivativeConvergence}.  \lbrack Hint: Let $a$ be an arbitrary
  fixed point in $I$ and let $x\in I$.  By the fundamental theorem of
  calculus, we have $$\int_{t=a}^x f^\prime_n(t)\d t=f_n(x)-f_n(a).$$ Take
  the limit of both sides and differentiate with respect to
  $x$.\rbrack\xqed{\lozenge}{}
  \begin{solution}{}
    Since $f^\prime\unif g$ we have, by theorem~\ref{th:UniformIntegralConvergence}
    \begin{align*}
      \limit{n}{\infty}{\int_{t=a}^x f^\prime(t)d{t}} &= \int_{t=a}^xg(t)\d{t}\\
         \intertext{or}
         \limit{n}{\infty}{\left(f_n(x)-f_n(a)\right)} &= \int_{t=a}^xg(t)\d{t}\\
       \intertext{and finally,}
         f(x)-f(a) &= \int_{t=a}^xg(t)\d{t}.\\
      \end{align*}
Since the right side of this last equation is differentiable, so is the left side. Therefore $f^\prime(x)$ exists. 

Differentiating gives
$$
f^\prime(x) = g(x).
$$
  \end{solution}
\newpage{}
\end{problem}

\begin{corollary}
\label{cor:UniformConvergenceDerivative}{}
  If $\sum_{n=0}^\infty a_nx^n$ converges pointwise to
  $f$ on an interval containing $0$ and $x$ and $\sum_{n=1}^\infty
  a_nnx^{n-1}$ converges uniformly on an interval containing $0$ and
  $x$, then $f^\prime(x)=\sum_{n=1}^\infty a_nnx^{n-1}.$\xqed{\blacktriangle}{}
\end{corollary}
\begin{problem}
\LabelProblem{prob:uniform convergence!differentiating power series}{}
  Prove Corollary~\ref{cor:UniformConvergenceDerivative}.\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{theorem}
\label{thm:Converge->Cauchy}{}
\IndexTheorem{thm:Converge->Cauchy}{}
 Suppose $\left(s_n\right)$ is a sequence of real
  numbers which converges to $s$.  Then $\left(s_n\right)$ is a
  Cauchy sequence.\xqed{\blacktriangle}{}
\end{theorem}

\begin{problem}
\LabelProblem{prob:Cauchy sequences!convergence implies Cauchy}{}
  Prove Theorem~\ref{thm:Converge->Cauchy}.
  [Hint: 
  $\abs{s_m-s_n}=\abs{s_m-s+s-s_n}\leq\abs{s_m-s}+\abs{s-s_n}$.]\xqed{\lozenge}{}
  \begin{solution}{}

    Let $\eps>0$ be given.

    Since $s_n\ptwise s,$ $\exists\  n\in\NN$ such that $\forall\,m>n \abs{s_m-s}<\frac\eps2$

Thus
\begin{align*}
  \abs{s_m-s_n}=\abs{s_m-s+s-s_n}&\leq\abs{s_m-s}+\abs{s-s_n}\\
  &\leq \frac\eps2+\frac\eps2\\
  &= \eps
\end{align*}
  \end{solution}
\newpage{}
\end{problem}

\begin{lemma}
  \label{lemma:Cauchy->Bounded}
\IndexLemma{lemma:Cauchy->Bounded}
%  \index{Lemma by description!Cauchy sequences are bounded}
  {\bf{}(A Cauchy sequence is bounded)} Suppose
  $\left(s_n\right)$ $\,$is a Cauchy sequence.  Then there exists
  $B>0$ such that $|s_n|\leq B\,$for all $n$.\xqed{\blacktriangle}{}
\end{lemma}

\begin{problem}
\LabelProblem{prob:Cauchy sequences!Cauchy implies bounded}{}
Prove Lemma~\ref{lemma:Cauchy->Bounded}.  \lbrack Hint: This is
similar to problem~\ref{prob:BoundedConvergent} of
Chapter~\ref{chpt:Convergence}.  There exists $N$ such that if
$m,n>N\,$then $|s_n-s_m|<1.\,\,$ Choose a fixed $m>N$ and let
$B=\max\left(\abs{s_1}, \abs{s_2}, \ldots, \abs{s_{\lceil N\rceil}},
  \abs{s_m}+1\right)$.\rbrack\xqed{\lozenge}{}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{theorem}{\bf{}(Cauchy sequences converge)}
\label{thm:Cauchy->Converge}
  Suppose
  $\left(s_n\right)\,$is a Cauchy sequence of real numbers.  There
  exists a real number $s$ such that 
  $\lim_{n\rightarrow\infty}s_n=s$.\xqed{\blacktriangle}{}
\end{theorem}


\begin{problem}
\LabelProblem{prob:Cauchy sequences!Cauchy implies convergence}{}
Provide a formal proof of
Theorem~\ref{thm:Cauchy->Converge}.\xqed{\lozenge}{}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{theorem}
  \label{thm:ConvCauchyEquivNIP}
\IndexTheorem{thm:ConvCauchyEquivNIP}{}
  Suppose every Cauchy sequence converges. Then the Nested Interval
  Property is true.\xqed{\blacktriangle}{}
\end{theorem}

\begin{problem}
\LabelProblem{prob:Cauchy sequences!Cauchy implies NIP}{Cauchy implies NIP}
Prove Theorem~\ref{thm:ConvCauchyEquivNIP}.
  \lbrack Hint:  If we start with two sequences $\left(x_n\right)$
  and $\left(y_n\right),$ satisfying all of the conditions of the NIP,
  you should be able to show that these are both Cauchy
  sequences.\rbrack\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:Cauchy sequences!don't converge in Q}{}
Since the convergence of Cauchy sequences can be taken as the
completeness axiom for the real number system, it does not hold for
the rational number system.  Give an example of a Cauchy sequence of
rational numbers which does not converge to a rational
number.\xqed{\lozenge}{}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{theorem} {\bf{}(Cauchy Criterion)}  
\label{thm:CauchyCriterion}
The series $\sum_{k=0}^\infty a_k$ converges if
  and only if  $\forall \eps>0$, $\exists N$ such that if 
  $m>n>N$ then $|\sum_{k=n+1}^ma_k|<\eps.$\xqed{\blacktriangle}{}
\end{theorem}

\begin{problem}
\LabelProblem{prob:Cauchy sequences!Cauchy criterion}{}
 Prove the Cauchy criterion.\xqed{\lozenge}{}
 \begin{solution}{}
   Suppose $\sum_{n=0}^\infty s_n=s.$ Then, by definition, the sequence
   $\left(\sum_{k=0}^ns_k\right)_{n=0}^\infty$ converges to $s$
   also. 

   Therefore the sequence $\left(\sum_{k=0}^ns_k\right)_{n=0}^\infty$
   is Cauchy.

   Let $\eps>0$ be given. Then for $m,n$ sufficiently large and WLOG
   $m\ge n$ we have
   \begin{align*}
     \eps&>\abs{\sum_{k=0}^ms_k - \sum_{k=0}^ns_k}\\
         &=\abs{\sum_{k=n+1}^ms_k}
 \end{align*}
 \end{solution}
\newpage{}
\end{problem}

\begin{problem}{\bf{}(The $n$th Term Test)}
  \LabelProblem{prob:NthTermTest}{$n$th term test}
  Show that if $\sum_{n=1}^\infty a_n$ converges then $\limit{n}{\infty}{a_n}=0.$\xqed{\lozenge}{}
  \begin{solution}{}
    Apply the Cauchy Criterion with $m=n+1.$
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}{\bf (The Strong Cauchy Criterion)}
  \LabelProblem{prob:StrongCauchyCriterion}{Strong Cauchy Criterion}
Show that  $\sum a_n$ converges if and only if
$\limit{n}{\infty}{\sum_{k=n+1}^\infty a_n}=0.$ [Hint: The hardest
part of this problem is recognizing that it is really about the limit
of a sequence as in Chapter~\ref{chpt:Convergence}.]\xqed{\lozenge}{}
\begin{solution}{}
  \begin{description}
  \item[Case 1:] Assume that $\sum a_n=c.$ \\

    Let $\eps>0$ be given.

    Since $\displaystyle \sum_{k=1}^\infty a_k = c$ we see that there
    is a real number $N$ such that if $n>N$ then:
    \begin{align*}
      \abs{c-\sum_{k=1}^n a_k} &< \eps.\\
      \intertext{Therefore if $n>N$} \abs{c-\sum_{k=1}^n
        a_k-\sum_{k=n+1}^\infty a_k +
        \sum_{k=n+1}^\infty a_k } &< \eps\\
      \abs{\underbrace{c-\sum_{k=1}^\infty a_k}_{=0}+
        \sum_{k=n+1}^\infty a_k } &< \eps\\
      \abs{\sum_{k=n+1}^\infty a_k } &< \eps\\
    \end{align*}

    Therefore $\limit{n}{\infty}{\sum_{k=n+1}^\infty a_n}=0.$
  \item[Case 2:] Assume $\limit{n}{\infty}{\sum_{k=n+1}^\infty
      a_n}=0.$
    Let $\eps>0$ be given.

    There is an $N\in\RR$ such that $\forall\ n>N$ we have
    $\displaystyle\sum_{k=n+1}^\infty a_n < \frac{\eps}{2}.$ Let
    $m>n>N.$ Then
    \begin{align*}
      \sum_{k=n+1}^ma_k &= \sum_{k=n+1}^\infty a_k -
                          \sum_{k=m+1}^\infty a_k \\
\intertext{so that}
      \abs{\sum_{k=n+1}^ma_k} &= \abs{\sum_{k=n+1}^\infty a_k -
                                \sum_{k=m+1}^\infty a_k} \\
      \abs{\sum_{k=n+1}^ma_k} &\leq \abs{\sum_{k=n+1}^\infty a_k} +
                                \abs{\sum_{k=m+1}^\infty a_k} \\
      &= \frac{\eps}{2} + \frac{\eps}{2}.\\
\intertext{Therefore}      
      \abs{\sum_{k=n+1}^ma_k}&\leq \eps.
    \end{align*}
Therefore $\displaystyle\sum_{k=n+1}^\infty a_n $ satisfies the Cauchy
Criterion.

Therefore $\displaystyle\sum_{k=n+1}^\infty a_n $ converges.    
  \end{description}
\end{solution}
\newpage{}
\end{problem}

\begin{theorem}
\label{thm:ComparisonTest}
\IndexTheorem{thm:ComparisonTest}{} Suppose $|a_n|\leq b_n$ for all
$n.$ If $\sum b_n$ converges then $\sum a_n$ also
converges.\xqed{\blacktriangle}{}
\end{theorem}

\begin{problem}
\LabelProblem{prob:Cauchy sequences!Comparison Test}{Comparison Test}
 Prove Theorem~\ref{thm:ComparisonTest}. 
\lbrack Hint:  Use the Cauchy criterion with the fact that
$\abs{\sum_{k=n+1}^ma_k}\leq\sum_{k=n+1}^m\abs{a_k}.$\rbrack\xqed{\lozenge}{}
\begin{solution}{}
Let $\eps>0$ be given. Since $b_n\ge 0$ and $\sum_{k=1}^\infty b_k$ is
Cauchy $\exists\,N\in\RR$ such that $\forall\,m>n>N$
$$
  \sum_{k=n+1}^mb_k= \abs{\sum_{k=n+1}^mb_k}<\eps.
$$
Therefore
$$
  \abs{\sum_{k=n+1}^ma_k} \le
  \sum_{k=n+1}^m\abs{a_k}\le\sum_{k=n+1}^mb_k<\eps.
$$

Therefore $\sum_{k=1}^\infty a_k$ is Cauchy. 

Therefore $\sum_{k=1}^\infty a_k$ converges.

\end{solution}
\newpage{}
\end{problem}

\begin{corollary}
\label{cor:AbsConv->Conv}
 If  $\sum a_n$ converges absolutely, then $\sum a_n$
   converges.\xqed{\blacktriangle}{}
\end{corollary}

\begin{problem}
\LabelProblem{prob:Cauchy sequences!Absolute Convergence}{}
   Show that Corollary~\ref{cor:AbsConv->Conv}{} is a direct consequence of
  Theorem~\ref{thm:ComparisonTest}.\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:Cauchy sequences!Absolute Convergence does not imply convergence}{}
 If  $\sum_{n=0}^\infty|a_n|=s$, then does it follow
  that $s=|\sum_{n=0}^\infty a_n|$?  Justify your answer.  What can
  be said?\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{theorem}
\label{thm:RearrageAbsConv}
\IndexTheorem{thm:RearrageAbsConv}{}
 Suppose $\sum a_n$ converges absolutely and let
  $s=\sum_{n=0}^\infty a_n$.  Then any rearrangement of $\sum a_n$
  must converge to $s$.\xqed{\blacktriangle}{}
\end{theorem}

\begin{problem}
\LabelProblem{prob:Cauchy sequences!rearrangements of Absolutely Convergent series}{}
 Fill in the details and provide a formal proof of
  Theorem~\ref{thm:RearrageAbsConv}{}.\xqed{\lozenge}{}
  \begin{solution}{}
    \noindent{\bf{}\underline{Special Case:} Assume $a_n\ge 0\,\,\forall\, n\in\NN.$}\\
    Let $p(n)$ be a permutation of $\NN.$ Then $\sum_n^\infty a_{p(n)}$ is a rearrangement of 
      $\sum_n^\infty a_{n}.$  Since $a_n\ge0$ and $\sum_n^\infty a_n$
      converges, say to $A,$ we see that for every $k\in\NN,$
      \begin{align*}
        0&\le \sum_{n=1}^ka_n\le A\\
\intertext{and}        
        0&\le \sum_{n=1}^ka_{p(n)}\le A.\\
      \end{align*}
Since the \emph{sequence} $\left(\sum_{n=1}^ka_{p(n)}\right)_k$ is
bounded, and increasing it converges, say to $B.$

\noindent{\bf \underline{Claim:}} $B\le A.$\\
{\bf Proof (by Contradiction) of Claim:} Suppose $B>A.$ Then there is
a positive integer, $m,$ such that 
$$
\sum_{n=1}^ma_{p(n)} > A.
$$
Take $\displaystyle P=\max_{0\le n \le m}\left\{p(n)\right\}.$ 

Then
$$\hskip2in\sum_{n=1}^p a_n \ge \sum_{n=1}^p a_{p(n)} > A \hskip1in
\Rightarrow\Leftarrow$$
Therefore $B\le A.\hskip3.5in \halmos \text{ (Claim.)}$

Since $\sum_{n=1}^p a_n$ is a rearrangement of $\sum_{n=1}^p a_{p(n)}$
we also have $A\le B.$ Therefore $A=B.$\hskip3in{}{$\halmos$ (Special Case.)}

\noindent{\bf{}\underline{General Case:}}
  \begin{align*}
    \sum_{n=1}^\infty a_n &= \sum_{n=1}^\infty\left(
      \frac{\abs{a_n}+a_n}{2} -
      \frac{\abs{a_n}-a_n}{2} \right)\\
    \intertext{Since $\frac{\abs{a_n}+a_n}{2}\le \abs{a_n}$ and
      $\frac{\abs{a_n}-a_n}{2}\le \abs{a_n},$ both $\sum_{n=1}^\infty
      \frac{\abs{a_n}+a_n}{2}$ and $\sum_{n=1}^\infty
    \frac{\abs{a_n}-a_n}{2}$ converge, by the Comparison
    Test. Therefore}
    \sum_{n=1}^\infty a_n &= \left(\sum_{n=1}^\infty
      \frac{\abs{a_n}+a_n}{2} -\sum_{n=1}^\infty
      \frac{\abs{a_n}-a_n}{2} \right).\\
\intertext{Recall that  $p(n)$ is a permutaion of $\NN.$ Since both of
the above series are positive, by our \underline{Special Case} }
    \sum_{n=1}^\infty a_n &= \left(\sum_{n=1}^\infty
      \frac{\abs{a_{p(n)}}+a_{p(n)}}{2} -\sum_{n=1}^\infty
      \frac{\abs{a_{p(n)}}-a_{p(n)}}{2} \right).\\
    &= \left(\sum_{n=1}^\infty
      \frac{\abs{a_{p(n)}}+a_{p(n)}}{2}-
      \frac{\abs{a_{p(n)}}-a_{p(n)}}{2} \right).\\
&=\sum_{n=1}^\infty a_{p(n)}. 
  \end{align*}

  \end{solution}
\newpage{}
\end{problem}

\begin{theorem}
\label{thm:RadiusOfConvergence}
\IndexTheorem{thm:RadiusOfConvergence}{}
 Suppose $\sum_{n=0}^\infty a_nc^n$ converges for some
  nonzero real number $c$.  Then $\sum_{n=0}^\infty a_nx^n$ converges
  absolutely for all $x$ such that $|x|<|c|$.\xqed{\blacktriangle}{}
\end{theorem}

\begin{problem}
\LabelProblem{prob:Cauchy sequences!Radius of Convergence}{}
 Prove Theorem~\ref{thm:RadiusOfConvergence}.\xqed{\lozenge}{}
 \begin{solution}{}
 By the $n$th Term Test $a_nc^n\rightarrow 0$ as $n\rightarrow0.$
 Therefore $\abs{a_nc^n}<B  $ for some real number, $B.$ Therefore
 \begin{align*}
   \abs{a_nx^n} &= \abs{a_nc^n\left(\frac{x}{c}\right)^n}\\
   &= \abs{a_nc^n}\abs{\frac{x}{c}}^n\\
   &\le B\abs{\frac{x}{c}}^n.\\
\end{align*}
Since $\abs{\frac{x}{c}}<1,$ $\sum_{n=0}^\infty
  B\abs{\frac{x}{c}}^n$ is a convergent geometric series. Therefore,
  by the Comparison Test $\sum_{n=0}^\infty a_nx^n$ converges
  absolutely. Therefore $\sum_{n=0}^\infty a_nx^n$ converges.


 \end{solution}
\newpage{}
\end{problem}

\begin{corollary}
\label{cor:RadiusOfDivergence}
 Suppose  $\sum_{n=0}^\infty a_nc^n$ diverges for
  some real number $c$.  Then  $\sum_{n=0}^\infty a_nx^n$ diverges
  for all $x$ such that $|x|>|c|.$\xqed{\blacktriangle}{}
\end{corollary}

\begin{problem}
\LabelProblem{prob:Cauchy sequences!a series diverges outside its Radius of Convergence}{}
 Prove Corollary~\ref{cor:RadiusOfDivergence}.\xqed{\lozenge}{}
 \begin{solution}{}
   The proof is by contradiction. Suppose for some real number
   $\abs{x}>\abs{c}$ the series converges. Then by
   theorem~\ref{thm:RadiusOfConvergence} the series $\sum_{n=0}^\infty
   a_nc^n$ converges, which contradicts the assumption that
   $\sum_{n=0}^\infty a_nc^n$ diverges.

Therefore Corollary~\ref{cor:RadiusOfDivergence} is true.
 \end{solution}
\newpage{}
\end{problem}

\begin{theorem}{\bf{}(The Weierstrass-$M$ Test)}
\label{thm:WeierstrassM}
\IndexTheorem{thm:WeierstrassM}{}
  Let $\left\{f_n\right\}_{n=1}^\infty$ be a sequence of functions
  defined on $S\subseteq\RR$ and suppose that
  $\left(M_n\right)_{n=1}^\infty$ is a sequence of nonnegative real
  numbers such that $$\abs{f_n(x)}\leq M_n,\,\, \forall x\in S,\,\, n=1, 2, 3,
  \ldots.$$

If $\sum_{n=1}^\infty M_n$ converges then $\sum_{n=1}^\infty
f_n(x)$ converges uniformly on $S$ to some function (which we will
denote by $f(x).$\xqed{\blacktriangle}{}
\end{theorem}

\begin{problem}
  \LabelProblem{prob:WeierstrassM}{}
Use the ideas above to provide a proof of
Theorem~\ref{thm:WeierstrassM}.\xqed{\lozenge}{}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}\ 
  \LabelProblem{prob:FourierUniformConv}{}
  \begin{description}
  \item[(a)] Referring back to Part~\ref{interegnum}, show that the Fourier
    series
$$
\sum_{k=0}^\infty\frac{(-1)^k}{(2k+1)^2}\sin\left((2k+1)\pi x\right)
$$
converges uniformly on $\RR.$
\item[(b)] Does its differentiated series converge uniformly on $\RR?$
  Explain.\xqed{\lozenge}{}
  \end{description}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:Weierstrass M-test!identifying pointwise vs. uniform convergence}{}
Observe that for all $x \in [-1,1]$ $\abs{x}\le 1.$ Identify which of
the following series converges pointwise and which converges
uniformly on the interval $[-1,1].$ In every case identify the limit function.\\
\centerline{ $ \displaystyle \text{(a)}\
  \sum_{n=1}^\infty\left(x^n-x^{n-1}\right) \ \ \ \ \ \text{(b)}\
  \sum_{n=1}^\infty\frac{\left(x^n-x^{n-1}\right)}{n} \ \ \ \ \
  \text{(c)}\ \sum_{n=1}^\infty\frac{\left(x^n-x^{n-1}\right)}{n^2} $
  \xqed{\lozenge}{}}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{theorem}
\label{thm:PowerSeriesConvergeUniformly}
\IndexTheorem{thm:PowerSeriesConvergeUniformly}{}
  Suppose $\sum_{n=0}^\infty a_nx^n$ has radius of
  convergence $r$ (where $r$ could be $\infty$ as well).  Let $b$ be
  any nonnegative real number with $b<r$.  Then  $\sum_{n=0}^\infty
  a_nx^n$ converges uniformly on $[-b,b]$.\xqed{\blacktriangle}{}
\end{theorem}

\begin{problem}
\LabelProblem{prob:Weierstrass M-test!and power series}{}
  Prove Theorem~\ref{thm:PowerSeriesConvergeUniformly}.  \lbrack Hint:  We know that \
  $\sum_{n=0}^\infty|a_nb^n|$ converges.  This should be all set for the Weierstrass-$M$ test.\rbrack\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:uniform convergence!integration and power series}{}
\label{prob:PwrSeriesDiffConv}
  Show that $\sum_{n=1}^\infty nx^{n-1}$ converges for
  $|x|<1$.   \lbrack Hint:  We know that
  $\sum_{k=0}^nx^k=\frac{x^{n+1}-1}{x-1}$.  Differentiate both sides
  and take the limit as $n$ approaches infinity.\rbrack\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{theorem}
\label{thm:SeriesConv->DerivConv}
\IndexTheorem{thm:SeriesConv->DerivConv}{}
 Suppose $\sum_{n=0}^\infty a_nx^n\,$has a radius of
  convergence $r$ and let $|x|<r$.  Then $\sum_{n=1}^\infty
  a_nnx^{n-1}$ converges.\xqed{\blacktriangle}{}
\end{theorem}

\begin{problem}
\LabelProblem{prob:uniform convergence!differentiation and power series}{}
 Prove Theorem~\ref{thm:SeriesConv->DerivConv}. \lbrack Hint:  Let $b$ be a number
  with $|x|<b<r$ and consider
  $\left|a_nnx^{n-1}|=|a_nb^n\cdot\frac{1}{b}\cdot
  n\left(\frac{x}{b}\right)^{n-1}\right|$.  You should be able to use the
  Comparison Test and Problem~\ref{prob:uniform convergence!integration and power series}.\rbrack\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:M test on boundary}{}
Suppose the power series $\sum
  a_nx^n$  has radius of convergence $r$ and the series $\sum a_nr^n$
  converges absolutely.  Then $\sum a_nx^n$ converges uniformly on
  $[-r,r].$ [Hint: For $|x|\leq r$, $|a_nx^n|\leq |a_nr^n|.$] \xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{lemma}
\label{lemma:AbelsPartialSummationFormula}
\IndexLemma{lemma:AbelsPartialSummationFormula}
%\index{Lemma by description!Abel's partial summation formula}
  {\bf{}Abel's Partial Summation Formula}  Let
  $$
   a_1,a_2,\,\ldots,\,a_n,\,b_1,b_2,\,\ldots\,,\,b_n
  $$ 
  be real numbers and let $A_m=\sum_{k=1}^ma_k$.  Then
  $$a_1b_1+a_2b_2+\cdots+a_nb_n=\sum_{j=1}^{n-1}A_j\left(b_j-b_{j+1}\text{
    }\right)+A_nb_n.\xqedhere{.75in}{\blacktriangle}$$
\end{lemma}

\begin{problem}
\LabelProblem{prob:Abel's Partial Summation}{}
 Prove Lemma~\ref{lemma:AbelsPartialSummationFormula}.  \lbrack Hint:  For $j>1$,
  $a_j=A_j-A_{j-1}$.\rbrack\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{lemma}
\label{lemma:AbelsLemma}
\IndexLemma{lemma:AbelsLemma}
%\index{Lemma by description!Abel's Lemma}
 Let $a_1,a_2,\,\ldots,\,a_n,\,b_1,b_2,\,\ldots\,,\,b_n$
  be real numbers with $\,b_1\geq b_2\geq\,\ldots\geq\,b_n\geq 0\,$and
  let $A_m=\sum_{k=1}^ma_k$.  Suppose $|A_m|\leq B$ for all $m$. 
  Then
  $|\sum_{j=1}^na_jb_j|\leq B\cdot b_1$\xqed{\blacktriangle}{}
\end{lemma}

\begin{problem}
\LabelProblem{prob:Abel's Lemma}{}
 Prove Lemma~\ref{lemma:AbelsLemma}.\xqed{\lozenge}{}
 \begin{solution}{}
   
 \end{solution}
 \begin{solution}{}
   
 \end{solution}
\newpage{}
\end{problem}


\begin{problem}
\LabelProblem{prob:Abel's Theorem}{}
  Prove Theorem~\ref{AbelsTheorem}.  \lbrack Hint:  Let $\epsilon>0$.
  Since $\sum_{n=0}^\infty a_nr^n$  converges then by the Cauchy
  Criterion, there exists $N$ such that if $m>n>N$ then
  $\abs{\sum_{k=n+1}^ma_kr^k}<\frac{\epsilon}{2}$  Let $0\leq x\leq r$.
  By
  Lemma~\ref{lemma:AbelsLemma}, $$\abs{\sum_{k=n+1}^ma_kx^k}=\abs{\sum_{k=n+1}^ma_kr^k\left(\frac{x}{r}\right)^k}\leq
  \left(\frac{\epsilon}{2}\right)\left(\frac{x}{r}\right)^{n+1}\leq\frac{\epsilon}{2}.$$ 
Thus for $0\leq x\leq r$, $n>N$, 
$$
\abs{\sum_{k=n+1}^\infty
  a_kx^k}=\lim_{n\rightarrow\infty}\abs{\sum_{k=n+1}^ma_kx^k}\leq\frac{\epsilon}{2}<\epsilon.\rbrack\xqedhere{1.1in}{\lozenge}{}
$$ 
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:uniform convergence!and power series}{}
Prove Corollary~\ref{cor:PowerSeriesConvUnif}.  \lbrack Hint: Consider
$\sum a_n\left(-x\right)^n$.\rbrack\xqed{\lozenge}{}
\centerline{\sc{} The wrong problem is given here.}
\begin{solution}{}
  \begin{proof}
    \begin{description}
    \item[Case 1 $(\implies)$:] Assume $a$ is a limit point of $S.$ Then
      there is a sequence, $\left(a_n\right)_{n=1}^\infty$ such that
      $a_n\rightarrow a$ and $a_n\in S-\left\{a\right\}.$ Therefore for
      every $\eps>0,\,\exists\, N\in\RR$ such that $\forall{}n>N$
$$
a_n\in(a-\eps,a+\eps).
$$

Therefore $a_n\in (a-\eps, a+\eps)\bigcap S-\left\{a\right\}. \hfill\halmos$
\item[Case 2$(\impliedby)$:] Assume $\forall{}\eps>0,$
$$
(a-\eps,a+\eps)\bigcap S-\left\{a\right\}\neq \emptyset
$$

Consider the sequence $\left(\frac1n\right)_{n=1}^\infty.$ By
assumption $\forall{}n\in\NN$ there is at least on
$a_n\in\left(a-\frac1n,a+\frac1n\right)\bigcap S-\left\{A\right\}.$
    Since $a-\frac1n\rightarrow a,$ and $a+\frac1n\rightarrow a,$ we
    see that $a_n\rightarrow a$ by the Squeeze Theorem. \hfill$\halmos$
    \end{description}
  \end{proof}
\end{solution}
\newpage{}
\end{problem}

\chapter{Back to the Real Numbers}
\label{chpt:BackToFourier}
\markboth{{\sc Back to the Real Numbers}}{{\sc Back to the Real Numbers}}


\begin{problem}
  \LabelProblem{prob:accumulation-point}{}
Let $S\subseteq\RR$  and let $a$ be a real number. Prove that $a$ is a
limit point of $S$ if and only if for every $\eps>0$ the intersection
$$
(a-\eps, a+\eps) \cap S-\left\{a\right\} \neq \emptyset.\xqedhere{1.55in}{\lozenge}{}
$$
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
  \LabelProblem{prob:derived-set}{}
Determine the derived set, $S^\prime,$ of each of the following
sets.
\begin{description}
\item[\hskip1in{}(a)] $S=\left\{\frac11, \frac12, \frac13, \ldots\right\}$
\item[\hskip1in{}(b)] $S=\left\{0,\frac11, \frac12, \frac13, \ldots\right\}$
\item[\hskip1in{}(c)] $S=(0,1]$
\item[\hskip1in{}(d)] $S=\left[\left.0,1/2\right)\right.\cup\left.\left(1/2,1\right.\right]$
\item[\hskip1in{}(e)] $S=\QQ$
\item[\hskip1in{}(f)] $S=\RR-\QQ$
\item[\hskip1in{}(g)] $S=\ZZ$
\item[\hskip1in{}(h)] Any finite set $S.$
\end{description}\xqed{\lozenge}{}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
  \LabelProblem{prob:derived-s-subset-of-s}{}
 Let $S\subseteq\RR.$ 
  \begin{description}
  \item[\hskip1in{}(a)] Prove that $\left(S^{\,\prime}\right)^{\,\prime}\subseteq S^{\,\prime}.$
  \item[\hskip1in{}(b)] Give  an example where these two sets are equal.
  \item[\hskip1in{}(c)] Give  an example where these two sets are not equal.
  \end{description}\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
  \LabelProblem{prob:NIP-TwoPoints}{}
Suppose $\limit{n}{\infty}{\abs{b_n-a_n}}>0.$ Show that there are at
least two points, $c$ and $d,$ such that 
$c\in[a_n, b_n]$ and $d\in[a_n, b_n]$ for all $n\in\NN.$

\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:countable sets!examples of}{}
Show that each of the following sets is countable.
\begin{description}
\item[(a)] $\left\{2,3,4,5,\ldots\right\}=\left\{n\right\}_{n=2}^\infty$
\item[(b)] $\left\{0,1,2,3,\ldots\right\}=\left\{n\right\}_{n=0}^\infty$
\item[(c)] $\left\{1,4,9,16,\ldots,n^2,\ldots\right\}=\left\{n^2\right\}_{n=1}^\infty$
\item[(d)] The set of prime numbers
\item[(e)] $\ZZ$\\
\solution{$f(n) =
  \begin{cases}
    2n & \text{ if }n>0\\
    \abs{2n}+1  & \text{ if }n\le0\\
  \end{cases}$
}
\end{description}\xqed{\lozenge}{}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:countable sets!unions of}{countable sets!unions and
  intersections of}
  Let $\left\{A_i\right\}$ be a collection of countable sets. Show
  that each of the following sets is also countable:
  \begin{description}
  \item[(a)] Any subset of $A_1.$
  \begin{solution}{}
    Let $A_1=\left\{a_n\right\}_{n=1}^\infty$ and  $T\subset A_1.$ Let
    $t_1=a_{n_1}$ where $n_1$ is the smallest subscript appearing in
    $T,$ $t_2=a_{n_2}$ the second smallest, and in general
    $t_k=a_{n_k}$ is the $k$th smallest subscript appearing in $T.$
    Then the function 
    $$
    f(t_k) = k
    $$ is clearly one to one and onto.
  \end{solution}
  \item[(b)] $A_1\cup A_2$
    \begin{solution}{}
      Since $A_1$ and $A_2$ are countable there are bijections
      $f|\NN\rightarrow A_1$ and $g|\NN\rightarrow A_2.$ Define
      $h|\NN\rightarrow A_1\cup A_2$ by
$$
h(n) =
\begin{cases}
  f\left(\frac{n}{2}\right)& \text{if $n$ is even}\\
  g\left(\frac{n+1}{2}\right)& \text{if $n$ is odd}.
\end{cases}
$$
    \end{solution}
  \item[(c)] $A_1\cup A_2 \cup A_3$
    \begin{solution}{}
      By part (b) the set $A_1\cup A_2$ is countable. Thus, also by
      part (b) the set $A_1\cup A_2\cup A_3$ is also countable.
    \end{solution}
  \item[(d)] $\displaystyle\bigcup_{i=1}^nA_i$
    \begin{solution}{}
      \underline{\bf{}Proof by Induction:}\\
      \noindent{\bf{}Base Case:} $A_1$ is countable by assumption.\\
      \noindent{\bf{}Induction Hypothesis: $\displaystyle\bigcup_{i=1}^{n-1}A_i$ is countable.}

      Then by part (b) of this problem
      $\displaystyle\bigcup_{i=1}^nA_i=\left(\bigcup_{i=1}^{n-1}A_i\right)\bigcup
      A_{n}$ is also countable.
    \end{solution}
  \item[(e)] $\displaystyle\bigcup_{i=1}^\infty A_i$
    \begin{solution}{}
      Let $T_n=\frac{n(n+1)}{2}$ be the $n$th Triangular
      Number. Observe that $T_n+(n+1)=T_{n+1}$ so that every
      non-negative\footnote{Note that $T_0 =0.$}
      integer can be represented uniquely as $k=T_n+m$ where $T_n$ is
      the largest Triangular Number less than or equal to $k$ and
      $0\le m \le n.$

      We label the elements of $A_n$ as follows:
$$
A_n = \left\{a_{n n}, a_{n n+1}, a_{n n+2}, \ldots\right\},
$$
and define $\mu:\bigcup_{i=1}^\infty A_i \rightarrow\;\NN\;\bigcup
\left\{0\right\}$
by $$\mu(a_{n m})= T_m+n.$$
    \end{solution}
  \end{description}\xqed{\lozenge}{}
\newpage{}
\end{problem}

\begin{theorem}
\label{thm:QisCountable}
\IndexTheorem{thm:QisCountable}{}
  Show that $\QQ$ is countable.\xqed{\blacktriangle}{}
\end{theorem}

\begin{problem}
\LabelProblem{prob:countable sets!Q}{}
  Prove Theorem~\ref{thm:QisCountable}.\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
  \LabelProblem{prob:QMeasureZero}{$\QQ$ has measure zero in $\RR$}
Prove Corollary~\ref{cor:Q-MeasureZero}.
[Hint: If we had only finitely many rationals to deal with this would
be easy. Let $\left\{r_1, r_2, \ldots, r_k\right\}$ be these rational
numbers and take $a_n=r_n-\frac{\eps}{2k}$ and
$b_n=r_n+\frac{\eps}{2k}.$ Then for all $n=1,\ldots, k$
$r_n\in[a_n,b_n]$ and 
$$
\sum_{n=1}^kb_n-a_n = \sum_{n=1}^k \frac{\eps}{k}=\eps.
$$
The difficulty is, how do we move from the finite to the infinite case?]
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\noindent{}\begin{problem}\ 
  \LabelProblem{prob:uncountable sets!open intervals in R}{}
  \begin{description} 
  \item[(a)] Let $(a,b)$ and $(c,d)$ be two open intervals of real
    numbers.  Show that these two sets have the same cardinality by
    constructing a one-to-one onto function between them.  [Hint: A
    linear function should do the trick.]
    \begin{solution}{}
      $$
      f(x) = \left(\frac{c-d}{a-b}\right)x + \frac{ad-bc}{a-b}
      $$
or
$$
      f(x) = \left(\frac{c-d}{a-b}\right)(x-b) + c
$$
    \end{solution}
  \item[(b)] Show that any open interval of real numbers has the same
    cardinality as $\RR.$ [Hint: Consider the interval
    $(-\pi/2,\pi/2).$]
    \begin{solution}{}
      Let $(a,b)$ be any open interval. By part (a) there is a mapping
      $\phi:(a,b)\rightarrow(-\pi/2,\pi/2).$

      Let $\psi:(-\pi/2,\pi/2)\rightarrow\RR$ be the mapping:
$$
\psi(x) = \tan(x).
$$
Then the composition $(\psi\circ\phi)$ maps $(a,b)$ to $\RR.$
    \end{solution}
  \item[(c)] Show that $(0,1]$ and $(0,1)$ have the same cardinality.
    [Hint: Note that  $\left\{1,1/2,1/3,\ldots\right\}$ and
    $\left\{1/2, 1/3, \ldots\right\}$  have the same cardinality.]
    \begin{solution}{}
      Define $\phi:(0,1]\rightarrow(0,1)$ by
      $$
      \phi(x) =
      \begin{cases}
        x; & \text{if $x\in(0,1)$ and $x\neq\frac1n, \forall\,n\in\NN$}\\
        \frac{1}{n+1}; & \text{if $x=\frac1n,$ for some $n\in\NN$}\\
      \end{cases}
      $$
    \end{solution}
  \item[(d)] Show that $[0,1]$ and $(0,1)$ have the same cardinality.
  \begin{solution}{}
    Define $\phi:[0,1]\rightarrow(0,1)$ by
      $$
      \phi(x) =
      \begin{cases}
        x; & \text{if $x\in(0,1)$ and $x\neq\frac1n, \forall\,n\in\NN$}\\[2mm]
        \frac12;& \text{if $x=0$}\\[2mm]
        \frac{1}{n+2}; & \text{if $x=\frac1n,$ for some $n\in\NN$}\\
      \end{cases}
      $$
  \end{solution}
  \end{description}\xqed{\lozenge}{}
\newpage{}
\end{problem}

\begin{problem}
  \LabelProblem{prob:NineBar}{}
  Consider the sequence $(0.9,0.99,0.999,\ldots).$ Determine that this
  sequence converges and, in fact, it converges to $1$.  This suggests
  that $0.999\ldots=1.$\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
  \LabelProblem{prob:PowerSet}{sets!power set}
Prove: If $\abs{S}=n,$ then $\abs{ P(S)}=2^n.$  [Hint:  Let
$S={a_1,a_2,\ldots,a_n}.$  Consider the following correspondence
between the elements of $P(S)$ and the set $T$ of all $n$-tuples of
yes (Y) or no (N):
\begin{align*}
  \{ \}  &\leftrightarrow \{N,N,N,\ldots,N\}\\
  \{a_1\}&\leftrightarrow \{Y,N,N,\ldots ,N\}\\
  \{a_2\}&\leftrightarrow \{N,Y,N,\ldots,N\}\\
&\vdots\\
S&\leftrightarrow \{Y,Y,Y,\ldots,Y\}
\end{align*}
How many elements are in $T?$]
\xqed{\lozenge}{}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{theorem}{\bf{}(Cantor's Theorem)}
  \label{thm:CantorsTheorem}
\IndexTheorem{thm:CantorsTheorem}{}
  Let $S$ be any set.  Then there is no one-to-one correspondence
  between $S$ and $P(S),$ the set of all subsets of $S.$\xqed{\blacktriangle}{}
\end{theorem}

\begin{problem}
  \LabelProblem{prob:CantorsTheorem}{}
Prove Cantor's Theorem (Theorem~\ref{thm:CantorsTheorem}).
[Hint: 
  Assume for contradiction, that there is a one-to-one correspondence
  $f:S\rightarrow P(S).$  Consider  $A=\left\{x\in S|x\not\in
    f(x)\right\}.$  Since $f$ is onto, then there is $a\in A$ such
  that  $A=f(a).$  Is $a\in A$  or is  $a\not\in A?$]\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
  \LabelProblem{prob:CountablyInfinite}{}
  Let $U_n=\{(a_1,a_2,a_3,\ldots)\  |\  a_j\in \{0,1\} \text{ and }
  a_{n+1}=a_{n+2}=\cdots=0\}.$ Show that for each $n,$ $U_n$ is finite and
use this to conclude that $U$ is countably infinite.\xqed{\lozenge}{}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
  \LabelProblem{prob:InfiniteContainsCountablyInfinite}{}
  Let $S$ be an infinite set.  Prove that $S$ contains a countably
  infinite subset.\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
  \LabelProblem{prob:InfiniteDeleteCountablyInfinite}{}
  Suppose $X$ is an uncountable set and $Y\subset X$ is countably
  infinite.  Prove that $X$ and $X-Y$ have the same cardinality.
  [Hint: Let $Y=Y_0.$ By the previous problem, $X-Y_0$ is an infinite
  set, so it contains a countably infinite set $Y_1.$ Likewise
  $X-(Y_0\cup Y_1)$ is infinite so it contains an infinite set $Y_2.$
  Again, $X-(Y_0\cup Y_1\cup Y_2)$ is an infinite set so it contains
  an infinite set $Y_3,$ etc. For $n=1, 2, 3,\ldots ,$ let
  $f_n:Y_{n-1}\rightarrow Y_n$ be a one-to-one correspondence and
  define $f:X\rightarrow X-Y$ by
$$
  \begin{cases}
    f(x)=f_n(x), &\text{ if } x\in Y_n, n=0,1,2,\ldots\\
    f(x)=x, &\text{ if } x\in X-(\cup_{n=0}^\infty Y_n )
  \end{cases}.
$$
  Show that $f$ is one-to-one and onto.]\xqed{\lozenge}{}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\chapter*{Epilogue}
\addcontentsline{toc}{chapter}{Epilogue}
\label{chap:epilogue}
\section*{On the Nature of Numbers: A Dialogue (with Apologies to
  Galileo)}
\label{sec:nature-numb-dial}
\addcontentsline{toc}{section}{{\bf{}Epilogue:} On the Nature of Numbers}
\markboth{{\sc Epilogue}}{{\sc The Nature Of Numbers}}

\begin{problem}
\LabelProblem{ZeroNotEqualToOne}{$0\neq 1$}
Show that $0\neq 1.$ [Hint: Show that if $x\neq0,$ then $0\cdot x \neq
x.$]\xqed{\lozenge}{}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
  \LabelProblem{prob:RationalField}{Number Fields!$\QQ$}
Consider the set of ordered pairs of integers: $\left\{(x,y)|s, y \in
  \ZZ\right\},$ and define addition and multiplication as follows:
\begin{description}
\item[Addition:] $(a,b)+(c,d) = (ad+bc, bd)$
\item[Multiplication:] $(a,b)\cdot(c,d) = (ac, bd).$
\end{description}
\begin{description}
\item[(a)] If we add the convention that 
$$
(ab, ad) = (b,d)
$$
show that this set with these operations forms a number field.
\item[(b)] Which
number field is this?\xqed{\lozenge}{}
\end{description}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
  \LabelProblem{prob:ComplexField}{Number Fields!$\CC$}
Consider the set of ordered pairs of real numbers, $\left\{(x,y)|x,
  y\in\RR\right\},$ and define addition and multiplication as follows:
\begin{description}
\item[Addition:] $(a,b)+(c,d) = (a+c, b+d)$
\item[Multiplication:] $(a,b)\cdot(c,d) = (ac- bd,ad+bc).$
\end{description}
\begin{description}
\item[(a)] Show that this set with these operations forms a number field.
\item[(b)] Which number field is this?\xqed{\lozenge}{}
\end{description}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}


\section*{Building the Real Numbers}
\label{sec:real-numbers}

\begin{problem}\ 
  \LabelProblem{prob:LinearlyOrderedFields}{number fields!linearly ordered}
  \begin{description}
  \item[(a)] Prove that the following must hold in {\bf any} linearly
    ordered number field.
    \begin{enumerate}
    \item $0<x$ if and only if $-x<0.$
    \item If $x<y$ and $z<0$ then $y\cdot z<x\cdot z.$
    \item For all $x\neq 0,$ $0<x^2.$
    \item $0<1.$
    \end{enumerate}
  \item[(b)] Show that the set of complex numbers ($\CC$) is not a
    linearly ordered field.
  \end{description}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:InfiniteDecimalAddition}{infinite decimal addition}
  Define addition on infinite decimals in a manner that is
  closed. [Hint: Find an appropriate ``carry'' operation for our
  definition.]\xqed{\lozenge}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
\LabelProblem{prob:EquivalentCauchySequences}{equivalent Cauchy sequences}
  Show that:
  \begin{description}
  \item[a)] $x\equiv x$
  \item[b)] $x\equiv y \imp y\equiv x$
  \item[c)] $x\equiv y$ and $y\equiv z \imp x\equiv z$\xqed{\lozenge}
  \end{description}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
  \LabelProblem{prob:CauchyAdditionWellDefined}{addition of Cauchy
    sequences is well defined}
  Let $x$ and $y$ be real numbers in $\QQ$ (that is, let them be sets
  of equivalent Cauchy sequences). If $(s_n)$ and $(t_n)$ are in $x$
  and $(\sigma_n)$ and $(\tau_n)$ are in $y$ then
$$
(s_n+t_n)_{n=1}^\infty \equiv
(\sigma_n+\tau_n)_{n=1}^\infty. \xqedhere{1.55in}{\lozenge}
$$
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
  \LabelProblem{prob:OneInCauchy}{building the reals by Cauchy
    sequences!identify the multiplicative identity}
  Identify the set of equivalent Cauchy sequences, $1^*,$ such that 
$$
1^*\cdot x=x.
$$
\xqed{\lozenge}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
  \LabelProblem{prob:ConfirmFieldAxiomsCauchy}{building the reals by Cauchy
    sequences!confirm the field axioms}
  Let $x, y,$ and $z$ be real numbers (equivalent sets of Cauchy
  sequences). Show that with addition and multiplication defined as
  above we have:
\begin{description}
\item[a)] $x+y=y+x$
\item[b)] $(x+y)+z=x+(y+z)$
\item[c)] $x\cdot y=y\cdot x$
\item[d)] $(x\cdot y)\cdot z=x\cdot (y\cdot z)$
\item[e)] $x\cdot(y+z)=x\cdot y+x\cdot z$\xqed{\lozenge}
\end{description}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{theorem}
\label{thm:OrderingCuts}
\IndexTheorem{thm:OrderingCuts}{}
  Let $\alpha$ and $\beta$ be cuts. Then $\alpha<\beta$ if and only if
  $\alpha\subset\beta.$ \xqed{\blacktriangle}
\end{theorem}

\begin{problem}
  \LabelProblem{DedekindOrdering}{Dedekind cuts!order properties}
  Prove Theorem~\ref{thm:OrderingCuts} and use this to conclude that
  if $\alpha$ and $\beta$ are cuts then exactly one of the following
  is true:
\begin{enumerate}
\item $\alpha=\beta.$
\item $\alpha<\beta.$
\item $\beta<\alpha.$
\end{enumerate}
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{problem}
  \LabelProblem{prob:MultPreserveCut}{cuts!multiplication of}
Show that if $\alpha$ and $\beta$ are cuts then $\alpha\cdot\beta$ is
also a cut.
\begin{solution}{}
  
\end{solution}
\newpage{}
\end{problem}

\begin{lemma}
\label{lem:Technical}
\IndexLemma{lem:Technical}
  Let $\beta$ be a cut, $y$ and $z$ be positive rational numbers not
  in $\beta$ with $y<z,$ and let $\eps>0$ be any rational number. Then
  there exist positive rational numbers $r$ and $s$ with $r\in\beta,$
  and $s\not\in\beta,$ such that $s<z,$ and $s-r<\eps.$\xqed{\blacktriangle}
\end{lemma}

\begin{problem}
  \LabelProblem{prob:ProveTechnical}{}
  Prove Lemma~\ref{lem:Technical}. [Hint: Since $\beta$ is a cut there
  exists $r_1\in\beta.$ Let $s_1=y\not\in\beta.$ We know that
  $r_1<s_1<z.$ Consider the midpoint $\frac{s_1+r_1}{2}.$ If this is
  in $\beta$ then relabel it as $r_2$ and relabel $s_1$ as $s_2.$ If
  it is not in $\beta$ then relabel it as $s_2$ and relabel $r_1$ as
  $r_2,$ etc.]\xqed{\lozenge}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}

\begin{problem}
  \LabelProblem{prob:CutSubtraction}{}
  Let $\alpha$ and $\beta$ be cuts with $\beta<\alpha.$ Prove that
  $\beta+(\alpha-\beta)=\alpha.$ [Hint: It is pretty straightforward
  to show that $\beta+(\alpha-\beta)\subseteq\alpha.$ To show that
  $\alpha\subseteq\beta+(\alpha-\beta),$ we let $x\in\alpha.$ Since
  $\beta<\alpha,$ we have $y\in\alpha$ with $y\not\in\beta.$ We can
  assume without loss of generality that $x<y.$ (Why?)  Choose
  $z\in\alpha$ with $y<z.$ By the Lemma~\ref{lem:Technical}, there
  exists positive rational numbers $r$ and $s$ with $r\in\beta,$
  $s\in\beta,$ $s<z,$ and $s-r<z-x.$  Show that
  $x<r+(z-s).$]\xqed{\lozenge}
  \begin{solution}{}
    
  \end{solution}
\newpage{}
\end{problem}


\end{document}
%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% eval:(load-file (concat dropbox-location "/lisp/start-assessment.el"))
%%% problem-header: "\\begin{problem}"
%%% problem-tail: "\\end{problem}"
%%% End: 
